Index: blog/.vuepress/config.ts
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import { viteBundler } from \"@vuepress/bundler-vite\";\nimport { defineUserConfig } from \"vuepress\";\nimport { gungnirTheme } from \"vuepress-theme-gungnir\";\n\nconst isProd = process.env.NODE_ENV === \"production\";\n\nexport default defineUserConfig({\n  title: \"Xiaohan Zou\",\n  description: \"Xiaohan Zou (Renovamen) is a dragon lost in human world.\",\n\n  head: [\n    [\n      \"link\",\n      {\n        rel: \"icon\",\n        type: \"image/png\",\n        sizes: \"16x16\",\n        href: `/img/logo/favicon-16x16.png`\n      }\n    ],\n    [\n      \"link\",\n      {\n        rel: \"icon\",\n        type: \"image/png\",\n        sizes: \"32x32\",\n        href: `/img/logo/favicon-32x32.png`\n      }\n    ],\n    [\"meta\", { name: \"application-name\", content: \"Xiaohan Zou\" }],\n    [\"meta\", { name: \"apple-mobile-web-app-title\", content: \"Xiaohan Zou\" }],\n    [\n      \"meta\",\n      { name: \"apple-mobile-web-app-status-bar-style\", content: \"black\" }\n    ],\n    [\n      \"link\",\n      { rel: \"apple-touch-icon\", href: `/img/logo/apple-touch-icon.png` }\n    ],\n    [\"meta\", { name: \"theme-color\", content: \"#377bb5\" }],\n    [\"meta\", { name: \"msapplication-TileColor\", content: \"#377bb5\" }]\n  ],\n\n  bundler: viteBundler(),\n\n  theme: gungnirTheme({\n    repo: \"Renovamen/blog.zxh.io\",\n    docsDir: \"blog\",\n    docsBranch: \"master\",\n\n    hitokoto: \"https://v1.hitokoto.cn?c=i\", // enable hitokoto (一言) or not?\n\n    // personal information\n    personalInfo: {\n      name: \"Renovamen\",\n      avatar: \"/img/avatar.jpg\",\n      description: \"いつか、私がヒトじゃなくなっても\",\n      sns: {\n        github: \"Renovamen\",\n        linkedin: \"xiaohan-zou\",\n        // facebook: \"renovamen.zou\",\n        twitter: \"renovamen_zxh\",\n        zhihu: \"chao-neng-gui-su\",\n        email: \"renovamenzxh@gmail.com\",\n        rss: \"/rss.xml\"\n      }\n    },\n\n    // header images on home page\n    homeHeaderImages: [\n      {\n        path: \"/img/home-bg/1.jpg\",\n        mask: \"rgba(40, 57, 101, .4)\"\n      },\n      {\n        path: \"/img/home-bg/2.jpg\",\n        mask: \"rgba(196, 176, 131, .1)\"\n      },\n      {\n        path: \"/img/home-bg/3.jpg\",\n        mask: \"rgba(68, 74, 83, .1)\"\n      },\n      {\n        path: \"/img/home-bg/4.jpg\",\n        mask: \"rgba(19, 75, 50, .2)\"\n      },\n      {\n        path: \"/img/home-bg/5.jpg\"\n      }\n    ],\n\n    // other pages\n    pages: {\n      tags: {\n        subtitle: \"Black Sheep Wall\",\n        bgImage: {\n          path: \"/img/pages/tags.jpg\",\n          mask: \"rgba(211, 136, 37, .5)\"\n        }\n      },\n      links: {\n        subtitle:\n          \"When you are looking at the stars, please put the brightest star shining night sky as my soul.\",\n        bgImage: {\n          path: \"/img/pages/links.jpg\",\n          mask: \"rgba(64, 118, 190, 0.5)\"\n        }\n      }\n    },\n\n    themePlugins: {\n      // only enable git plugin in production mode\n      git: isProd,\n      katex: true,\n      giscus: {\n        repo: \"This-is-an-Apple/blog-giscus-comments\",\n        repoId: \"R_kgDOGl2SjQ\",\n        category: \"Announcements\",\n        categoryId: \"DIC_kwDOGl2Sjc4CAcxK\",\n        darkTheme: \"https://blog.zxh.io/styles/giscus-dark.css\"\n      },\n      mdPlus: {\n        all: true\n      },\n      ga: \"G-HCQSX53XFG\",\n      ba: \"75381d210789d3eaf855fa16246860cc\",\n      rss: {\n        siteURL: \"https://blog.zxh.io\",\n        copyright: \"Renovamen 2018-2022\"\n      }\n    },\n\n    navbar: [\n      {\n        text: \"Home\",\n        link: \"/\",\n        icon: \"fa-fort-awesome\"\n      },\n      {\n        text: \"Tags\",\n        link: \"/tags/\",\n        icon: \"fa-tag\"\n      },\n      {\n        text: \"Links\",\n        link: \"/links/\",\n        icon: \"fa-satellite-dish\"\n      },\n      {\n        text: \"About\",\n        link: \"https://zxh.io\",\n        icon: \"fa-paw\"\n      },\n      {\n        text: \"Portfolio\",\n        link: \"https://portfolio.zxh.io/\",\n        icon: \"oi-rocket\"\n      }\n    ],\n\n    footer: `\n      &copy; <a href=\"https://github.com/Renovamen\" target=\"_blank\">Renovamen</a> 2018-2022\n      <br>\n      Powered by <a href=\"https://v2.vuepress.vuejs.org\" target=\"_blank\">VuePress</a> &\n      <a href=\"https://github.com/Renovamen/vuepress-theme-gungnir\" target=\"_blank\">Gungnir</a>\n    `\n  }),\n\n  markdown: {\n    headers: {\n      level: [2, 3, 4, 5]\n    },\n    code: {\n      lineNumbers: false\n    }\n  }\n});\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/blog/.vuepress/config.ts b/blog/.vuepress/config.ts
--- a/blog/.vuepress/config.ts	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
+++ b/blog/.vuepress/config.ts	(date 1683078251808)
@@ -5,9 +5,9 @@
 const isProd = process.env.NODE_ENV === "production";
 
 export default defineUserConfig({
-  title: "Xiaohan Zou",
-  description: "Xiaohan Zou (Renovamen) is a dragon lost in human world.",
-
+  title: "Weiming Chen",
+  // base: "/blog.zxh.io/blog/.vuepress/dist", //打包专用
+  description: "Weiming Chen is a dragon lost in human world.",
   head: [
     [
       "link",
@@ -27,8 +27,8 @@
         href: `/img/logo/favicon-32x32.png`
       }
     ],
-    ["meta", { name: "application-name", content: "Xiaohan Zou" }],
-    ["meta", { name: "apple-mobile-web-app-title", content: "Xiaohan Zou" }],
+    ["meta", { name: "application-name", content: "weiming Chen" }],
+    ["meta", { name: "apple-mobile-web-app-title", content: "weiming Chen" }],
     [
       "meta",
       { name: "apple-mobile-web-app-status-bar-style", content: "black" }
@@ -52,16 +52,13 @@
 
     // personal information
     personalInfo: {
-      name: "Renovamen",
-      avatar: "/img/avatar.jpg",
-      description: "いつか、私がヒトじゃなくなっても",
+      name: "陈伟铭",
+      avatar: "/img/head.jpeg",
+      description: "CODE_CHEN",
       sns: {
-        github: "Renovamen",
-        linkedin: "xiaohan-zou",
-        // facebook: "renovamen.zou",
-        twitter: "renovamen_zxh",
-        zhihu: "chao-neng-gui-su",
-        email: "renovamenzxh@gmail.com",
+        github: "chen-wm",
+        zhihu: "https://www.zhihu.com/people/hey-4-21",
+        email: "627891695@qq.com",
         rss: "/rss.xml"
       }
     },
@@ -99,8 +96,9 @@
         }
       },
       links: {
+        title: 'Introduction',
         subtitle:
-          "When you are looking at the stars, please put the brightest star shining night sky as my soul.",
+          "Part of my profile.",
         bgImage: {
           path: "/img/pages/links.jpg",
           mask: "rgba(64, 118, 190, 0.5)"
@@ -125,8 +123,8 @@
       ga: "G-HCQSX53XFG",
       ba: "75381d210789d3eaf855fa16246860cc",
       rss: {
-        siteURL: "https://blog.zxh.io",
-        copyright: "Renovamen 2018-2022"
+        siteURL: "https://chen-wm.github.io/chenwm.github.io/",
+        copyright: "chenwm 2019-up to now"
       }
     },
 
@@ -142,24 +140,24 @@
         icon: "fa-tag"
       },
       {
-        text: "Links",
+        text: "Introduction",
         link: "/links/",
         icon: "fa-satellite-dish"
       },
       {
         text: "About",
-        link: "https://zxh.io",
+        link: "https://www.baidu.com",
         icon: "fa-paw"
       },
       {
         text: "Portfolio",
-        link: "https://portfolio.zxh.io/",
+        link: "https://www.baidu.com/",
         icon: "oi-rocket"
       }
     ],
 
     footer: `
-      &copy; <a href="https://github.com/Renovamen" target="_blank">Renovamen</a> 2018-2022
+      &copy; <a href="https://github.com/chenwm" target="_blank">coding by</a> 2019.10-至今
       <br>
       Powered by <a href="https://v2.vuepress.vuejs.org" target="_blank">VuePress</a> &
       <a href="https://github.com/Renovamen/vuepress-theme-gungnir" target="_blank">Gungnir</a>
Index: blog/posts/2020-02-29-image-aesthetic-assessment.md
===================================================================
diff --git a/blog/posts/2020-02-29-image-aesthetic-assessment.md b/blog/posts/2020-02-29-image-aesthetic-assessment.md
deleted file mode 100644
--- a/blog/posts/2020-02-29-image-aesthetic-assessment.md	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
+++ /dev/null	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
@@ -1,358 +0,0 @@
----
-layout: Post
-title: 图像美感评估
-subtitle: A Survey on Image Aesthetic Assessment
-author: Renovamen
-date: 2020-02-29
-headerImage: /img/in-post/2020-02-29/header.jpeg
-permalinkPattern: /post/:year/:month/:day/:slug/
-tags:
-  - CV
----
-
-对图像美感评估（Image Aesthetic Assessment）领域的简单调研，到时候大概可以直接复制粘贴进毕业论文里。
-
-<!-- more -->
-
-## Surveys
-
-- **Algorithmic Inferencing of Aesthetics and Emotion in Natural Images: An Exposition.** *Ritendra Datta, Jia Li, and James Z. Wang.* ICIP 2008. [[Paper]](https://www.ri.cmu.edu/pub_files/pub4/datta_ritendra_2008_2/datta_ritendra_2008_2.pdf)
-
-- **On Aesthetics and Emotions in Images: A Computational Perspective.** *Dhiraj Joshi, et al.* IEEE Signal Processing Magazine 2011. [[IEEE]](https://ieeexplore.ieee.org/document/5999579) [[Paper]](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/37213.pdf)
-
-- **Aesthetic Analysis of Images.** 2015. [[Report]](https://eg.uc.pt/bitstream/10316/35507/1/Aesthetic%20Analysis%20of%20Images%20Intermediate%20report.pdf)
-
-- **Image Aesthetic Assessment: An Experimental Survey.** *Yubin Deng, et al.* IEEE Signal Processing Magazine 2017. [[IEEE]](https://ieeexplore.ieee.org/abstract/document/7974874) [[arxiv]](https://arxiv.org/pdf/1610.00838.pdf)
-
-- **A Report: Image Aesthetic Assessment.** *Chunbiao Zhu.* 2018. [[Report]](https://www.researchgate.net/publication/325184839_A_Report_Image_Aesthetic_Assessment)
-
-
-## Datasets
-
-### Photo.net (PN)
-
-**Algorithmic Inferencing of Aesthetics and Emotion in Natural Images: An Exposition.** *Ritendra Datta, Jia Li, and James Z. Wang.* ICIP 2008. [[Paper]](https://www.ri.cmu.edu/pub_files/pub4/datta_ritendra_2008_2/datta_ritendra_2008_2.pdf)
-
-共 20,278 张图片（[Deng et al. 2017](https://arxiv.org/pdf/1610.00838.pdf)），平均每张图片 12 个评分，评分范围为 0-7，分越高说明图片质量越高。所有图片的平均得分的峰值在分布右侧，说明整体评价偏高。
-
-![photo-net-distribution](/img/in-post/2020-02-29/photo-net-distribution.png)
-
-<p class="desc">PN 数据集的图片平均得分分布</p>
-
-有论文认为 PN 数据集中超过 30% 的图片都被其拍摄者 P 上了一个相框以让它更好看一些，这会导致这些图片的评分偏高（[Marchesotti, et al. 2011](https://ieeexplore.ieee.org/abstract/document/6126444)）。
-
-下载：需要根据 [Dataset File](http://ritendra.weebly.com/aesthetics-datasets.html) 中的索引号去 [photo.net](http://photo.net) 上找图片，有的图片已经被从网上移除了。
-
-
-
-### DPChallenge
-
-**Algorithmic Inferencing of Aesthetics and Emotion in Natural Images: An Exposition.** *Ritendra Datta, Jia Li, and James Z. Wang.* ICIP 2008. [[Paper]](https://www.ri.cmu.edu/pub_files/pub4/datta_ritendra_2008_2/datta_ritendra_2008_2.pdf)（依然是这篇论文）
-
-共 16,509 张图片，平均每张图片 205 个评分，评分范围为 0-10，分越高说明图片质量越高。
-
-
-![dpchallenge-distribution](/img/in-post/2020-02-29/dpchallenge-distribution.png)
-
-<p class="desc">DPChallenge 数据集的图片平均得分分布</p>
-
-**现在大概已经可以被 AVA 数据集所取代。**
-
-下载：需要根据 [Dataset File](http://ritendra.weebly.com/aesthetics-datasets.html) 中的索引号去 [dpchallenge.com](https://www.dpchallenge.com/) 上找图片。
-
-
-### CUHK-PQ
-
-**Content-based Photo Quality Assessment.** *Wei Luo, Xiaogang Wang, and Xiaoou Tang.* ICCV 2011. [[IEEE]](https://ieeexplore.ieee.org/abstract/document/6126498) [[Paper]](http://mmlab.ie.cuhk.edu.hk/archive/2011/cvpr11_WLuo_XWang_XTang.pdf)
-
-**Content-based Photo Quality Assessment.** *Xiaoou Tang, Wei Luo, and Xiaogang Wang.* TMM 2013. [[IEEE]](https://ieeexplore.ieee.org/document/6544270) [[Paper]](http://mmlab.ie.cuhk.edu.hk/archive/2011/cvpr11_WLuo_XWang_XTang.pdf)
-
-现在有 30,000 左右张图片，每张图片被按内容分为了 7 个类别。美学标注只有“高质量”和“低质量”两个，高低质量图片比例约为 1:3（[Deng et al. 2017](https://arxiv.org/pdf/1610.00838.pdf)）。所以该数据集很难被用来进行评分任务的训练，而且分类难度不算大。因为是直接把从专业摄影网站（dpchallenge.com）和从业余摄影师处收集到的图片混在了一起，所以可能不能代表真实场景（[Murray et al. 2012](http://refbase.cvc.uab.es/files/MMP2012a.pdf)）。
-
-下载：[<v-icon name="ri-link-m" scale="0.9"/>  Multimedia Laboratory, CUHK](http://mmlab.ie.cuhk.edu.hk/archive/CUHKPQ/Dataset.htm)
-
-### AVA
-
-**AVA: A Large-Scale Database for Aesthetic Visual Analysis.** *Naila Murray, Luca Marchesotti, Florent Perronnin.* CVPR 2012. [[IEEE]](https://ieeexplore.ieee.org/document/6247954) [[Paper]](http://refbase.cvc.uab.es/files/MMP2012a.pdf) [[Dataset]](https://github.com/mtobeiyf/ava_downloader)
-
-收集并标注了来源于 dpchallenge.com 的超过 250,000 张图片。带有美学质量标注（Aesthetic annotations）（78～549 个评分，评分范围为 0-10，分越高说明图片质量越高）、语义标注（Semantic annotations）（共 66 种）和摄影风格标注（Photographic style annotations）（共 14 种，大概就是所谓的“美学因素”）。是第一个带有详细标注的大型图像美感评估数据集，也是图像美感评估领域公认的基准数据集。
-
-该论文比较了 AVA 与其他数据集：
-
-![compare](/img/in-post/2020-02-29/ava-compare.png)
-
-<p class="desc">AVA 与其他数据集的比较</p>
-
-对于二分类任务，一般认为平均得分高于 $5 + \sigma$ 的图片质量高，低于 $5 + \sigma$ 的图片质量低。
-
-但 AVA 的很多图片后期处理痕迹太重。且绝大多数图片来自于专业摄影者而非普通人，所以 AVA 有较大的 bias（[Kone et al. 2016](https://arxiv.org/pdf/1606.01621.pdf)）。
-
-下载：[<v-icon name="ri-link-m" scale="0.9"/> Github](https://github.com/mtobeiyf/ava_downloader)
-
-
-### AADB
-
-**Photo Aesthetics Ranking Network with Attributes and Content Adaptation.** *Shu Kong, et al.* ECCV 2016. [[arxiv]](https://arxiv.org/pdf/1606.01621.pdf) [[Project]](https://www.ics.uci.edu/~skong2/aesthetics.html) [[Code]](https://github.com/aimerykong/deepImageAestheticsAnalysis) [[Dataset & Model]](https://drive.google.com/open?id=0BxeylfSgpk1MOVduWGxyVlJFUHM)
-
-收集并标注了来自 [Flickr](https://www.flickr.com/) 的共 10,000 张图片。带有美学质量标注（5 个人评分）和美学因素标注（共 11 种，二分类，算是对 AVA 的补充）。
-
-相比 AVA，AADB 中所有图片都是真实照片，且注意平衡了专业摄影者和普通拍照者的作品数量，且标注了每个评分的标注者 ID（用于消除标不同标注者评价标准的不同所带来的影响）。
-
-该论文还比较了 AADB 与其他数据集：
-
-![compare](/img/in-post/2020-02-29/aadb-compare.png)
-
-<p class="desc">AADB 与其他数据集的比较</p>
-
-但 AADB 的数据量过小，且标注人员过少。
-
-下载：[<v-icon name="ri-link-m" scale="0.9"/> Google Drive](https://drive.google.com/open?id=0BxeylfSgpk1MOVduWGxyVlJFUHM)
-
-
-### AROD
-
-**Will People Like Your Image? Learning the Aesthetic Space.** *Katharina Schwarz, Patrick Wieschollek, and Hendrik P. A. Lensch.* WACV 2018. [[arxiv]](https://arxiv.org/pdf/1611.05203.pdf) [[Code & Dataset]](https://github.com/cgtuebingen/will-people-like-your-image)
-
-
-从 [Flickr](https://www.flickr.com/) 上爬了 2004 - 2016 年间的超过 380,000 张图片，及他们的浏览量（views）、评论数、被喜欢次数（faves）、图片标题、在网站上的描述等数据。然后定义了图片的美学质量为：
-
-$$
-S(i) \sim \frac{\log F(i)}{\log V(i)}
-$$
-
-其中 $V(i)$ 为每张图片的 views，$F(i)$ 为 faves。
-
-相当于用一种类似于无监督标注的方法在试图解决 AVA 的 bias 太重和 AADB 数据量和标注人员过少的问题。
-
-该论文还比较了 AROD 和 AVA 与 AADB：
-
-![compare](/img/in-post/2020-02-29/arod-compare.png)
-
-<p class="desc">AROD 与其他数据集的比较</p>
-
-下载：[<v-icon name="ri-link-m" scale="0.9"/> Github](https://github.com/cgtuebingen/will-people-like-your-image)，`arod/list.txt` 中给出了图片的 URL，格式为 `url;faves;views`。
-
-### GPA
-
-**Gourmet Photography Dataset for Aesthetic Assessment of Food Images.** *Kekai Sheng, et al.* SIGGRAPH 2018. [[Dataset]](https://github.com/Openning07/GPA)
-
-一个用于食物图片美感评估的数据集。从社交媒体和食物分类数据集中收集了共 24,000 张图片，然后人工标注（二分类）。
-
-下载：[<v-icon name="ri-link-m" scale="0.9"/> Github](https://github.com/Openning07/GPA)
-
-
-
-### PCCD
-
-**Aesthetic Critiques Generation for Photos.** *Kuang-Yu Chang, Kung-Hung Lu, and Chu-Song Chen.* ICCV 2017. [[IEEE]](https://ieeexplore.ieee.org/document/8237642) [[Paper]](https://www.iis.sinica.edu.tw/~kuangyu/iccv17_aesthetic_critiques.pdf) [[Code]](https://github.com/kunghunglu/DeepPhotoCritic-ICCV17) [[Dataset]](https://github.com/ivclab/DeepPhotoCritic-ICCV17)
-
-首次在图像美学数据集中加入了语言评论信息。包含了来自 [GuruShots](https://gurushots.com/)（一个专业图片评论网站）上的 4235 张图片，和它们的超过 60,000 条评论信息。评论被按角度（如“color & light”、“depth of field”等）分成了 7 类。并且张图片都带有对图片整体和 7 个角度的打分（评分范围为 1-10）。可以说在美学因素的标注上比 AVA 和 AADB 的二分类更详细。
-
-但数据量过少。
-
-~~我并没有找到这个数据集，该论文的 [Github 主页](https://github.com/kunghunglu/DeepPhotoCritic-ICCV17)上似乎也没有。~~ 不久前似乎开源了：[<v-icon name="ri-link-m" scale="0.9"/> Github](https://github.com/ivclab/DeepPhotoCritic-ICCV17)
-
-我也不明白为啥 2017 年的论文 2020 年才开源数据集...
-
-
-### DPC-Caption
-
-**Aesthetic Attributes Assessment of Images.** *Xin Jin, et al.* ACM MM 2019. [[arxiv]](https://arxiv.org/pdf/1907.04983.pdf) [[Dataset]](https://github.com/BestiVictory/DPC-Captions)
-
-把 AVA 中图片的评论都爬了下来，并按角度分成了 6 类，分类的标准基于从 PCCD 中统计出来的信息。比 PCCD 数据量大得多，但没有每个角度的评分，标注要弱一些。
-
-下载：[<v-icon name="ri-link-m" scale="0.9"/> Github](https://github.com/BestiVictory/DPC-Captions)
-
-
-
-### 其他
-
-- **Understanding Aesthetics in Photography Using Deep Convolutional neural Networks.** *Maciej Suchecki and Tomasz Trzciski.* SPA 2017. [[IEEE]](https://ieeexplore.ieee.org/abstract/document/8166855) [[Paper]](http://ii.pw.edu.pl/~ttrzcins/papers/SPA_2017.pdf)
-
-
-    该论文用的数据集与 AROD 比较类似，从 Flicker 上爬了大概 170 万张图片，定义的美学分数为：
-
-    $$
-    \text{score} = \log_2 (n_{\text{views}} + \frac{1}{n_{\text{days}}} + 1)
-    $$
-
-    其中 $n_{\text{views}}$ 是图片浏览量，$n_{\text{days}}$ 是距离图片上传日期的天数。
-
-    然而该论文最后给出的数据集地址已经失效了......
-
-    &nbsp;
-
-- **An Image is Worth More than a Thousand Favorites: Surfacing the Hidden Beauty of Flickr Pictures.** *Rossano Schifanella, et al.* ICWSM 2015. [[arxiv]](https://arxiv.org/pdf/1505.03358.pdf) [[Dataset]](http://www.di.unito.it/~schifane/dataset/beauty-icwsm15/#)
-
-
-    研究的是在人气较低的图片中找出高质量图片，它的数据集包含来自 Flicker 上的约 15,000 张图片，带有语义标注（共 4 种）和美学质量标注（评分范围为 1-5）。
-
-    下载：需要根据[这里](http://www.di.unito.it/~schifane/dataset/beauty-icwsm15/#)的 `flickr_photo_id` 通过 [Flicker API](https://www.flickr.com/services/api/) 去搞图片。
-
-
-
-## Papers
-
-### 手工特征
-
-**全局特征：**
-
-- **Classification of Digital Photos Taken by Photographers or Home Users.** *Hanghang Tong, et al.* PCM 2004.
-[[Paper]](http://bigeye.au.tsinghua.edu.cn/english/paper/_PCM04_tong.pdf)
-
-    图像美感评估最早的一篇论文，提取了基本的全局低级特征（blurriness、contrast、colorfulness、saliency），然后用 boosting 来区分来自专业摄影师和普通拍照者的照片。
-
-- **Studying Aesthetics in Photographic Images Using a Computational Approach.** *Ritendra Datta, et al.* ECCV 2006. [[Paper]](http://infolab.stanford.edu/~wangz/project/imsearch/Aesthetics/ECCV06/datta.pdf)
-
-    靠直觉（论文原话）提取了 56 维低层和高层特征，用 SVM 搞二分类，用 CART 评估美感分数值。展示了用机器学习进行图像美感分析的可行性，是个里程碑。
-
-- **The Design of High-Level Features for Photo Quality Assessment.** *Yan Ke, Xiaoou Tang, Feng Jing.* CVPR 2006. [[Paper]](http://www-cgi.cs.cmu.edu/~yke/photoqual/cvpr06photo.pdf)
-
-    构造了包括很多高层语义特征在内的 7 维特征，然后用朴素贝叶斯搞二分类。该论文跟上一篇论文都是最早把图像审美问题转换为二分类问题的尝试。
-
-**前景背景对比特征：**
-
-- **Photo and Video Quality Evaluation: Focusing on the Subject.** *Yiwen Luo and Xiaoou Tang.* ECCV 2008. [[Paper]](http://mmlab.ie.cuhk.edu.hk/pdf/luoT_ECCV08.pdf)
-
-    先把主题区域和背景分离，然后考虑了主题区域和背景的清晰度对比度、亮度对比度等特征，最终提取了 5 维特征。分类器分别使用了朴素贝叶斯、SVM 和 Gentle AdaBoost。从它给出的结果来看效果比上面两篇论文提高了很多。它还顺便用这种方法搞了一下视频质量评估。
-
-
-- **Saliency-enhanced Image Aesthetics Class Prediction.** *Lai-Kuan Wong, Kok-Lim Low.* ICIP 2009. [[IEEE]](https://ieeexplore.ieee.org/document/5413825) [[Paper]](https://projet.liris.cnrs.fr/imagine/pub/proceedings/ICIP-2009/pdfs/0000997.pdf)
-
-    也分离了主题区域和背景，认为主题区域一定是显著区域，所以在提取了主题区域时用了一个显著性模型。而且在考虑前景背景对比特征的同时也考虑了一些全局特征。然后用 SVM 搞二分类。
-
-- **A Framework for Photo-quality Assessment and Enhancement Based on Visual
-Aesthetics.** *Subhabrata Bhattacharya, et al.* ACM MM 2010. [[Paper]](http://www.cs.cmu.edu/~rahuls/pub/mm2010-rahuls.pdf)
-
-
-    **A Holistic Approach to Aesthetic Enhancement of Photographs.** *Subhabrata Bhattacharya, et al.* TOMCCAP 2011. [[Paper]](http://www.cs.cmu.edu/~rahuls/pub/tomccap2011-rahuls.pdf)
-
-
-    对有单个前景的图片提取了 relative foreground position 作为特征（用分割或显著度提取前景的 visual attention point，然后算它跟四个 stress point 之间的距离），对风景图片提取了 visual weight ratio 作为特征（检测地平线，然后算它跟黄金分割线的差距）。然后用 SVR 来对图片的的美感进行打分（范围为 1-5）。它还能根据上述法则提出增强图片美感的建议。
-
-
-**通用局部特征：**
-
-- **Aesthetic Quality Classification of Photographs Based on Color Harmony.** *Masashi Nishiyama, et al.* CVPR 2011. [[Paper]](http://research.nii.ac.jp/~imarik/resources/papers/CVPR2012-Nishiyama.pdf)
-
-- **Assessing the Aesthetic Quality of Photographs Using Generic Image Descriptors.** *Luca Marchesotti, et al.* ICCV 2011. [[IEEE]](https://ieeexplore.ieee.org/document/6126444) [[Paper]](http://www.tamaraberg.com/teaching/Fall_13/papers/Marchesotti2011.pdf)
-
-- **A Statistic Approach for Photo Quality Assessment.** *Li-Yun Lo, et al.* ISIC 2012. [[IEEE]](https://ieeexplore.ieee.org/abstract/document/6449719) [[Paper]](http://www.csie.kuas.edu.tw/~jcchen/pdf/A%20Statistic%20Approach%20for%20Photo%20Quality%20Assessment%20.pdf)
-
-
-
-
-### 深度学习
-
-#### 分类
-
-**Multi-column：**
-
-- **RAPID: Rating Pictorial Aesthetics Using Deep Learning.** *Xin Lu, et al.* ACM MM 2014. [[Paper]](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.710.1251&rep=rep1&type=pdf)
-
-    **Rating Image Aesthetics Using Deep Learning.** *Xin Lu, et al.* TMM 2015. [[IEEE]](https://ieeexplore.ieee.org/document/7243357) [[Paper]](http://infolab.stanford.edu/~wangz/project/imsearch/Aesthetics/TMM15/lu.pdf)
-
-    首次用神经网络搞图片美感评估。用了双列 CNN，把全局图像和随机提取出的一个局部 patch 各输入一列 CNN，输出的特征会被联合起来输入分类层进行二分类：
-    
-
-    ![rapid-dcnn](/img/in-post/2020-02-29/rapid-dcnn.png)
-    
-    
-    因为数据集用的是有 style 标注的 AVA，该论文还把 style 属性也输入了一列 CNN，相当于最后是 3 列 CNN：
-
-    ![rapid-style-cnn](/img/in-post/2020-02-29/rapid-style-cnn.png)
-
-
-- **Deep Multi-Patch Aggregation Network for Image Style, Aesthetics, and Quality Estimation.** *Xin Lu, et al.* ICCV 2015. [[IEEE]](https://ieeexplore.ieee.org/abstract/document/7410476/) [[Paper]](http://infolab.stanford.edu/~wangz/project/imsearch/Aesthetics/ICCV15/lu.pdf)
-
-    只用了 patch 作为输入。从图片中随机提取一些 patch，用一组 CNN 对每个 patch 提取特征，然后把所有 patch 的特征聚合起来，最后把特征输进 soft-max 层进行二分类。
-
-    ![dma-net](/img/in-post/2020-02-29/dma-net.png)
-
-
-- **A-Lamp: Adaptive Layout-Aware Multi-Patch Deep Convolutional Neural.** *Shuang Ma, et al.* CVPR 2017. [[Paper]](http://openaccess.thecvf.com/content_cvpr_2017/papers/Ma_A-Lamp_Adaptive_Layout-Aware_CVPR_2017_paper.pdf) [[arxiv]](https://arxiv.org/pdf/1704.00248.pdf)
-
-
-    上一篇论文的 patch 是随机提取的，它们可能大量重叠，或者不能覆盖图片的关键信息。所以该论文用了一个显著性模型提取了显著度最高、更多样、重叠部分更少的一些 patch。
-
-    同时该论文还用了另一个显著性模型来提取出图片中的主要物体，从而利用了图片中的物体布局信息。
-
-    ![alamp](/img/in-post/2020-02-29/alamp.png)
-
-- **Attention-based Multi-Patch Aggregation for Image Aesthetic Assessment.** *Kekai Sheng, et al.* ACM MM 2018. [[Paper]](http://chongyangma.com/publications/am/2018_am_paper.pdf) [[Code]](https://github.com/Openning07/MPADA)
-
-    在聚合不同 patch 的特征时使用了 attention 机制。
-
-
-- **Brain-Inspired Deep Networks for Image Aesthetics Assessment.** *Zhangyang Wang, et al.* arXiv 2016. [[arxiv]](https://arxiv.org/pdf/1601.04155.pdf)
-
-- **Composition-preserving Deep Photo Aesthetics Assessment.** *Long Mai, et al.* CVPR 2016.
-[[IEEE]](https://ieeexplore.ieee.org/document/7780429) [[Paper]](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Mai_Composition-Preserving_Deep_Photo_CVPR_2016_paper.pdf) [[Project]](http://web.cecs.pdx.edu/~fliu/project/deep-quality/)
-
-    
-    因为全连接层的特征数是固定的，所以 CNN 一般会对输入图片的尺寸做固定要求。为了适应这种要求，往往需要对输入图片进行剪裁拉伸等操作，这就会破坏图片的布局、降低图片分辨率、导致图片失真等，从而破坏图片的美感。
-
-    所以该论文提出了一个叫 Multi-Net Adaptive Spatial Pooling ConvNet 的结构，由多个用 adaptive spatial pooling 层替换了普通 pooling 层（卷积层和全连接层之间）的 CNN 组成，每个 CNN 除了 adaptive spatial pooling 不一样其他都一样。每个 CNN 的输入是同一张原始图片，输出是指定大小的特征。最后把所有网络输出的特征聚合起来。
-
-    然后还用了另外一个 CNN 来提取图片的场景特征，跟上述特征一起扔进聚合层聚合。
-
-    ![mna](/img/in-post/2020-02-29/mna.png)
-
-    跟 SPP 有点像：
-
-    **Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition.** *Kaiming He, et al.* TPAMI 2015. [[IEEE]](https://ieeexplore.ieee.org/abstract/document/7005506) [[arxiv]](https://arxiv.org/pdf/1406.4729.pdf) [[Code]](https://github.com/yueruchen/sppnet-pytorch)
-
-
-**Multi-task：**
-
-- **Deep Aesthetic Quality Assessment with Semantic Information.** *Yueying Kao, Ran He, and Kaiqi Huang.* TIP 2017. [[IEEE]](https://ieeexplore.ieee.org/abstract/document/7814292) [[arxiv]](https://arxiv.org/pdf/1604.04970.pdf)
-
-    用一个 MTCNN 来提取提取美学特征和场景语义信息。
-
-
-- **Hierarchical Aesthetic Quality Assessment Using Deep Convolutional Neural Networks.** *Yueying Kao, Kaiqi Huang, and Steve Maybank.* Signal Processing: Image Communication 2016. [[Paper]](https://core.ac.uk/download/pdf/141224862.pdf)
-
-
-
-- **Visual Aesthetic Quality Assessment with Multi-task Deep Learning.** *Yueying Kao, Ran He, and Kaiqi Huang.* arXiv 2016. [[Paper]](https://www.researchgate.net/profile/Yueying_Kao/publication/301877404_Visual_Aesthetic_Quality_Assessment_with_Multi-task_Deep_Learning/links/573a717108ae9f741b2cad7a/Visual-Aesthetic-Quality-Assessment-with-Multi-task-Deep-Learning.pdf)
-
-
-- **Photo Aesthetics Ranking Network with Attributes and Content Adaptation.** *Shu Kong, et al.* ECCV 2016. [[arxiv]](https://arxiv.org/pdf/1606.01621.pdf) [[Project]](https://www.ics.uci.edu/~skong2/aesthetics.html) [[Code]](https://github.com/aimerykong/deepImageAestheticsAnalysis) [[Dataset & Model]](https://drive.google.com/open?id=0BxeylfSgpk1MOVduWGxyVlJFUHM)
-
-   提出了 AADB 数据集。
-
-
-**DBM：**
-
-- **Joint Image and Text Representation for Aesthetics Analysis.** *Ye Zhou, et al.* ACM MM 2016. [[Paper]](http://infolab.stanford.edu/~wangz/project/imsearch/Aesthetics/ACMMM2016/zhou.pdf)
-
-    把 AVA 中所有图片的评论都爬了下来，建了一个叫 AVA-Comments 的数据集。用 DBM 来同时利用图片的视觉特征和评论的文本特征。
-
-
-
-#### 评分分布
-
-- **NIMA: Neural Image Assessment.** *Hossein Talebi and Peyman Milanfar.* TIP 2018. [[arxiv]](https://arxiv.org/pdf/1709.05424.pdf) [[Blog]](https://ai.googleblog.com/2017/12/introducing-nima-neural-image-assessment.html) [[Code (Reproduction)]](https://github.com/titu1994/neural-image-assessment)
-
-
-- **Predicting Aesthetic Score Distribution through Cumulative Jensen-Shannon Divergence.** *Xin Jin, et al.* AAAI 2018. [[Paper]](http://jinxin.me/downloads/papers/028-AAAI2018/ScoreDestribution.pdf) [[Code]](https://github.com/BestiVictory/CJS-CNN)
-
-
-#### 文字描述
-
-- **Aesthetic Critiques Generation for Photos.** *Kuang-Yu Chang, Kung-Hung Lu, and Chu-Song Chen.* ICCV 2017. [[IEEE]](https://ieeexplore.ieee.org/document/8237642) [[Paper]](https://www.iis.sinica.edu.tw/~kuangyu/iccv17_aesthetic_critiques.pdf) [[Code]](https://github.com/kunghunglu/DeepPhotoCritic-ICCV17) [[Dataset]](https://github.com/ivclab/DeepPhotoCritic-ICCV17)
-
-    在每个角度的数据集上跑了一个图像描述模型（直接用了 [NeuralTalk2](#show-and-tell)），然后用 Attention 把所有模型输出的隐状态融合起来，作为另一个新的 LSTM 的输入，新的 LSTM 的输出就是涵盖了多个角度的描述。（但从论文给的结果来看角度还是比较单一？）
-
-    <img src="/img/in-post/2020-02-29/pccd.png" width="400px" alt="pccd" />
-
-- **Aesthetic Attributes Assessment of Images.** *Xin Jin, et al.* ACM MM 2019. [[arxiv]](https://arxiv.org/pdf/1907.04983.pdf) [[Dataset]](https://github.com/BestiVictory/DPC-Captions)
-
-    搞了一个比 PCCD 大得多的数据集，跑了一个浮夸的模型，输出指定角度的描述。
-
-    ![aman](/img/in-post/2020-02-29/aman.png)
-
-
-- **Neural Aesthetic Image Reviewer.** *Wenshan Wang, et al.* IET Computer Vision 2019. [[arxiv]](https://arxiv.org/pdf/1802.10240.pdf)
-
-- **Aesthetic Image Captioning From Weakly-Labelled Photographs.** *Koustav Ghosal, Aakanksha Rana, and Aljosa Smolic.* ICCV Workshop 2019. [[Paper]](http://openaccess.thecvf.com/content_ICCVW_2019/papers/CROMOL/Ghosal_Aesthetic_Image_Captioning_From_Weakly-Labelled_Photographs_ICCVW_2019_paper.pdf) [[Code]](https://github.com/V-Sense/Aesthetic-Image-Captioning-ICCVW-2019)
Index: blog/posts/2021-01-01-new-year.md
===================================================================
diff --git a/blog/posts/2021-01-01-new-year.md b/blog/posts/2021-01-01-new-year.md
deleted file mode 100644
--- a/blog/posts/2021-01-01-new-year.md	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
+++ /dev/null	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
@@ -1,115 +0,0 @@
----
-layout: Post
-title: 新年快乐
-subtitle: Happy New Year 2021
-author: Renovamen
-date: 2021-01-01
-headerImage: /img/in-post/2021-01-01/header.jpg
-useHeaderImage: true
-headerMask: rgb(30, 57, 133, .4)
-permalinkPattern: /post/:year/:month/:day/:slug/
-tags:
-  - 摸鱼
----
-
-太长不看版：顺位第一的新年愿望是能成为一个温暖的人类，如果这个愿望今年无法实现，那就先当一个正常一些的人类吧。<!-- more -->然后，希望今年能（在生存率较高的前提下）有书读，希望这个世界能免于鹦鹉的困扰，嗷。
-
-
----
-
-
-我在毕业论文致谢里写，这个六月无法不让我想起四年前那个高考成绩意料之内的不怎么样，自招发挥也情理之中的没有很好，却依然被同济软院降分捞了进来的神奇的盛夏。
-
-那时给我的印象最深刻的是，一个志愿者学姐在四平路南楼尽头的阶梯教室里告诉我们：“不要玩手机，同济校规要求不能在教室里玩手机。”
-
-教室里的人大概都还很天真，于是大家几乎都相信了这句话。
-
-也不知道现在的高中毕业生们还有没有那么容易被骗。
-
-
----
-
-
-我没有想到的是我居然还有直接揭穿这个谎言的机会。那一天我以为我走出同济校门之后就再也不会回来，没想到四年朝朝暮暮，我又在同济迎来了一个又一个的夏天。
-
-现在想想，造成我最后来同济的是一个个敷衍的决定。自招志愿填得相当随意，本来脑子一热想填上交，还好竞赛教练帮我冷静了一把“你上交肯定初审都过不了，还是填个概率高一点的，别浪费机会”（结果我校那年上交自招似乎全军覆没）。第二天我走出教室，看到教室门外贴来给学生打鸡血的高校照片，突然觉得“诶同济这名字真好听”，遂报了名。
-
-因为并不怎么想来这学校，于是自招也考得相当随意，面试的时候还说了些奇怪的话，结果居然还是给了降分。
-
-再然后，即使以我当时那个糟糕的高考成绩，我依然有更想去且我也能去的学校，最后会来同济很大程度上是因为我抗争到最后实在太累了，觉得算了吧就这儿了吧，然后填了志愿，尘埃落定。
-
-这么看来，那个夏天的确相当神奇。
-
-于是本科生涯以来了一个不太想来却又觉得自己不配来的学校开始，又以一个大概对不太起当年的降分机会的毕业状态结束。我同样在毕业论文致谢里写，希望我这四年的成长能够对得起同济当年的选择，但我心里清楚肯定是对不起的。
-
-可我总不能真的把这个想法写进论文里。
-
-
----
-
-
-毕业的那天，我以搞砸了一堆事的状态进入了失学失业无业游民期。在找地方收留我的惊慌失措中，我第一次完整的回顾了我过去那么多年来的浑浑噩噩和偏执顽固。
-
-大概我的一切努力和挣扎只是为了让自己能好受一点，但却挣扎错了方向。我找了一块大石头，在上面刻了“我讨厌人类”几个大字，然后蹲在这个石头旁边逃避一切问题，以为这样就能过得轻松一点。但结果是我得天天生活在对失去我所喜欢的人事物的恐惧中，最让人恐惧的是那些人事物还真大多数都离开我了，简直让我想把它定义为“魔咒”这种在魔法位面才会有的东西。
-
-七月快结束的时候，我终于开始觉得我可能本来可以过上更好的生活，我本来可以留住那些我喜欢的人们，我本来可以不用眼睁睁地看着那些光芒散去。我并不算什么很有追求的人，我只是想过得好一点而已，那这又有什么难的。
-
-我本来以为自己多少还是留住了一些人，但认真想想，是他们顶着我身边那块相当不友好的大石头的压力，却依然没有离开。他们一边手把手教我怎么当个别那么宅那么丧那么邋遢那么难相处的正常人，一边让我有了“即使我永远也改不过来也依然有人喜欢我”的底气（当然也有可能是错觉 2333）。
-
-现在想来，即使我在过去的六七年里情绪状态为人处事社交技能都糟糕透顶，即使我负能量得高中大学都有人觉得我会去跳楼，即使我天天都在恐惧今天会不会又有什么离我而去，即使我连很多以前的朋友都不敢去联系，却还从来没有一次担心过有一天我头顶那片天空会彻底暗下去。
-
-我这种人居然会有这种自信，想想就觉得太奢侈了。
-
-这些话大概应该在毕业的那天就对那些在我身边或不在我身边的人们说出来，但那天大家都很开心，而按我的社交能力的正常水平大概率会搞砸开心的场面，于是还是啥也没说。
-
-那一天室友们抓着无数次表达过“我不喜欢照相”的我去照了毕业照，我得说她们相当英明，那大概是照破我的天灵盖的第一束曙光。
-
-原来只要我想开心，还是很容易就能开心起来的。
-
-（当然并没有我现在就喜欢照相了的意思
-
-
----
-
-
-唯一遗憾的只是错过了南门的那些樱花，
-
-和让你们在我最糟糕的时候认识了我。
-
-
----
-
-
-其他的改变大概就是些鸡毛蒜皮的事了，比如跟导师换到了一个贼理论的以前从没想过我会去碰的研究方向。老师似乎是个负能量终结者，经常跟我进行类似于“我要是想不出来 idea 该怎么办”“那你也就没有必要读研究生了”的对话。
-
-算了算了丧什么丧好好干活。
-
-比如去烫了头发，虽然很多人根本看不出来，只是觉得我的自然卷怎么换了种卷法，所以我可能烫了个寂寞。我想起初中时有朋友跟我说“我好羡慕你们自然卷的人，你们以后可以不用烫头发”。结果我烫头发还得先拉直再烫，花双倍的力气折腾。
-
-羡慕你个大头鬼，摔 （╯‘□′）╯╘═╛
-
-比如终于认识到了为什么 GitHub 被称为“社交平台”。
-
-比如溜出去玩的频率增加了很多，虽然很多时候只是“换了个地方宅着”，但还是有进步嘛有进步。
-
-比如终于开始看朋友圈了，虽然原定计划是三天至少看一次，但实际上经常一连半个多月都不想看，但还是有进步嘛有进步。
-
-再然后，很开心能够看到很多朋友们在 2020 的后期都开心了起来。我一直觉得那么丧的人有我一个就够了，但除了尬聊以外我也做不了什么，我要是能把你们推出去，我为啥不推我自己出去。2020 相当的 surreal，你们能在这一年里熬出头，是件非常不容易的事。
-
-我希望能成为一个在这种时候能做点什么事的温暖的人，虽然以我目前的水平，大概得先从一个正常一点的人开始做起。
-
-
----
-
-
-即使现在让我回到高中毕业时再选一遍，我可能依然不会选择来同济，我总无法摆脱“换个大学会不会就能过得更好一点”的想法。但对于我在这里收获到的认识到的一切，我依然心怀感激与敬意。
-
-人生总有各种奇奇怪怪遗憾和后悔，我大概也很难有那种绝不回望逝去的过往的境界。但我们的生命永远不会被拘囿与一时一地，这也是我们等待下去的动力。
-
-新年快乐朋友们。
-
-
----
-
-
-最后的最后，希望今年不要再失学了。
Index: blog/posts/2021-07-27-fisher-information-matrix.md
===================================================================
diff --git a/blog/posts/2021-07-27-fisher-information-matrix.md b/blog/posts/2021-07-27-fisher-information-matrix.md
deleted file mode 100644
--- a/blog/posts/2021-07-27-fisher-information-matrix.md	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
+++ /dev/null	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
@@ -1,113 +0,0 @@
----
-layout: Post
-title: Fisher 信息矩阵
-subtitle: Fisher Information Matrix
-author: Renovamen
-date: 2021-07-27
-headerImage: /img/in-post/2021-07-27/header.jpeg
-permalinkPattern: /post/:year/:month/:day/:slug/
-tags:
-  - Machine Learning
-  - Math
----
-
-Fisher 信息矩阵的数学意义和直观上的理解。
-
-<!-- more -->
-
-## 定义
-
-假设有一个似然函数 $p(x \mid \theta)$，为了求能让这个似然最大的 $\hat{\theta}$（最大似然估计），需要让它的对数似然函数的一阶导为 0，即：
-
-$$
-s(\theta) = \nabla \log p(x \mid \theta) = 0
-$$
-
-这个一阶导 $s(\theta)$ 被称为 score function。**Fisher 信息矩阵**（Fisher Information Matrix）的定义，就是这个 score function 的二阶矩（second moment）：
-
-$$
-F = \mathbb{E}_{p(x \mid \theta)} \Big [ s(\theta)^2 \Big ] = \mathbb{E}_{p(x \mid \theta)} \Big [ \nabla \log p(x \mid \theta) \nabla \log p(x \mid \theta)^{\top} \Big ]
-$$
-
-考虑监督学习的场景，模型为 $p_{\theta}(y \mid x)$，真实数据分布为 $p_D(y \mid x)$，那么上式可以写为：
-
-$$
-F = \mathbb{E}_{p_{\theta}(y \mid x)} \Big [ \nabla \log p_{\theta}(y \mid x) \nabla \log p_{\theta}(y \mid x)^{\top} \Big ]
-$$
-
-因为 $p_{\theta}(y \mid x)$ 是 intractable 的，所以在算这个分布时会用蒙特卡洛采样来近似。需要注意的是，反向传播算出来梯度是 $\nabla p_D(y \mid x)$，而在 true Fisher 中，$y$ 是从模型 $p_{\theta}(y \mid x)$ 中采样的，这时的 $\nabla \log p_{\theta}(y \mid x)$ 并不是我们在反向传播时算出来的梯度，而是需要额外计算。
-
-但在 empirical Fisher 中，上式变为了：
-
-$$
-F = \mathbb{E}_{p_D(y \mid x)} \Big [ \nabla \log p_D(y \mid x) \nabla \log p_D(y \mid x)^{\top} \Big ]
-$$
-
-即 $y$ 是从直接数据分布 $p_D(y \mid x)$ 中采样的，这时就可以直接使用反向传播算出来的梯度，从而减小计算量。当数据量足够大，模型已经可以很好地拟合数据分布时，empirical Fisher 和 true Fisher 的差距不会很大。
-
-
-
-## 数学意义
-
-### Score Function 的方差
-
-::: info 断言
-Fisher 信息矩阵就是 score function 的方差
-:::
-
-::: tip 证明
-首先可以证明的是 score function 的期望为 0，即：
-
-$$
-\mathbb{E}_{p(x \mid \theta)} [ s(\theta) ]^2 = 0
-$$
-
-证明过程可以参考博客 [Fisher Information Matrix](https://wiseodd.github.io/techblog/2018/03/11/fisher-information/)。
-
-所以有：
-
-$$
-\begin{aligned}
-  Var[s(\theta)] &= \mathbb{E}_{p(x \mid \theta)} [ s(\theta)^2 ] - \textcolor{blue}{\underbrace{\mathbb{E}_{p(x \mid \theta)} [ s(\theta) ]^2}_{=0}} \\
-    &= \mathbb{E}_{p(x \mid \theta)} [ s(\theta)^2 ] \\
-    &= F
-\end{aligned}
-$$
-:::
-
-对这个方差的直观理解可以为：
-
-对两组相互独立的随机变量 $X, Y$，有：
-
-$$
-Var(X + Y) = Var(X) + Var(Y)
-$$
-
-也就是说当收集到的数据越来越多，方差就会变得越来越大。所以 Fisher 信息矩阵越大，说明 score function 的方差越大，也就说明得到的信息越来越多。
-
-这个理解来源于：[[知乎] 费雪信息的直观意义是什么？- Detian Deng 的回答](https://www.zhihu.com/question/26561604/answer/33275982)
-
-
-### 海森矩阵的期望
-
-::: info 断言
-Fisher 信息矩阵等于对数似然函数的海森矩阵（Hessian Metrix）的期望取负，即：
-
-$$
-F = - \mathbb{E}_{p(x \mid \theta)} \Big [H_{\log p(x \mid \theta)} \Big ]
-$$
-:::
-
-::: tip 证明
-参考博客 [Fisher Information Matrix](https://wiseodd.github.io/techblog/2018/03/11/fisher-information/)
-:::
-
-也就是说，$F$ 反映了对数似然函数在参数真实值处的曲率。对于一个对数似然函数，它的曲率越小，说明它越平而宽，从而说明我们对于参数的估计越不确定（因为平而宽的对数似然函数意味着，观测值出现的概率并不比其他值出现的概率大多少）；曲率越大，说明它越高而窄，则说明对于参数的估计越确定。
-
-换句话说，$F$ 反映了我们对于参数估计的不确定度。
-
-
-## 参考
-
-- [[博客] Fisher Information Matrix](https://wiseodd.github.io/techblog/2018/03/11/fisher-information/)
-- [[知乎] 费雪信息 (Fisher information) 的直观意义是什么](https://www.zhihu.com/question/26561604)
Index: blog/posts/2018-09-01-p-value.md
===================================================================
diff --git a/blog/posts/2018-09-01-p-value.md b/blog/posts/2018-09-01-p-value.md
deleted file mode 100644
--- a/blog/posts/2018-09-01-p-value.md	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
+++ /dev/null	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
@@ -1,61 +0,0 @@
----
-layout: Post
-title: p-value
-subtitle: Something about p-value
-author: Renovamen
-date: 2018-09-01
-headerImage: /img/in-post/2018-09-01/header.jpeg
-permalinkPattern: /post/:year/:month/:day/:slug/
-tags:
-  - Math
----
-
-一个例子：一个正常的硬币，在被投掷无数次后，结果一定会是正面朝上和反面朝上各占 50%。如果想要知道一个硬币是否正常，是否被做过手脚，显然是没办法投掷无数次的。因此，只能用有限的结果来判断“该硬币是否正常”。
-
-<!-- more -->
-
-
-## P值 (p-value)
-
-在统计学上，通常会设定一个虚无假设（零假设，Null Hypothesis），记作 $H_0$。和一个与虚无假设对立的对立假设（Alternative Hypothesis），记做 $H_1$。如果证明虚无假设错误，则可以推出对立假设成立。
-
-本例中：
-- $H_0$ : 该硬币是正常硬币
-- $H_1$: 该硬币被做过手脚
-
-
-p-value：错误拒绝（reject）$H_0$ 假设的概率，即 $H_0$ 事实上成立，但我们计算出的结果却错误判断虚无假设不成立的概率。
-
-## 卡方 (chi-square)
-
-我们认为该硬币是正常硬币，因此我们对于投掷 10 次硬币的期望值 (expected value) 是正面 5 次，反面 5 次。而实际结果是正面 3 次，反面 7 次，这个结果就是我们对于投掷 10 次硬币的观测值（observed valued）。
-
-通过分析期望值和观测值的差距，就可以判断出硬币是否正常，而这个期望值和观测值差距的判断方法就是 chi-square，公式为：
-
-$$
-x^2 = \sum_{i=1}^{n} \frac{(O_i-E_i)^2}{E_i}
-$$
-
-$O$ 为观测值，$E$ 为期望值。可以看到该公式与方差很相似，方差是一组数据与其均值的比较，而 chi-suaqre 是一组数据与另一组数据期望值的比较。
-
-本例中，$\text{chi-square} = \frac{(3-5)^2}{5} + \frac{(7-5)^2}{5} = 1.6$
-
-
-## 卡方分布 (chi-square distribution)
-
-![](/img/in-post/2018-09-01/chi-square-distribution.png)
-
-上图为卡方分布表，$\alpha$ 为错误拒绝 $H_0$ 假设的概率，$n$ 为自由度，即独立变量数减 1。本例中，独立变量数为 2（正面和反面），所以自由度 $n = 1$。
-
-当置信度为 95%，即错误拒绝 $H_0$ 的概率为 0.05，意义就是我们有95%的概率确信检验结果正确，有 5% 的概率会错误拒绝虚无假设。（所以大多数时候用 $\text{p-value}<0.05$ 来判断结果是否靠谱，当然根据情况也可以不用 0.05）
-
-本例中，对照着卡方分布表，找到 $n = 1$ 所在的行，发现 1.6 介于 1.323 和 2.706 之间，查出其 p-value 介于 0.25 到 0.1 之间，大于 0.05。所以我们不能拒绝 $H_0$，即 $H_0$ 成立，该硬币是正常硬币。
-
-可以看到，当自由度相同，chi-square 越大，其 p-value 越小。因为如果观测值与期望值越一致，则说明检验现象与 $H_0$ 越接近，则越没有理由拒绝 $H_0$。如果观测值与期望值越偏离，说明 $H_0$ 越站不住脚，则越有理由拒绝 $H_0$，从而推出对立假设的成立。
-
-一个极端的例子，如果掷 10 次硬币，刚好 5 次正面朝上 5 次反面朝上，此时 $\text{chi-square} = 0$，p-value 远大于 0.095，没有理由拒绝 $H_0$，即 $H_0$ 成立，该硬币是正常硬币。
-
-## 总结
-做出 $H_0$，$H_1$ 这对互斥的假设，计算出 $H_0$ 为真时的期望值和实际观测值，通过期望值和观测值求得 chi-square，再通过查卡方分布表得到 p-value，然后将 p-value 与 $\alpha$（1 - 置信度）比较，如果 $\text{p-value} < \alpha$，则拒绝 $H_0$，推出 $H_1$ 成立，否则接受（accpet）$H_0$，推出 $H_1$ 不成立。
-
-大部分时候 p-value 用于检验独立变量与输入变量的关系，$H_0$ 假设通常为假设两者没有关系，所以若 $\text{p-value} < 0.05$，则可以推翻 $H_0$（两者没有关系），推出 $H_1$（两者有关系），我们就说这个独立变量重要（significant），因为这个独立变量与输出结果有关系。
Index: blog/posts/2021-01-28-lets-talk-about-pytorch.md
===================================================================
diff --git a/blog/posts/2021-01-28-lets-talk-about-pytorch.md b/blog/posts/2021-01-28-lets-talk-about-pytorch.md
deleted file mode 100644
--- a/blog/posts/2021-01-28-lets-talk-about-pytorch.md	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
+++ /dev/null	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
@@ -1,220 +0,0 @@
----
-layout: Post
-title: 凌乱的 PyTorch 笔记
-subtitle: PyTorch 能有什么坏心思呢
-author: Renovamen
-date: 2021-01-28
-headerImage: /img/in-post/2021-01-28/header.jpg
-useHeaderImage: true
-headerMask: rgb(30, 77, 121, .3)
-permalinkPattern: /post/:year/:month/:day/:slug/
-tags:
-  - Deep Learning
----
-
-记录一些 PyTorch 的细节。
-
-<!-- more -->
-
-## 名不符实的损失函数
-
-### NLL Loss
-
-`nn.NLLLoss`，自称实现的是 Negative Log Likelihood Loss，理论上应该是：
-
-$$
-\ell (x, y) = \{ \ell_1, \dots, \ell_N \}, \text{ where } \ell_n = - \log x_{n, y_n}
-$$
-
-但[文档](https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html)上同样也自称了，它实现的其实是：
-
-$$
-\ell_n = - x_{n, y_n}
-$$
-
-是的 log 仅仅只存在于函数名里 (╯‵□′)╯︵╧═╧
-
-### Cross Entropy Loss
-
-`nn.CrossEntropyLoss`，理论上的交叉熵应该是：
-
-$$
-L = - \sum_{i}^C y_i \log p_i
-$$
-
-其中 $y$ 是实际类别，$p$ 是预测类别。但[文档](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)上同样也说了，它实现的其实是 `nn.LogSoftmax()` + `nn.NLLLoss()`，即：
-
-$$
-L = - \sum_{i}^C y_i \cdot \text{LogSoftmax} (p_i)
-$$
-
-所以不能在用 `nn.CrossEntropyLoss` 前再手动 softmax 一次，不然就是两次 softmax 了，要出大问题。
-
-
-## 不明觉厉的优化器实现
-
-### Momentum
-
-Momentum 的介绍可以参考[这里](/post/2020/07/10/messy-notes-nlp/#一阶动量)。首先，PyTorch 的 [momentum 实现](https://github.com/pytorch/pytorch/blob/7a8c64da4d93fef5986aee5ada59289b5387cf8e/torch/optim/functional.py#L143)是：
-
-$$
-v_t = \rho v_{t-1} + \nabla L(\theta_t)
-$$
-
-$$
-\theta_{t+1} = \theta_t - r \cdot v_t
-$$
-
-而不是：
-
-$$
-v_t = \rho v_{t-1} + r \cdot \nabla L(\theta_t)
-$$
-
-$$
-\theta_{t+1} = \theta_t - v_t
-$$
-
-学习率是要跟整个动量相乘，而不是只乘梯度，Polyak's Momentum 和 Nesterov's Momentum 都是如此。
-
----
-
-然后，Nesterov's Momentum 的公式是：
-
-$$
-v_t = \rho v_{t-1} + \nabla L(\theta_t - r \rho v_{t-1})
-$$
-
-$$
-\theta_{t+1} = \theta_t - r \cdot v_t
-$$
-
-它的思想是，先假设当前参数点 0 按上一次的动量多更新一步到点 1（下图的棕色箭头），然后在更新后的参数 $\theta'_t = \theta_t - r \rho v_{t-1}$ 上算梯度 $\nabla L(\theta'_t)$（红色箭头），用这个梯度来算这一次的动量 $v_t$（绿色箭头），最后用这个动量来真正的更新当前参数点 0 到点 2。
-
-![Hinton's example](/img/in-post/2021-01-28/nesterov-momentum-hinton.png)
-
-<p class="desc">图片来源：<a href="https://stats.stackexchange.com/questions/179915/whats-the-difference-between-momentum-based-gradient-descent-and-nesterovs-acc" target="_blank">What's the difference between momentum based gradient descent and Nesterov's accelerated gradient descent?</a></p>
-
-可以看到，$\theta$ 和 $\nabla L(\theta)$ 是不需要关注的，我们没有必要 $0 \rarr 1 \rarr 0 \rarr 2 \rarr 3$，我们可以直接把 $\theta'$ 和 $\nabla L(\theta')$ 作为目标，即直接 $1 \rarr 2 \rarr 3$，$1 \rarr 2$ 是在更新参数，$2 \rarr 3$ 相当于是每一步都多更新一步，就不用再假设和回退了。
-
-那么令 $\theta_t' = \theta_t - r \rho v_{t-1}$，则有：
-
-$$
-v_t = \rho v_{t-1} + \nabla L(\theta_t') \tag{1}
-$$
-
-$$
-\begin{aligned}
-   \theta_{t+1}' &= \theta_{t+1} - r \rho v_t \\
-    &= \theta_t - r \cdot v_t - r \rho v_t \\
-    &= \theta_t' + r \rho v_{t-1} - r \cdot v_t - r \rho v_t \\
-    &= \theta_t' - r \nabla L(\theta_t') - r \rho v_t \\
-    &= \theta_t' - r \cdot \Big (\nabla L(\theta_t') + \rho v_t \Big )
-\end{aligned}  \tag{2}
-$$
-
-$- r \cdot \nabla L(\theta_t')$ 是 $1 \rarr 2$，$- r \rho v_t$ 是 $2 \rarr 3$。
-
-包括 PyTorch 在内的深度学习框架的实现基本就是按照公式 $(1)$ 和 $(2)$ 来的，我把源码复制过来：
-
-```python{13,17,21}
-for i, param in enumerate(params):
-    d_p = d_p_list[i]
-    # l2 正则化
-    if weight_decay != 0:
-        d_p = d_p.add(param, alpha=weight_decay)
-    if momentum != 0:
-        buf = momentum_buffer_list[i]
-        if buf is None:
-            buf = torch.clone(d_p).detach()
-            momentum_buffer_list[i] = buf
-        else:
-            # v_t = rho * v_{t-1} + delta L(theta'_t)
-            buf.mul_(momentum).add_(d_p, alpha=1 - dampening)
-        # nesterov's momentum
-        if nesterov:
-            # delta L(theta'_{t+1}) = delta L(theta'_t) + rho * v_t
-            d_p = d_p.add(buf, alpha=momentum)
-        else:
-            d_p = buf
-    # theta'_{t+1} = theta'_t - lr * delta L(theta'_{t+1})
-    param.add_(d_p, alpha=-lr)
-```
-
-`buf` 是 $v_t$，`d_p` 是 $\nabla L(\theta_t')$，`alpha` 是动量参数 $\rho$，`lr` 是学习率 $r$。
-
-
-## 奇奇怪怪的初始化器
-
-### Kaiming Init
-
-PyTorch 中，linear 层和 conv 层的默认 init 是 kaiming init：
-
-**Delving Deep into Rectifiers: Surpassing Human-level Performance on ImageNet Classification.** *Kaiming He, et al.* ICCV 2015. [[Paper]](https://arxiv.org/pdf/1502.01852.pdf)
-
-但这两个地方都给了一个奇怪的参数：
-
-[`nn/modules/linear.py`](https://github.com/pytorch/pytorch/blob/7a8c64da4d93fef5986aee5ada59289b5387cf8e/torch/nn/modules/linear.py#L86) / [`nn/modules/conv.py`](https://github.com/pytorch/pytorch/blob/7a8c64da4d93fef5986aee5ada59289b5387cf8e/torch/nn/modules/conv.py#L111)
-
-```python{2}
-def reset_parameters(self) -> None:
-    init.kaiming_uniform_(self.weight, a=math.sqrt(5))
-    if self.bias is not None:
-        fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)
-        bound = 1 / math.sqrt(fan_in)
-        init.uniform_(self.bias, -bound, bound)
-```
-
-`a` 这个参数看上去非常的奇怪，因为 PyTorch 在[文档](https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.kaiming_uniform_)里说参数 `a` “only used with leaky_relu”。
-
-`a` 代表的是 Leaky ReLU 函数 $x < 0$ 部分的斜率 negative slop。在用 kaiming uniform init 时，PyTorch 会根据这个 negative slop 算一个放缩因子 `gain` 出来（[文档](https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.calculate_gain)）：
-
-$$
-\text{gain} = \sqrt{\frac{2}{1 + \text{negative\_slop}^2}}
-$$
-
-然后 kaiming uniform 的边界为：
-
-$$
-\text{gain} \cdot \sqrt{\frac{3}{\text{fan\_in}}}
-$$
-
-如果用别的激活函数，就不该有 negative slop 这个参数，`gain` 也会用别的公式计算，但 PyTorch 就是给你搞了一个 `a = sqrt(5)` 的奇怪的默认值。
-
-这个问题在这两个地方有解释：
-
-- [Kaiming init of conv and linear layers, why gain = sqrt(5)](https://github.com/pytorch/pytorch/issues/15314)
-- [Why the default negative_slope for kaiming_uniform initialization of Convolution and Linear layers is √5?](https://discuss.pytorch.org/t/why-the-default-negative-slope-for-kaiming-uniform-initialization-of-convolution-and-linear-layers-is-5/29290)
-
-PyTorch 的 init 进行过一次重构（[pr #9038](https://github.com/pytorch/pytorch/pull/9038)），重构前 linear 和 conv 的默认 init 是：
-
-```python
-def reset_parameters(self):
-    stdv = 1. / math.sqrt(self.weight.size(1))
-    self.weight.data.uniform_(-stdv, stdv)
-    if self.bias is not None:
-        self.bias.data.uniform_(-stdv, stdv)
-```
-
-重构之后才开始用 kaiming init。但为了保证向后兼容，他们希望重构前后的默认 init 的输出是等价的。重构前的均匀分布边界是（`self.weight.size(1)` 就是 `fan_in`（输入节点数量））：
-
-$$
-\frac{1}{\sqrt{\text{fan\_in}}}
-$$
-
-因此为了让重构前后的边界等价：
-
-$$
-\begin{aligned}
-   \frac{1}{\sqrt{\text{fan\_in}}} &= \text{gain} \cdot \sqrt{\frac{3}{\text{fan\_in}}} \\
-    &= \sqrt{\frac{6}{\text{fan\_in} \cdot (1 + \text{negative\_slop}^2)}} \\
-\end{aligned} 
-$$
-
-$$
-\rArr \text{negative\_slop} = \sqrt{5}
-$$
-
-所以这个 `a = sqrt(5)` 的奇怪的默认值就是这样来的，不是什么推荐值，只是为了保证向后兼容而强行设的而已...
-
-为什么我写了那么大一段话来解释这个无聊的结论...
Index: blog/posts/2019-07-06-last-three-years.md
===================================================================
diff --git a/blog/posts/2019-07-06-last-three-years.md b/blog/posts/2019-07-06-last-three-years.md
deleted file mode 100644
--- a/blog/posts/2019-07-06-last-three-years.md	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
+++ /dev/null	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
@@ -1,73 +0,0 @@
----
-layout: Post
-title: 对过去三年的碎碎念
-subtitle: 像样的麻婆豆腐是这个令人讨厌的世界上的唯一的光
-author: Renovamen
-date: 2019-07-06
-useHeaderImage: true
-headerImage: /img/in-post/2019-07-06/header.jpg
-headerMask: rgb(119, 145, 168, .2)
-permalinkPattern: /post/:year/:month/:day/:slug/
-tags:
-  - 摸鱼
----
-
-封面图是《塞尔达传说：荒野之息》里的利特族族长 Kaneli，来自 [@wroage (tumblr)](https://wroage.tumblr.com/image/185206416422)。利特族真是一个毛茸茸的好族。
-
-<!-- more -->
-
----
-
-我的游戏机（之一）死掉了，大概上学期就发现它死掉了。
-
-三年的浑浑噩噩足够耗掉一个 3DS 的生命。嗷不，不管是浑浑噩噩还是兢兢业业的三年都会耗掉它的生命，而只有浑浑噩噩的三年会耗掉我的生命。
-
-答完软测后室友找了个店试图修好她的 Switch，并顺便把我的 3DS 也带了过去。老板接下了 Switch，但对于 3DS，他说：“要是再早两年，我可能还知道怎么修这机子。”
-
-呜呜呜我还是来得太晚了你还是离我而去了呜呜呜…（？？？
-
-谨以这条大一时发的说说来纪念它：
-
-<img src="/img/in-post/2019-07-06/3ds.jpg" width="400px" alt="GRU" />
-
-同样离我而去的还有那些进城的人们，向往诗和远方的人类总会离开他们注定要离开的地方。而我对诗和远方并没有什么向往，如果全世界都是眼前的苟且，并且城里的苟且对我来说并没有太大的吸引力，那不如在嘉大荒苟且完第三年 —— 我抱着我床上的显示器游戏机手柄和还没通关的游戏这样说。
-
-大一结束搬去嘉定后买了 PS4 和显示器，并把它们都安在了我的床上。于是整整两年我都在思考等到大四要搬回本部的时候我该拿它们怎么办，都搬过去太折腾，杂牌显示器和二手 PS4 看起来也不像能卖出去的样子，贫穷如我更不可能把他们扔掉。这种思考一直到这学期宅且懒一点也不想折腾的我知道了也可以选择不搬回去并决定大四留在嘉定后才停止。
-
-虽然可以晚一年再处理我的游戏机和显示器了，但也并没有感觉很解脱，毕竟有的人真的就离开我了。
-
-除了失去的东西，还有些东西是从来没有出现过的。昨天才想起好像在我读大学的这三年里，江南还没出过新书。龙族没出，天之炽没出，西泽尔他们依然还坐在狮心骑士团团长（兼公主）的敞篷礼车上奔赴战场。高中的时候我会第一时间溜出去买新书，书店老板看到我买了“跟学习无关的书”还会特意找不透明的袋子来装以免被老师看到，而我会一边盯着那只贼肥的永远在收银台上睡觉的橘猫大爷一边回忆它三个月前很小很毛茸茸贼喜欢拿头蹭你的样子，脑子里一阵恍惚。当时还想进了大学之后要在哪里买书来着，结果江南老贼压根就不出书（上天保佑上海堡垒别崩球球了（2019.8 补充：好吧还是崩了，崩得比我想象中还惨得多））。    
-
-那句“因为你们不喜欢这个世界，而我也不喜欢”大概是我最大的社交动力。我希望有一天我能对某个人说出这句话，不过想来我连我自己都不喜欢，大概也不会喜欢跟我一样不喜欢这个世界的人。
-
-既然连我都这样，那那些站在光芒中的家伙到底都喜欢什么样的人啊。
-
-于是三年就这样过去了。鹩哥从六岁的老年鸟变成了九岁的老年鸟，它看起来身体非常硬朗，但似乎还停留在更年期，一天到晚活蹦乱跳脾气暴躁吃的贼多。鹦鹉一点点的变得健壮然后体重固定在了 63 克（然而上次回家的时候它似乎长肥到了 66 克），性格越来越嚣张，会咬我扯我头发在我舒服的被子上翻滚，鬼知道我不在的时候它会怎么对我的床。生活带给它的唯一的坎是它跟楼下的鹦鹉隔空吵架吵输了（我猜是输了），郁闷了好长一段时间，于是那段时间都只听得到楼下鹦鹉嚣张的嘹叫。我还是没能吃掉它，剩下的这一年大概也不能了。
-
-同样没能做到的事情还有很多，比如至今没在上海找到过像样的麻婆豆腐（2020.1 补充：在实习公司周围的一家食其家找到了勉强像样的麻婆豆腐，真是神奇的日料快餐店），在重庆以外吃到过的最像样的麻婆豆腐还是区域赛时在西安西工大旁吃的那家川菜馆（只有这句话与题目有关）。比如高中时就想着进了大学以后要找个心理医生看看，然而因为懒且宅和不想跟医生说我在想啥至今没去。比如希望进了大学之后能不那么糟糕一点，然而虽然的确不那么糟糕了一点，但也并没有不糟糕多少，于是身边的人依然得忍受我高频率的情绪失控。所以每次生日都会在心里感谢一遍在过去的一年里没有把我打包送进宇宙监察总局给外星人做实验的善良的朋友们，然后在新的一年里又继续频繁的失控。
-
-那么我为啥会那么糟糕呢？人类在思考这个问题的时候总是会为自己找理由，找理由的时候就会去回忆自己过去的经历。有的时候想想我小学的时候常常被某个同学推在地上用脚踩在脸上殴打，而我每次被打完甚至都没有想过要告诉老师和家长，而是用“我摔了一跤”这种理由糊弄过去，实在想不通这是为什么，但不管怎么说这至少能说明校园暴力还真不是个好解决的事。而突然开始感到愤怒感到暴躁感到“我想把那个当时那个欺负我的女生揍一顿”已经是几年之后了，那个时候我对自己的格斗能力充满了自信，毕竟已经在跆拳道馆~~被~~跟各种身强力壮的大佬~~单方面揍了几年~~打了几年架，然而那个女生已经不再欺负我了（难道是因为我长得比她还高了？笑），甚至天天对我作出一副“我们不是好朋友吗”的样子，所以我实在找不到理由去揍她了，那种感觉真是憋屈愤懑而又无可奈何。
-
-值得欣慰的是我初中过得相当的平淡，冲散了快要崩溃的情绪，算是把我往奇奇怪怪的方向发展的势头拉了回来...再然后我就在高中遭遇了当头一棒。高中过得挺憋屈的，这种憋屈把初中的平淡又冲得一干二净。很多时候都处在怀疑自己能不能熬到高考那一天的焦虑之中，毕竟高二的时候就有人对我说过「我觉得你高三会去跳楼」。我脑子里一片空白，心里毫无波动，毕竟比这更神奇的话我也听过不少。我大概不算是一个讨人喜欢的人，可我也不想去跳楼，于是我无所事事浑浑噩噩，这反而成了一种幸福。虽然这样的浑浑噩噩只能让我不断想起以前的自己，那时候我觉得自己天下无敌，我有要点燃世界的理想，我有要走南闯北的嚣张。
-
-而我现在是一个只想过得稍微舒服一点的死宅。
-
-可要是不为自己找理由呢？那唯一的原因就只剩我太废物这一点了。所有的过去都不能成为你现在浑浑噩噩的理由，道理的确是这个道理，可废物的我的确没有做到。大学的浑浑噩噩对我来说算是早就预料到的事，高三的时候我一边希望自己能理智的撑到高考一边想象进大学之后的最坏情况，值得庆幸的是我的状态离当时想象的最坏情况还是有那么点距离。虽然再废物的人也是想好好生活的，再丧的人心里也总是有一丝“说不定以后就会好起来”的侥幸的，但控制自己行为的浅层思想的阴影也是永远能掩盖内心深处那个想骑着名为绝影的宝马跑赢时光的自己的。于是我只能清醒地看着自己一点点按照早就猜到的轨迹坠落下去，任凭心里的不甘疯狂生长。
-
-我似乎从来没有对任何技能有过“好想学会”的热情，那种热情真实学都学不来（等等听起来我似乎对学习“学某项技能的热情”挺有热情的，这似乎是一个悖论）。大学前两年在垒球队里训练，棒垒球大概是少年漫里最热血的运动，热血也的确流淌在我队友们的身体里，但我只是茫然的看着球从天上划过，全垒打对我来说也不过只是划得更远一些的球。随着时间的流逝我越来越觉得我格格不入，加上我越来越懒越来越宅不想嘉定四平往返跑，并且因为几乎不参与社交导致后来不太能融入队伍，于是大二后期开始就没再去训练过了。高中的时候竞赛教练问我大学想学啥，我说不会学计算机相关专业，也真是不怕伤教练的心。这个世界上多的是热爱和擅长写代码的人，但我不会是那些人之一，这是我高中时宁愿坐在竞赛教室里的电脑前玩扫雷也不愿意多敲两行代码多看两道题多学两个新算法的时候就知道的事。当时学竞赛只是为了给成绩不好找个理由，填志愿时选择软件工程也只是因为高考成绩和觉得写代码不是一个没有热情和天分就会饿死的行业。黑夜下的键盘声在我听来格外刺耳，每一声都在提醒我与这里格格不入，但我也不能离开这里，因为我跟哪里都格格不入。那么支撑我大学前半段的主要动力大概就是那些不甘了吧？不甘心自己的能力配不上不可一世的内心。但似乎这些不甘似乎并没有转化成多少努力，何况把不甘这种扭曲的东西作为动力实在是太过痛苦和危险。比如明知道这世界上是个稍微努力点的人大概都比我这种废物强，但看到他们的成就的时候依然会难受，于是就天天难受，一难受就别扭，一别扭就会失去他们。
-
-想来我大一最重要的成就大概就是把写代码缩进俩空格的神奇强迫症改成了缩进一个 Tab 的正常强迫症，不然以后写 Python 得哭死。大三的最重要成就应该是培养了良好（？？？）的文档排版强迫症。大二啥成就都没有，那一年在我浑浑噩噩的三年里都算是最浑浑噩噩的一年。失控的时间比不失控的时间多，状态大概处于高二和高三之间。开始正式的肥宅了起来，虽然还会跑去本部打球但身体素质还是差了不少，800 米成绩比大一慢了一分钟（虽然一定程度上是因为没有体育课的绩点压力）。绩点崩得一塌糊涂，上课听不进去，考前复习不进去，宁愿睁着眼睛想“我这门课凉了”想到凌晨四点也不会翻开书看两页，这还是在我早就决定要出国的情况下。这个习惯还蔓延到了现在，所以这学期没考试真是谢天谢地。脑子里动不动就开始想逃避的方法，留级休学转专业强化班之类莫名其妙的东西，不过最多想五秒钟就不会想了，一是这些莫名其妙的东西总得过家里人，而他们至今都还以为我是热爱写代码的有理想的好少年；二是觉得根本没法逃避，我不管在哪都会是这副德行，那不如得过且过。
-
-一切都似曾相识，发生过的事又在自己身上发生了一遍，杀不死我的也并没有让我更坚强，让我哭过的事我还是没法笑着说出来，这些鸡汤也并不能救我这条咸鱼。不过一天到晚把本该学习的时间都用去胡思乱想还是想通了不少事，至少那些奇奇怪怪的不甘心基本上消失了。虽然这同时也意味着我大二以后基本上失去了唯一的动力来源，变成了一个开心一些的彻底的咸鱼...不过至少在真的认识了一直想认识的人的时候，没有因为那些不甘心而失去她（虽然我觉得总有一天会因为我的别的什么弱点而失去她就是了 2333）（2020.7 补充：我真是个预言家，为啥要立这个 flag...）。还有一些本该学习的时间被用去追星了，偶像根本不需要做什么，她就在站在那个高高的地方发着光，深渊里的你就会想“她真美啊，我得爬上去看看”。
-
-我依然还是一个浑浑噩噩的人，可我们的生命永远不会被拘囿于一时一地，想要生存于世的有理想和没理想的人类都得有走下去的动力。我在我的 [Web 项目](https://galaxy.zxh.io)首页上放了一句话：*It is not easy to be a voyager, but we still want to leave*，虽然这跟尖叫鸡游戏扯在一起有点牵强......我这样没理想的人也会有想要离开的地方，这里的苟且跟那里的苟且也总还是不一样。每天在外面游荡和下课了去外面趴着栏杆发呆是我一直保留到了现在的习惯，就算是漫无目的的游荡，人类也总是趋向于游荡向更远的地方。我趴在栏杆上发呆时，想象过慢镜头下的我从天井式的楼里坠落，从顶楼到底楼的人们一层一层的从房间里出来冷漠的环绕着天井围观，风声在我耳边呼啸，寂静中的暴雨沿着四周的玻璃流淌如瀑布......但我总会在落地前的一刻清醒过来。
-
-我大概真的不想落地。
-
-祝各位一路顺风，感谢你们。
-
----
-
-好的，把碎碎念写得负能量不那么多的尝试又失败了呢。(╯‵□′)╯︵╘═╛
-
-而且虽然题目是过去三年的碎碎念，但似乎念了不止三年的时光...
Index: blog/posts/2018-11-30-dynamo.md
===================================================================
diff --git a/blog/posts/2018-11-30-dynamo.md b/blog/posts/2018-11-30-dynamo.md
deleted file mode 100644
--- a/blog/posts/2018-11-30-dynamo.md	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
+++ /dev/null	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
@@ -1,251 +0,0 @@
----
-layout: Post
-title: "Dynamo 论文总结"
-subtitle: 'Note about Dynamo'
-author: Renovamen
-date: 2018-11-30
-headerImage: /img/in-post/2018-11-30/header.jpg
-permalinkPattern: /post/:year/:month/:day/:slug/
-tags:
-  - 分布式
----
-
-阅读论文 [Dynamo: Amazon’s Highly Available Key-value Store](https://link.jianshu.com/?t=http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf) 后的一些总结。
-
-<!-- more -->
-
-
-## 1. Background
-
-Dynamo 是 Amazon 开发的分布式存储系统，它在 Amazon 所处的应用环境中面对的问题和场景：
-- 大多数场景并不需要复杂的查询功能；
-- 由于使用商用机作为服务器，机器或网络失败将成为相对常见的场景，需要妥善处理；
-- 为了提供良好的用户体验，服务需要极高的可用性和较好的性能；
-- 随着业务量逐步增大，服务的处理能力也需要平滑提升
-
-在其他很多互联网业务中也适用。
-
-针对上述背景，Dynamo 的基本定位：
-- 仅提供简单的 key-value 查询
-- 高可用性
-- 易扩展性
-
-因此 Dynamo 在设计中会舍弃掉许多负担，如关系型数据库复杂的查询模型、对 ACID 的支持，对强一致性的追求，以及复杂的存储结构等。同时，Dynamo 认为其面对的是相对安全的内部网络环境，所以并没有处理安全或权限问题。
-
-
-## 2. Introduction
-
-- 客户端使用 put、get 接口读写指定 key 所对应的数据；
-- 将整个数据空间划分为不同分片后存储在不同节点上；
-- 通过分片复制和一系列故障发生时的应对方案来保证整个服务的高可用性；
-- 为了可用性损失了一些一致性，可能发生的数据冲突有可能需要应用程序处理；
-- 去中心化的维护整个集群的成员及故障信息，并用 gossip 同步。
-
-
-## 3. System Architecture
-
-### 3.1 System Interface
-
-将对象与 key 相关联：
-
-- `get(key)`：定位与 `key` 关联的对象副本，并返回一个对象或一个包含冲突版本和对应上下文的对象列表。上下文信息与对象一起存储，以便系统可以验证请求中提供的上下文的有效性。
-
-- `put(key, context, object)`：基于对象（`object`）的 `key` 决定将对象的副本放在哪，并将副本写入到磁盘。`context` 包含对象的系统元数据且对调用者不透明，包括对象的版本信息等。
-
-
-### 3.2 数据分片（Partitioning）
-
-为了更好更灵活的操作管理存储的数据，考虑对数据空间进行分片并将分片分配到不同存储机器。Dynamo 采用类似一致性哈希的方式进行分片的划分和分配。关于数据分片的算法，Dynamo 经历了几个阶段的选择和进化：
-
-1. 传统的一致性哈希：将机器节点随机对应在哈希环（hash ring）上，数据 key 所对应的哈希值所在位置沿一致性哈希环顺时针遇到的第一个节点负责自己所在的 range。
-
-   - 优点：新节点加入，或旧节点退出时，只影响紧相邻的下一个节点
-   - 缺点：负载不均匀，且没有考虑到不同的机器性能的不同
-
-    &nbsp;
-
-	考虑节点的变动：
-  ![](/img/in-post/2018-11-30/cache-change.png)
-
-2. 增加虚拟节点（virtrual nodes）的一致性哈希：每个机器节点对应哈希环上的多个虚拟节点，可以根据机器性能方便的调节所负责的虚拟节点数。数据 key 所对应的哈希值所在位置沿一致性哈希环顺时针移动遇到的前 $N$ 个节点负责自己所在的 range（论文讨论的就是这种策略）。
-
-    - 优点：充分考虑机器性能的不同且可以做到负载均衡
-    - 缺点：分片转移时，实现上需要对整个 range 进行遍历；加入或删除节点时 Merkle tree 需要重新计算
-
-    <img src="/img/in-post/2018-11-30/strategy1.png" width="300px" alt="strategy1" />
-  
-    $A$，$B$，$C$ 为三个独立的节点，是 key $k_1$ 在一致性哈希环上的首选列表。阴影部分表示 $A$，$B$，$C$ 负责的 range。
-
-    &nbsp;
-
-    考虑虚拟节点：
-      ![](/img/in-post/2018-11-30/virtural-node.png)
-
-3. 数据空间等分 $Q$ 份，$T$ 个机器节点时，每个机器分得 $S$ 个分片，其中 $Q=T \times S$
-
-    - 优点：分片固定大小，可对应单个文件，因此容易加入或删除节点，且容易备份。
-
-    <img src="/img/in-post/2018-11-30/strategy2.png" width="300px" alt="strategy2" />
-
-
-### 3.3 分片备份（Replication）
-
-为了系统的高可用性，Dynamo 的每个分片都有 $N$ 个副本，存储在哈希环上顺时针方向的 $N$ 个节点上。这 $N$ 个节点称为该数据的 **preference list**。其中的每一个节点都可以对接受针对该数据的操作请求。
-
-<img src="/img/in-post/2018-11-30/replication.png" width="450px" alt="replication" />
-
-<p class="desc">对于key K : preference list = B, C, D</p>
-
-
-**Coordinator 协调器**：每个 key 被分配到一个 coordinator 节点，coordinator 节点复制这些 key 到环上顺时针方向的 $N-1$ 个后继节点。这样的结果是，系统中每个节点负责环上的从其自己到第 $N$ 个前继节点间的一段区域。
-
-考虑节点故障：preference list 可以包含超过 $N$ 个节点。其他的节点可以是这个环上的，也可以时其他数据中心的，可以根据需要配置。
-
-考虑虚拟节点：由于使用了虚拟节点，key 的前 $N$ 个后继位置可能属于少于 $N$ 个物理节点，因此 preference list 将跳过一些虚拟节点位置，以保证 list 中只包含不同的物理节点。
-
-
-
-### 3.4 数据版本（Data Versioning）
-
-**强一致性**：假如 $A$ 先写入了一个值到存储系统，存储系统保证后续 $A$、$B$、$C$ 的读取操作都将返回最新值。如果不能保证，写操作就会失败。
-
-Dynamo 根据 CAP 原理（在一个分布式系统中，Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三者不可兼得），在一致性上做出让步，在任何时刻用户都可以进行写操作，提供**最终一致性**：过程松，结果紧，最终结果必须保持一致性。
-
-最终一致性允许更新操作可以异步地传播到所有副本。
-
-由于 preference list 中的每个节点都可以对同一个数据进行处理，可能存在更新的数据还没来得及传播到所有的副本就返回数据给调用者的情况，导致 get() 操作返回的对象不是最新的。当有大量并行访问或故障发生时，集群中的不同机器看到的同一个数据状态可能不同，这时就发生了冲突。
-
-
-
-**例子：**
-
-当客户希望增加一个项目到购物车（或从购物车删除）但最新的版本不可用时，该项目将被添加到旧版本（或从旧版本中删除）。不可用的新版本和变化后的旧版本中的信息都需要保留，因此不同版本需要进行协调。
-
-
-
-为了保留所有版本的信息，Dynamo 将每次数据修改的结果当作一个新的且不可改变的数据版本。这造成一份数据会存在多个版本，分布在不同的节点上。多数情况下，系统会自动合并这些版本，一旦合并尝试失败，冲突的解决就交给应用端来解决。
-
-Dynamo 引入 **vector clock** 来缓解冲突的发生，这时 get(key) 操作返回的不是单一的数据，而是一个多版本的数据列表，最终由应用端对冲突进行合并。
-
-```python
-vector clock := list{ (node, counter), ...}
-node := 节点编号
-counter := 该数据在节点上的处理序序号
-```
-
-- vector clock 通过列出在数据在每个节点上的处理序列来发现不同 vector clock 之间的因果关系，其中每个 (node, counter) 可以看做是一个分量；
-- 当某个 vector clock 的所有分量都小于另一个时，该 vector clock 就是另一个的因，可以被覆盖；
-- 没有因果关系的所有 vector clock 需要全部返回客户端，在应用端处理。
-
-<img src="/img/in-post/2018-11-30/vector-clock.png" width="450px" alt="vector-clock" />
-
-**例子：**
-
-1. 假设该商城有 $A$、$B$、$C$ 三个 node，则 $N = 3$。令 $W = 1$，由 $W+R>N$ 得 $R=3$，则：
-
-    ![iphone-example1](/img/in-post/2018-11-30/iphone-example1.png)
-
-    最终：**A: 4500[A:2]&emsp;&emsp;B：5000[A:2,B:1]&emsp;&emsp;D:  3000[A:2,C:1]**
-
-    这时有人询问 iPhone 的价格，$R=3$，读到所有的数据。显而易见，$A$ 上的版本最低，应被舍弃。而对 $B$ 和 $C$ 被送到客户端去处理，我们可以让它有个判断依据——比如时间戳——现在客户端看到 $C$ 上的数据是最新的，那么结论就是 3000。
-
-    &nbsp;
-
-
-2. $W=2$，$R=2$：
-
-    ![iphone-example2](/img/in-post/2018-11-30/iphone-example2.png)
-
-    最终：**A: 3000[A:2,B:1,C:1]&emsp;&emsp;B: 5000[A:2,B:1]&emsp;&emsp;C:  3000[A:2,B:1,C:1]**
-
-    由于 $B$ 的版本低，所以无论读哪两个，都会返回 3000，无需客户端做出协调。
-
-    &nbsp;
-
-    由此也可以看出提高 $W$ 可以降低冲突，提高一致性。但代价是：写两份比写一份要慢，并且同时写成功的概率低于写成功一份的概率——也就是 Availability 降低。这符合 CAP 理论。
-
-
-可能的问题：如果许多服务器协调对一个对象的写，vector clock 的大小可能会增长。因为写入通常是Coordinator（也就是 Preference list 的第一个节点）执行，所以这个问题一般不会发生。但在多个服务器故障时，写请求可能会被不是 coordinator 的节点执行，导致 vector clock 的大小增长。
-
-因此需要限制 vector clock 的大小，Dynamo 采用了以下方案：对每个 (node, counter) 对，Dynamo 存储一个时间戳表示最后一次更新的时间。当 vector clock 中 (node, counter) 对的数目达到一个阈值(如 10)，最早的一对将从时钟中删除。
-
-显然，这个方案会导至在协调时效率低下，因为后代关系不能准确得到。但这个问题还没有出现在生产环境，因此这个问题没有得到彻底研究。
-
-
-### 3.5 读写过程
-
-Dynamo 采用类似 Quorum 的方式保证数据正确，即 $W+R>N$。
-
-Put 流程：
-- coodinator 生成新的数据版本，及 vector clock 分量
-- 本地保存新数据
-- 向 preference list 中的所有节点发送写入请求
-- 收到 $W-1$ 个确认后向用户返回成功
-
-Get 流程：
-- coodinator 向 preference list 中所有节点请求数据版本
-- 得到 $R-1$ 个答复
-- coodinator 通过 vector clock 处理有因果关系的数据版本
-- 将没有因果关系的所有数据版本返回给用户
-
-
-
-### 3.6 故障处理（Handling Failures: Hinted Handoff）
-
-Dynamo 中用 **hinted handoff** 的方式保证在出现暂时的节点或网络故障时，集群依然可以正常提供服务。
-
-流程：
-
-<img src="/img/in-post/2018-11-30/replication.png" width="400px" alt="replication" />
-
-- $A$ 失败，然后本来在 $A$ 上的一个分片将被发送到下一个本来没有该分片的节点 $D$。发送到 $D$ 的分片在其原数据中将有一个暗示，表明哪个节点才是在分片的预期接收者（节点 $A$）；
-- $D$ 将数据保存在一个单独的本地存储中，并成为该分片的处理节点，同时不断检测原节点；
-- 检测到 $A$ 可用时，$D$ 会尝试发送分片到 $A$，发送成功后 $D$ 将删除本地分片。
-
-
-优点：确保读取和写入操作不会因为节点临时或网络故障而失败
-
-由于一个 key 的 preference list 的构造可以是基于跨多个数据中心的节点的，这种跨多个数据中心的复制方案甚至能够处理整个数据中心都故障的情况。
-
-某些情况下仍然会导致数据丢失：如果 $D$ 发现 $A$ 重新上线了，会将本应该属于 $A$ 的分片传送回去，如果这期间 $D$ 发生故障，该分片就会丢失。
-
-
-
-### 3.7 副本同步（Handling permanent failures: Replica synchronization）
-
-当故障发生或者有新节点加入、离开集群时，都涉及分片的拷贝和传输。因此希望能够快速检查分片中内容是否相同，并通过仅发送不同的部分来减少数据传输量。Dynamo 采用 **Merkle Tree** 来解决这个问题。
-
-Merkle tree 是一个哈希树（hash tree）：
-
-- 每个叶子节点对应一个数据项，并记录其哈希值
-- 每个非叶子节点记录其所有子节点的哈希值
-
-使用：
-
-<img src="/img/in-post/2018-11-30/replication.png" width="400px" alt="replication" />
-
-- 每个节点为它维护的每一个分片维护一个 Merkle Tree
-
-  例如：$D$ 维护 $A-B$、$B-C$、$C-D$ 上的分片，所以要维护 3 个 Merkle Tree。
-
-  当两个节点的 Merkle Tree 进行比较时，只针对共同承载的分片的 Merkle Tree 进行比较，也就是对副本进行比较。
-
-- 需要比较分片是否相同时，自根向下的比较两个 Merkle Tree 的对应节点，可以快速发现并定位差异所在。
-  1. 从根节点开始；
-  2. 源节点将 Merkle Tree 当前层的哈希列表传递给其他有该副本的节点（目标节点）；
-  3. 目标节点接受到这个列表以后，就把这个列表与本身 Merkle Tree 的同一层的哈希列表做比较。如果都相同，说明不用同步。如果不同，找出哈希值不同的子树，并向原节点发出请求，告诉原节点哪些子树是不同的；
-  4. 重复 2、3 步骤，直到找到叶子节点。这样就可以找出哪些分片是不同的；
-  5. 源节点将不同的 key 的值传给目标节点。
-
-优点：
-
-- 时间：Merkle Tree 利用树形结构迅速定位到不同的分片，时间复杂度为 $O(\lg n)$
-- 空间：在分布式情况下，空间可以理解为相应的网络传输数据量。Merkle Tree 不必传输所有的节点，只需传输不同的节点。
-
-
-### 3.8 成员信息及故障检测（Membership and Failure Detection）
-考虑到节点失败无法恢复的情况并不常见，Dynamo 加入或离开集群都需要手动通过命令完成。
-
-- 当有用户请求时，coordinator 会发现不可达的节点，并用其他节点代替之，之后开始周期性探测其是否恢复；
-- Dynamo 集群中的每台机器都会维护当前集群的成员及节点不可达等信息，这些信息通过 gossip 协议广播到整个集群；
-- 客户端可以通过任意一个节点获得并维护这种成员信息，从而精确的找到自己要访问的数据所在。
Index: blog/posts/2020-07-10-messy-notes-nlp.md
===================================================================
diff --git a/blog/posts/2020-07-10-messy-notes-nlp.md b/blog/posts/2020-07-10-messy-notes-nlp.md
deleted file mode 100644
--- a/blog/posts/2020-07-10-messy-notes-nlp.md	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
+++ /dev/null	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
@@ -1,758 +0,0 @@
----
-layout: Post
-title: 乱七八糟的知识点
-subtitle: "Messy Notes (NLP)"
-author: Renovamen
-date: 2020-07-10
-headerImage: /img/in-post/2020-07-10/header.jpg
-permalinkPattern: /post/:year/:month/:day/:slug/
-tags:
-  - NLP
----
-
-菜鸡在失学失业的惊慌失措之下的胡乱总结，又因为懒惰压制了惊慌失措所以并没有总结多少...
-
-<!-- more -->
-
-
-## 优化器
-
-损失函数通常为：
-
-$$
-L(\theta) = \frac{1}{M} \sum_{i=1}^M L(f(x_i, \theta), y_i)
-$$
-
-### 无动量
-
-每次迭代按梯度方向更新参数，$r$ 是学习率：
-
-$$
-\theta_{t+1} = \theta_t - r \cdot \nabla L(\theta_t)
-$$
-
-#### BGD
-
-Batch Gradient Descent，批量梯度下降，在每一次迭代时使用所有样本来进行梯度更新：
-
-$$
-\nabla L(\theta) = \frac{1}{M} \sum_{i=1}^M \nabla L(f(x_i, \theta), y_i)
-$$
-
-
-- 所有的样本都对参数更新有贡献，凸函数假设下一定能达到全局最优；
-
-- 每次迭代都需要对所有样本进行计算，所以样本太多时，要耗费大量计算资源和时间
-
-
-
-#### SGD
-
-Stochastic Gradient Descent，随机梯度下降，每次迭代随机选一个样本 $x_i$ 来近似所有样本，并更新梯度：
-
-$$
-\nabla L(\theta) = \nabla L(f(x_i, \theta), y_i)
-$$
-
-- 每次参数更新只需要一个样本，速度快
-
-- 计算得到的不是准确梯度，凸函数假设下也不一定有全局最优
-
-
-#### MBGD
-
-Mini-Batch Gradient Descent，小批量梯度下降，对 BGD 和 SGD 的折中，每次迭代用 **m**（batch size）个样本来对参数进行更新：
-
-$$
-\nabla L(\theta) = \frac{1}{m} \sum_{i=1}^m \nabla L(f(x_i, \theta), y_i)
-$$
-
-m 是一个远小于总训练样本数 M 的数，通常为 2 的幂次（以充分利用矩阵运算）。为了避免样本的特定顺序给算法收敛带来的影响，一般会在每个 epoch 随机打乱所有样本，然后每次迭代时按顺序选 m 个样本，直到遍历完所有样本。
-
-- 用一个 batch 来近似整体样本的分布情况，降低了随机梯度的方差，提高了算法稳定性
-
-- 通过矩阵运算，用一个 batch 来优化参数并不会比用单个样本来优化参数慢太多
-
-
-### 一阶动量
-
-#### Polyak's Momentum
-
-最简单的 momentum，又名 Heavy Ball。引入惯性，即每次更新时，在一定程度上保留之前更新的方向：
-
-$$
-\begin{cases}
-   v_t = \rho v_{t-1} - r \cdot \nabla L(\theta_t) \\
-   \theta_{t+1} = \theta_t + v_t
-\end{cases}
-$$
-
-$$
-\Rightarrow \theta_{t+1} = \theta_t - r \cdot \nabla L(\theta_t) + \rho (\theta_t - \theta_{t-1})
-$$
-
-$\rho \in [0,1)$ 是 momentum parameter，$\rho = 0$ 时就相当于原始的梯度下降。$\rho (\theta_t - \theta_{t-1})$ 就是 Polyak's momentum。
-
-
-- 有一定的摆脱局部最优的能力
-
-- 加快收敛速度。这里是一个数学上的解释：[从动力学角度看优化算法：从SGD到动量加速](https://spaces.ac.cn/archives/5655)。
-
-
-#### Nesterov's Momentum
-
-Nesterov Accelerated Gradient（NAG），先按照之前的更新方向更新一步，然后在该位置计算梯度，再按梯度方向更新：
-
-$$
-v_t = \rho v_{t-1} - r \cdot \nabla L(\theta_t + \rho v_{t-1})
-$$
-
-$$
-\theta_{t+1} = \theta_t + v_t
-$$
-
-<img src="/img/in-post/2020-07-10/nesterov.jpeg" width="600px" alt="nesterov update" />
-
-
-梯度不是根据当前参数位置 $\theta_t$，而是根据先走了本来计划要走的一步后，达到的参数位置 $\theta_t + \rho v_{t-1}$ 计算出来的。
-
-
-- 比原始 momentum 收敛得更快，[这里](https://zhuanlan.zhihu.com/p/22810533)是一个解释，简单来说就是因为 NAG 相对于 momentum 多了一个本次梯度相对上次梯度的变化量（目标函数的二阶导）。
-
-
-### 二阶动量
-
-#### AdaGrad
-
-上述方法对于所有参数都用了同一个学习率，但同一个学习率不一定适合所有参数。不是所有神经网络中的参数都会经常被用到，经常更新的参数可能已经到了仅需要微调的阶段，但偶尔更新的参数可能还需要较大幅度的更新。因此 AdaGrad 的思想是给不同的参数不同的学习率。
-
-引入二阶动量，即该维度上，迄今为止所有梯度值的平方和：
-
-$$
-g_t = \nabla L(\theta_t)
-$$
-
-$$
-h_t = h_{t-1} + g_t^2
-$$
-
-$$
-\theta_{t+1} = \theta_t - \frac{r}{\sqrt{h_t + \epsilon}} \cdot g_t
-$$
-
-$\epsilon$ 是一个用于保证分母非 0 的平滑项。相当于现在学习率是 $\frac{r}{\sqrt{h_t + \epsilon}}$，参数更新越频繁，二阶动量就越大，学习率就越小。
-
-- 给不同参数不同的学习率
-
-- 因为 $\sqrt{h_t}$ 单调递增，所有学习率会单调递减至（接近）0，可能会使训练过程提前结束
-
-#### RMSProp
-
-为了避免学习率下降过于激进，RMSProp 用了梯度的指数加权移动平均，而不是简单累积所有历史梯度：
-
-$$
-h_t = \gamma h_{t-1} + (1 - \gamma) g_t^2
-$$
-
-$$
-= \gamma^k h_{t-k} + \gamma^k (1 - \gamma) g_{t-k}^2 + ... + (1 - \gamma) g_t^2
-$$
-
-多了一个超参数 $\gamma$。可以看到每次累加的梯度的平方项的权重都是 $\gamma$ 的指数，所以叫指数加权移动平均。只要通过控制 $\gamma$ 的大小，就可以使每次累加的梯度信息的权重减小不同的程度。越接近当前时刻，梯度权重就越大，影响也就越大；离当前时刻越远，梯度权重越小，影响也就越小。
-
-$$
-\theta_{t+1} = \theta_t - \frac{r}{\sqrt{h_t + \epsilon}} \cdot g_t
-$$
-
-
-#### AdaDelta
-
-二阶动量跟 RMSProp 是一样的：
-
-$$
-h_t = \gamma h_{t-1} + (1 - \gamma) g_t^2
-$$
-
-但没有学习率这个超参数，而是维护了一个能够根据梯度信息自动变化的量 $\Delta \theta$：
-
-$$
-g'_t = \sqrt{\frac{\Delta \theta_{t-1} + \epsilon}{h_t + \epsilon}} \cdot g_t
-$$
-
-$$
-\Delta \theta_t = \gamma \Delta \theta_{t-1} + (1 - \gamma) (g'_t)^2
-$$
-
-$$
-\theta_t = \theta_{t-1} - g'_t
-$$
-
-如果不考虑 $\epsilon$，可以看做是用 $\sqrt{\Delta \theta_{t-1}}$ 代替了 RMSProp 中的学习率 $r$。
-
-### Adam
-
-Adaptive Moment Estimation，考虑了一阶动量和二阶动量，可以理解为 momentum + RMSprop：
-
-$$
-v_t = \rho_1 v_t + (1 - \rho_1) g_t
-$$
-
-$$
-h_t = \rho_2 h_{t-1} + (1 - \rho_2) g_t^2
-$$
-
-初始化：$v_0 = 0, h_0 = 0$，这个初始化值跟真实值有偏差。而初期的更新幅度会很大，会严重受到初始化偏差的影响，所以有偏差修正（[这里](https://stats.stackexchange.com/questions/232741/why-is-it-important-to-include-a-bias-correction-term-for-the-adam-optimizer-for)是更详细的解释）：
-
-$$
-\hat{v}_t = \frac{m_t}{1 - \rho^t_1}
-$$
-
-$$
-\hat{h}_t = \frac{h_t}{1 - \rho^t_2}
-$$
-
-偏差修正在初期的影响比较大，后期的影响会越来越小。
-
-最终的参数更新：
-
-$$
-\theta_t = \theta_{t-1} - r \cdot \frac{\hat{v}_t}{\sqrt{\hat{h}_t + \epsilon}}
-$$
-
-### 参考
-
-- [CSC321 -	Lecture	6a: Overview of	mini-batch gradient descent ](http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)
-
-- [CS231n - Neural Networks Part 3: Learning and Evaluation](https://cs231n.github.io/neural-networks-3/)
-
-- [An overview of gradient descent optimization algorithms](https://ruder.io/optimizing-gradient-descent/index.html)
-
-
-## 词向量
-
-### 统计方法
-
-#### one-hot
-
-最简单的词向量。设词典大小为 n，则每个词的向量为一个 n 维向量，向量中其对应位置上的值为 1，其他位置都是 0。
-
-- 维度灾难：特征维度过高导致样本稀疏，造成计算困难
-
-- 语义鸿沟：无法通过词向量之间的距离来反映词之间的相似程度（任意两个向量的距离是相同的）
-
-- 无法反映文本的有序性
-
-
-为了将语义融入到词表示中，有了**分布式假说（distributional hypothesis）**：词的语义由其上下文决定。后面的词表示方法都是基于分布式假说。
-
-
-#### 共现矩阵
-
-共现矩阵（Co-occurrence Matrix）是由一个指定大小的窗口内的单词共现次数构成的矩阵，如对于以下语料：
-
-- I like deep learning.
-- I like NLP.
-- I enjoy flying.
-
-当窗口大小为 3（左右长度都为 1）时，共现矩阵为：
-
-<img src="/img/in-post/2020-07-10/co-matrix.png" width="500px" alt="Co-occurrence Matrix" />
-
-
-可以想到的方法是把共现矩阵的行或列作为单词的词向量：
-
-- 能够在一定程度上表现单词之间的语义关系，相比 one-hot 有了一定的提升
-
-- 没有解决维度灾难问题
-
-
-#### SVD
-
-SVD（Singular Value Decomposition，奇异值分解）的思想是对共现矩阵中得到的词向量进行降维，从而得到一个稠密的连续词向量。
-
-奇异值分解可以对任意大小的矩阵 $A$ 进行分解：
-
-$$
-A = U \Sigma V^T
-$$
-
-其中，$A \in R^{m \times n}$；$U \in R^{m \times m}$，各个向量相互正交，被称为左奇异矩阵；$\Sigma \in R^{m \times n}$，仅在对角线上有值，被称为奇异值；$V \in R^{n \times n}$，各个向量也相互正交，被称为右奇异矩阵。具体分解原理可以参考[这里](https://www.cnblogs.com/endlesscoding/p/10033527.html)。
-
-奇异值是从大到小排列的，可以认为奇异值代表了特征的权重。通常前 10% 甚至 1% 的奇异值的和就占了所有奇异值和的 99% 以上，所以一般会选择用 $U$ 的前 $k$ 维来代表词向量矩阵，最终词向量矩阵大小为 $m \times k$，$m$ 为词典大小，$k$ 为词向量维度。
-
-- 能够在一定程度上表现单词之间的语义关系
-
-- 利用了全局语料特征
-
-- 矩阵过于稀疏，因为在构建共现矩阵时，有很多词是没有共现的
-
-- 矩阵分解复杂度高
-
-- 需要手动去除高频无意义的停用词（如 is、a 等），否则会影响共现矩阵分解的效果
-
-
-### 浅层词嵌入
-
-通常采用浅层网络进行训练（浅层词嵌入，Non-Contextual Embeddings），主要缺陷为：
-
-- 词向量与上下文无关，每个单词的词向量始终是相同的（静态），无法解决一词多义问题
-
-- OOV（Out of Vocabulary）问题。一种解决方法是引入字符级（CharCNN）或 subword（fastText）表示
-
-
-#### NNLM
-
-**A Neural Probabilistic Language Model.** *Bengio, Yoshua, et al.* Journal of Machine Learning Research. [[Paper]](http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)
-
-NNLM（Neural Network Language Model，神经网络语言模型）即用神经网络训练得到一个语言模型，同时产生副产物词向量。其思想为：
-
-- 假定词典中的每个单词都对应一个连续的特征向量
-
-- 假定一个连续平滑的概率模型，输入为前 n-1 个单词的词向量，输出为一个维度为词表大小的向量，代表每个词出现的概率
-
-- 同时学习词向量的权重和 n 元组（ngram）模型里的参数
-
-其主要计算量在隐藏层上。softmax 层也是一个计算瓶颈，因为需要对词典中所有词都计算一遍条件概率。
-
-- 词向量只是一个副产物，由于其巨大的参数空间，NNLM 的训练很慢
-
-- 使用的是全连接神经网络，因此只能处理定长序列（不过后来的 RNNLM 解决了这个问题）
-
-
-#### word2vec
-
-**Efficient Estimation of Word Representations in Vector Space.** *Tomas Mikolov, et al.* ICLR 2013. [[Paper]](https://arxiv.org/pdf/1301.3781.pdf)
-
-**Distributed Representations of Words and Phrases and their Compositionality.** *Tomas Mikolov, et al.* NIPS 2013. [[Paper]](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf) 
-
-具体原理和数学推导可以参考这里：[word2vec 中的数学原理详解](https://blog.csdn.net/itplus/article/details/37969519)
-
-
-word2vec 的本质依然是语言模型，但是它的目标并不是语言模型本身，而是词向量。所以它所采取的一系列优化都是为了更快更好的得到词向量。
-
-##### 两种模型
-
-###### CBOW
-
-利用给定上下文 $\text{Context}(w)$（单词 $w$ 的前后共 $l$ 个词）预测单词 $w$，目标函数为（$C$ 为语料库）：
-
-$$
-L = \sum_{w \in C} \log p(w | \text{Context}(w))
-$$
-
-###### Skip-gram
-
-利用给定单词 $w$ 来预测上下文 $\text{Context}(w)$，目标函数为：
-
-$$
-L = \sum_{w \in C} \log p(\text{Context}(w) | w)
-$$
-
-$$
-p(\text{Context}(w) | w) = \prod_{u \in \text{Context}(w)} p(u | w)
-$$
-
-
-##### 两个优化方法
-
-###### Hierarchical Softmax
-
-Hierarchical Softmax（层次化 Softmax）会先构造一个哈夫曼树（Huffman Coding），然后将复杂的归一化概率问题转化为一系列二分类的条件概率相乘的形式，从而将目标概率的计算复杂度从 $V$ 降到 $\log_2V$，$V$ 为词典大小。
-
-哈夫曼树又称为最优二叉树，表示一种带权路径长度最短的二叉树。带权路径长度：叶子结点的权值 * 该结点到根结点的路径长度。
-
-这里构造的哈夫曼树的根节点是整个词典，每一个子节点为父节点的两个不相交子集，每个单词都是一个叶子节点，叶子节点的权值为词频。带权路径最小的条件保证了哈夫曼树中，高频词离根结点更近，而低频词离根结点更远。
-
-<img src="/img/in-post/2020-07-10/huffman.jpg" width="400px" alt="Huffman" />
-
-
-考虑单词 $w$ 对应的叶子节点，记：
-
-- $p^w$：从根节点到 $w$ 对应的叶子节点的路径
-
-- $l^w$：路径 $p^w$ 中包含的节点个数
-
-- $d^w_2, d^w_3, \dots , d^w_{l^w} \in \{ 0, 1 \}$：词 $w$ 的哈夫曼编码，共 $l^w - 1$ 位（根节点不对应编码），$d^w_j$ 表示路径 $p^w$ 中第 $j$ 个节点对应的编码
-
-- $\theta^w_1, \theta^w_2, \dots , \theta^w_{l^w-1}$：$\theta^w_j$ 表示路径 $p^w$ 中第 $j$ 个非叶子结点的对应的向量，作为求条件概率的参数
-
-假设根结点为词典 $D$，则第二层的两个子节点分别为 $D$ 的两个子集 $D_1$ 和 $D_2$。左子节点的哈夫曼编码为 0（负类），右子节点为 1（正类）。
-
-**CBOW**
-
-则在给定上下文的情况下，由二分类逻辑回归可知，第 $j$ 个节点被分为正类（即 $w_t \in D_2$）的概率为：
-
-$$
-p(d_j^w | x_w , \theta_{j-1}^w) = \sigma(x_w^{\top} \theta) = \frac{1}{1 + e^{-x_w^{\top} \theta}}
-$$
-
-分为负类（即 $w_t \in D_1$）的概率为：
-
-$$
-p(d_j^w | x_w , \theta_{j-1}^w) = 1 - \sigma(x_w^{\top} \theta)
-$$
-
-其中，$x_w$ 为相加后的上下文词向量。最终的条件概率为：
-
-$$
-p(w | \text{Context}(w)) = \prod_{j=2}^{l^w} p(d_j^w | x_w , \theta_{j-1}^w)
-$$
-
-**Skip-gram**
-
-条件概率函数为：
-
-$$
-p(\text{Context}(w) | w) = \prod_{u \in \text{Context}(w)} p(u | w)
-$$
-
-$$
-p(u | w) = \prod_{j=2}^{l^u} p(d_j^u | v(w) , \theta_{j-1}^u)
-$$
-
-其中 $v(w)$ 是单词 $w$ 的词向量。
-
-&nbsp;
-
-
-然后对条件概率函数求最大似然即可，具体公式上面引用的那篇[博客](https://blog.csdn.net/itplus/article/details/37969979)里有。
-
-- 时间复杂度从 $O(V)$ 降到 $O(\log_2V)$
-
-- 人为增强了词与词之间的耦合性。如果一个词的条件概率出现变化，会影响到其路径上所有非叶节点的概率变化，间接地对其他词的条件概率造成影响。所以构造合适的二叉树非常重要。
-
-
-###### Negative Sampling
-
-Negative-Sampling（NEG，负采样）可以作为 Hierarchical Softmax 的一种替代，它不再使用哈夫曼树，而是使用相对简单的随机负采样。
-
-**CBOW**
-
-对于给定的 $\text{Context}(w)$，单词 $w$ 是一个正样本，其他词都是负样本。我们希望最大化：
-
-$$
-g(w) = \prod_{u \in \{w\} \cup NEG(w)} p(u | \text{Context}(w))
-$$
-
-$$
-p(u | \text{Context}(w)) = 
-
-\begin{cases}
-   \sigma(x_w^{\top} \theta^u),      &u \text{为正样本} \\
-   1 - \sigma(x_w^{\top} \theta^u),  &u \text{为负样本}
-\end{cases}
-$$
-
-其中 $NEG(w)$ 是采样出的关于 $w$ 的负样本子集。把上面两个式子合起来可以得到：
-
-$$
-g(w) = \sigma(x_w^{\top} \theta^w) \prod_{u \in NEG(w)} [1 - \sigma(x_w^{\top} \theta^u)]
-$$
-
-其中，$\sigma(x_w^{\top} \theta^w)$ 为预测中心词为 $w$ 的概率，$\sigma(x_w^{\top} \theta^u)$ 为预测中心词为 $u$ 的概率。因此最大化 $g(w)$ 就相当于最大化 $\sigma(x_w^{\top} \theta^w)$（正样本概率），同时最小化所有的 $\sigma(x_w^{\top} \theta^u)$（负样本概率）。
-
-目标函数为：
-
-$$
-G = \prod_{w \in C} g(w)
-$$
-
-
-**Skip-gram**
-
-目标函数为：
-
-$$
-G = \prod_{w \in C} \prod_{u \in \text{Context}(w)} g(u)
-$$
-
-其中：
-
-$$
-g(u) = \prod_{z \in \{u\} \cup NEG(u)} p(z | w)
-$$
-
-$$
-p(z | w) = 
-
-\begin{cases}
-   \sigma(v(w)^{\top} \theta^z),      &z \text{为正样本} \\
-   1 - \sigma(v(w)^{\top} \theta^z),  &z \text{为负样本}
-\end{cases}
-$$
-
-**负采样算法**
-
-需要采样出负样本子集 $NEG(W)$。负采样算法是一个带权采样过程，即高频词被选为负样本的概率应该比较大，而低频词被选中的概率应该比较小。
-
-设词典 $D$ 中每一个单词 $w$ 对应一个线段 $l(w)$，长度为：
-
-$$
-\text{len}(w) = \frac{[\text{count}(w)]^{\frac{3}{4}}}{\sum_{u \in D} [\text{count}(w)]^{\frac{3}{4}}}
-$$
-
-然后把这些线段首尾相接拼在一起，形成一个长度为 1 的线段（相当于对区间 $[0,1]$ 做非等距切分）。然后再引入一个区间 $[0,1]$ 上的 $M$ 等距切分，其中 $M >> N$（word2vec 源码中 $M = 10^8$）。然后即可建立这两个切分的映射关系，如下图所示：
-
-<img src="/img/in-post/2020-07-10/neg.jpg" width="500px" alt="NEG" />
-
-采样时，每次生成一个 $[1, M-1]$ 之间的整数 $i$，则 $m_i$ 对应的线段对应的单词就是一个样本。当碰巧采样到自己（正样本）时，则跳过。
-
-
-##### 特点
-
-- 为了提高计算效率，将词向量直接相加（NNLM 中是把词向量拼接）
-
-- 舍弃了 NNLM 中的隐层，只有一个投影层（用于累加词向量）
-
-- 真正考虑了上下文（NNLM 的输入严格来说只有上文）
-
-- hierarchical softmax 和 negative sampling 优化
-
-- 只用了局部语料（特征提取基于滑窗）
-
-
-#### GloVe
-
-**GloVe: Global Vectors for Word Representation.** *Jeffrey Pennington, et al.* EMNLP 2014. [[Paper]](https://www.aclweb.org/anthology/D14-1162.pdf)
-
-GloVe（Global Vectors for Word Representation）可以看做是 SVD 和 word2vec 的结合，它先构建一个[共现矩阵](#共现矩阵) $X$，矩阵中的元素 $X_i$ 为单词 $i$ 和上下文单词 $j$ 在指定大小的上下文窗口中共同出现的次数。
-
-然后构建词向量和共现矩阵之间的近似关系，目标函数为：
-
-$$
-J = \sum_{i,j}^N f(X_{ij}) (w_i^{\top} \tilde{w}_j + b_i + b_j - \log X_{ij})
-$$
-
-这两篇博客推导了目标函数是怎么来的：[理解 GloVe 模型](https://blog.csdn.net/coderTC/article/details/73864097)、[GloVe 详解](http://www.fanyeong.com/2018/02/19/glove-in-detail/)。
-
-可以认为它的 label 是 $\log X_{ij}$。$w$ 和 $\tilde{w}$ 是两个不同的词向量，因为共现矩阵 $X$ 是对称的，所以理论上 $w$ 和 $\tilde{w}$ 也应该是对称的，但它们初始化的值不一样，所以最终的结果也不一样。为了提高鲁棒性，会用 $w + \tilde{w}$ 作为最终的词向量。
-
-这个目标函数就是一个均方差损失（Mean Square Error，MSE），只不过基于出现频率越高的词对权重应该越大的原则，还加了一个权重函数 $f(\cdot)$（论文里 $\alpha$ 取 $\frac{3}{4}$）：
-
-$$
-f(x) = 
-
-\begin{cases}
-    (x / x_{max})^{\alpha}  &\text{if } x < x_{max} \\
-    1                       &\text{otherwise}
-\end{cases}
-$$
-
-<img src="/img/in-post/2020-07-10/glove-weighting-function.png" width="400px" alt="Weighting Function" />
-
-该函数满足以下条件：
-
-- 非减函数
-
-- 到达一定程度之后不再增加（因为不希望权重过大）
-
-- 如果两个单词没有在一起出现，即 $X_{ij}=0$，那么他们应该不参与到损失函数的计算中，所以需要有 $f(0) = 0$
-
-GloVe 的特点：
-
-- 相比 SVD，GloVe 时间复杂度更低
-
-- 相比 word2vec，GloVe 用了全局语料，需要事先统计共现概率
-
-- word2vec 的损失函数是带权重的交叉熵，GloVe 的损失函数是带权重的均方差损失
-
-
-#### fastText
-
-模型结构与 CBOW 一样。
-
-用于计算词向量时：
-
-- 无监督
-
-- 局部语料
-
-- 相比 CBOW，考虑了 subword，最终的词向量是 subword 向量和的叠加。这样做的优点：
-
-    - 对于低频词生成的词向量效果会更好，因为它们的 subword 可以和其它词共享
-
-    - 对于训练集之外的单词，依然可以构建它们的词向量（叠加它们的 subword 向量）
-
-
-用于文本分类时：
-
-- 有监督，预测句子的类别标签
-
-- 引入 ngrams，考虑词序特征
-
-- 引入 subword 来处理长词、未登陆词
-
-- hierarchical softmax 优化，对输出的分类标签建立哈夫曼树，样本中标签多的类别离根节点更近
-
-
-### 预训练编码器
-
-通过一个能够输出上下文相关的词向量的预训练编码器来解决一词多义的问题。这类预训练编码器输出的向量被称为「上下文相关的词嵌入（contextual word embeddings）」。
-
-主要代表有 ELMo、GPT、BERT、XLNet 等，总结在[预训练模型](#预训练模型)一节。
-
-
-### 参考
-
-- 语言模型综述：[A Survey on Neural Network Language Models](https://arxiv.org/pdf/1906.03591.pdf)
-
-    中文翻译：[神经网络语言模型综述](https://zhuanlan.zhihu.com/p/109564205)
-
-- 预训练模型综述：[Pre-trained Models for Natural Language Processing: A Survey](https://arxiv.org/pdf/2003.08271.pdf)
-
-- [PTMs：NLP 预训练模型的全面总结](https://zhuanlan.zhihu.com/p/115014536)
-
-- [NLP 中的词向量对比](https://zhuanlan.zhihu.com/p/56382372)
-
-- [词向量（one-hot/SVD/NNLM/Word2Vec/GloVe）](https://www.cnblogs.com/sandwichnlp/p/11596848.html)
-
-- [【语言模型系列】原理篇一：从 one-hot 到 Word2vec](https://www.6aiq.com/article/1586815086168)
-
-
-## 预训练模型
-
-![Pre-trained Models](/img/in-post/2020-07-10/PTMs.jpg)
-
-<p class="desc">预训练模型分类（来源：<a href="https://zhuanlan.zhihu.com/p/115014536" target="_blank">PTMs：NLP预训练模型的全面总结</a>）</p>
-
-
-预训练模型（Pre-trained Models）会学习带有上下文的 contextual embedding，词的表征可以根据上下的语境而动态改变。给定一个文本序列 $x_1, x_2, \dots, x_T$，$x_t$ 的 contextual embedding（或者叫 dynamical embedding）$h_t$ 依赖于整个文本：
-
-$$
-[h_1, h_2, \dots, h_T] = f_{\text{enc}} (x_1, x_2, \dots, x_T)
-$$
-
-$f_{\text{enc}}(\cdot)$ 就是下图中的 contextual encoder：
-
-<img src="/img/in-post/2020-07-10/contextual-embedding.png" width="500px" alt="Contextual Embeddings" />
-
-<p class="desc">图片来源：<a href="https://arxiv.org/pdf/2003.08271.pdf" target="_blank">Pre-trained Models for Natural Language Processing: A Survey</a></p>
-
-
-输入为文本序列的 one-hot 编码，经过 embedding 层得到 non-contextual embeddings，然后经过 contextual encoder 得到 contextual embeddings。embedding 层和 contextual encoder 都需要学习。
-
-绝大多数预训练模型用的是自监督学习，[这篇](https://arxiv.org/pdf/2003.08271.pdf)综述把基于自监督学习的预训练模型分为了两类：基于上下文（Context Based）和基于对比（Contrastive Based）。而基于上下文的预训练模型所用的语言模型可以分为：
-
-- **自回归语言模型（Aotoregressive Lanuage Modeling）**
-
-    依据前面（或后面）出现的 token 来预测当前时刻的 token，代表模型有 ELMo、GTP 等。
-
-    $$
-    p(x_{1:T}) = \prod_{t=1}^T p(x_t | x_{0:t-1})
-    $$
-
-    特点：
-
-    - 语言模型联合概率的无偏估计（即传统的语言模型），考虑被预测 token 之间的相关性，天然适合处理生成任务（所以 GPT 能编故事，BERT 编不太了）
-
-    - 只能获取单方向的信息
-
-- **自编码语言模型（Autoencoding Language Modeling）**
-
-    通过上下文信息来预测当前被 mask 的 token，代表模型有 BERT 等。
-
-    $$
-    p(x_{1:T}) = \sum_{t=1}^T m_t \log p(x_t | \hat{x})
-    $$
-
-    其中 $\hat{x}$ 为上下文，即加噪后的文本序列；如果当前 token 需要被预测，$m_t=1$，否则 $m_t=0$。
-    
-    特点：
-
-    - 通过引入噪声「MASK」来获取双向上下文信息表示
-
-    - 引入独立性假设，为语言模型联合概率的有偏估计，没有考虑预测 token 之间的相关性
-
-    - 预训练（DAE；有「MASK」）与微调（Autogressive LM；，无「MASK」）模式不匹配
-
-- **排列语言模型（Permuted Language Model）**
-
-
-### ELMo
-
-**Deep contextualized word representations.** *Matthew E. Peters, et al.*  NAACL-HLT 2018. [[Paper]](https://www.aclweb.org/anthology/N18-1202.pdf) [[Code]](https://github.com/allenai/bilm-tf) 
-
-自回归语言模型。编码器是双层双向 LSTM，每层的两个单向 LSTM（前向和后向）直接拼接。并未进行双向信息的融合，所以不会出现标签泄漏。（[这里](https://www.zhihu.com/question/322034410/answer/794201004)是对标签泄漏的更详细的解释）
-
-![ELMo](/img/in-post/2020-07-10/elmo.png)
-
-<p class="desc">图片来源：<a href="https://www.aclweb.org/anthology/N19-1423.pdf" target="_blank">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a></p>
-
-ELMo 中每一层的输出向量都有不同的含义：E1 是单词特征，E2 是句法特征，E3 是语义特征。下游任务在使用词向量时，会通过一些方式将每一层的向量融合得到预训练词向量，然后将该向量与下游任务的词向量进行拼接得到最终的词向量。
-
-
-### GPT-1
-
-**Improving Language Understanding by Generative Pre-Training.** *Alec Radford, et al.* [[Paper]](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf) [[Code]](https://github.com/openai/finetune-transformer-lm)
-
-自回归语言模型。编码器是 Transformer 的 decoder 部分（首次将 Transformer 应用于预训练语言模型），decoder 部分只能使用单向信息，即只使用上文预测当前词，无法获取上下文相关的特征表示。
-
-相比 ELMo：
-
-- 编码器从 BiLSTM 变成 Transformer
-
-- 只用上文信息而不使用下文
-
-- 进行下游任务时，直接在预训练模型上进行 fine-tuning，而不是直接用现成的词向量
-
-
-
-### BERT
-
-**BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.** *Jacob Devlin, et al.* NAACL-HLT 2019. [[Paper]](https://www.aclweb.org/anthology/N19-1423.pdf) [[Slide]](https://nlp.stanford.edu/seminar/details/jdevlin.pdf) [[Code]](https://github.com/google-research/bert)
-
-
-自编码语言模型。编码器是 Transformer 的 encoder 部分，更够利用双向信息。
-
-![BERT](/img/in-post/2020-07-10/bert.png)
-
-BERT 还在 Transformer-Encoder 的基础上做了 mask 操作（Masked Language Model，MLM），即随机 mask 掉输入序列的部分 tokens，然后只预测被 mask 掉的 tokens。MLM 能够更好的获取双向上下文特征表示，也能解决深度 Transformer 带来的标签泄露（see itself）的问题。标签泄露指，Transformer 自带的全局 self-attention 会将上下文的词编码到当前模型里，所以在预测其他词的时候，该词的信息已经包含在了前一层的网络参数里：
-
-<img src="/img/in-post/2020-07-10/see-itself.jpg" width="400px" alt="see itself" />
-
-BERT 的特点：
-
-- 能够获取上下文相关的双向特征表示
-
-- 在生成任务上表现不佳：预训练（DAE；有「MASK」标记）与微调（Autogressive LM；无「MASK」标记）模式不匹配
-
-- 引入了独立性假设，为语言模型联合概率的有偏估计，没有考虑预测「MASK」之间的相关性
-
-
-### XLNet
-
-**XLNet: Generalized Autoregressive Pretraining for Language Understanding.** *Zhilin Yang, et al.* NIPS 2019. [[Paper]](http://papers.nips.cc/paper/8812-xlnet-generalized-autoregressive-pretraining-for-language-understanding.pdf) [[Code]](https://github.com/zihangdai/xlnet)
-
-
-
-### 参考
-
-- 语言模型综述：[A Survey on Neural Network Language Models](https://arxiv.org/pdf/1906.03591.pdf)
-
-    中文翻译：[神经网络语言模型综述](https://zhuanlan.zhihu.com/p/109564205)
-
-- 预训练模型综述：[Pre-trained Models for Natural Language Processing: A Survey](https://arxiv.org/pdf/2003.08271.pdf)
-
-- [PTMs：NLP 预训练模型的全面总结](https://zhuanlan.zhihu.com/p/115014536)
-
-- [NLP 中的预训练语言模型总结](https://zhuanlan.zhihu.com/p/76912493)
-
-- [【语言模型系列】原理篇二：从 ELMo 到 ALBERT](https://www.6aiq.com/article/1587401784826)
-
-
-## Batch Normalization
-
-**Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift.** *Sergey Ioffe and Christian Szegedy.* ICML 2015. [[Paper]](http://proceedings.mlr.press/v37/ioffe15.pdf)
-
-Inception V2 的论文，重要贡献之一是提出了 Batch Normalization（BN，批标准化）。
-
-
-
-
-
-
-### 参考
-
-- [深入理解 Batch Normalization 批标准化](https://www.cnblogs.com/guoyaohua/p/8724433.html)
-
-- [Understanding the backward pass through Batch Normalization Layer](https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html)
Index: blog/posts/2020-08-22-bocd.md
===================================================================
diff --git a/blog/posts/2020-08-22-bocd.md b/blog/posts/2020-08-22-bocd.md
deleted file mode 100644
--- a/blog/posts/2020-08-22-bocd.md	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
+++ /dev/null	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
@@ -1,372 +0,0 @@
----
-layout: Post
-title: BOCD
-subtitle: "Bayesian Online Changepoint Detection"
-author: Renovamen
-date: 2020-08-22
-headerImage: /img/in-post/2020-08-22/header.jpg
-permalinkPattern: /post/:year/:month/:day/:slug/
-tags:
-  - Machine Learning
-  - Math
-  - Bayesian
----
-
-
-给定一个数据序列，在某个时间点，数据的某个（或某些）参数可能由于系统性因素（而非偶然性因素）而突然发生变化，那么这个时间点被称为**变点**（changepoint）。<!-- more -->**变点检测**（changepoint detection）就是要估计出变点的位置。
-
-本文主要打算理一下这篇论文：
-
-**Bayesian Online Changepoint Detection.** *Ryan Prescott Adams and David J.C. MacKay.* arXiv 2007. [[Paper]](https://arxiv.org/pdf/0710.3742.pdf)
-
-翻译过来大概是贝叶斯在线变点检测？“online”这个词指检测变点时只能利用当前已经观测到的数据，不能用未来数据。而很多 offline 的方法是可以拿所有的数据来做检测的。
-
-本文很大程度上（又）~~抄~~参考了一篇讲 BOCD 讲得非常清楚的博客：
-
-[**Bayesian Online Changepoint Detection**](http://gregorygundersen.com/blog/2019/08/13/bocd/) (Gregory Gundersen)
-
-
-## 问题定义
-
-假设有一个观测序列 $x_1, x_2, \dots, x_T \in \Reals^d$，我们用 $x_{a:b}$ 来表示 $x_a, x_{a+1}, \dots x_b$。$x_{1:T}$ 可以被划分成一些不重叠的 [product partitions](https://projecteuclid.org/download/pdf_1/euclid.aos/1176348521)，即每个 partition 中的数据点都是 i.i.d（独立同分布）的，都服从参数为 $\theta_p$ 的分布 $p(x_t \mid \theta_p)$，每个 partition 的参数 $\theta_p \thicksim p(\phi)$ 也是 i.i.d 的：
-
-<img src="/img/in-post/2020-08-22/product-partitions.png" width="6500px" alt="product partitions" />
-
-而 BOCD 会估计当前时刻的 run length（距离上一个变点已经过了多少时刻）的后验分布 $p(r_t \mid x_{1:t})$，$t$ 时刻的 run length 为 $r_t$。显然 $r_t$ 只可能有两种情况：
-
-$$
-x = 
-\begin{cases}
-   0 &t \text{ 时刻是变点} \\
-   r_{t-1} + 1 &t \text{ 时刻不是变点}
-\end{cases}
-$$
-
-那么一个可能的 $r_t$ 随 $t$ 的变化图如下（$r_t = 0$ 的时刻（$t=5, 11$）为变点）：
-
-<img src="/img/in-post/2020-08-22/run_length.png" width="500px" alt="run length" />
-
-除了 $p(r_t \mid x_{1:t})$ 以外，BOCD 还会估计 $p(x_{t+1} \mid x_{1:t})$，这样就能既预测变点（run lenght），又预测下一个数据点的值了。不过如果单纯只求变点的话，$p(x_{t+1} \mid x_{1:t})$ 是没必要算的。
-
-
-## 一个递推式
-
-如果不想看推导过程，可以直接[跳到](#递推流程)这里看结果。
-
-### 下一个数据点的分布
-
-$p(x_{t+1} \mid x_{1:t})$ 可以由给定 $r_t$ 时 $x_{t+1}$ 的边缘分布算出来：
-
-$$
-\begin{aligned}
-    p(x_{t+1} \mid x_{1:t})&= \sum_{r_t} p(x_{t+1}, r_t \mid x_{1:t}) & \text{(边缘概率公式)} \\
-        &= \sum_{r_t} p(x_{t+1} \mid r_t, x_{1:t}) p(r_t \mid x_{1:t}) & \text{(链式法则)}\\
-        &= \sum_{r = 0}^t p(x_{t+1} \mid r_t = r, x_{(t - r):t}) p(r_t \mid x_{1:t}) & \text{(假设 1)}\\
-        &= \sum_{r_t} p(x_{t+1} \mid r_t, x_t^{(r)}) p(r_t \mid x_{1:t}) & 
-\end{aligned}
-$$
-
-其中 $x_t^{(r)} = x_{(t - r):t}$ 为 run length $= r$ 时当前 partion 的观测点集合，因为我们只会用当前 partion 的数据来预测 $x_{t+1}$ 的分布（假设 1）。因为 $r_t$ 可能为 0，所以 $x_t^{(r)}$ 可能为空集。
-
-
-### run length 的分布
-
-那么我们就需要计算 run length 的分布 $p(r_t \mid x_{1:t})$：
-
-$$
-p(r_t \mid x_{1:t}) = \frac{p(r_t, x_{1:t})}{p(x_{1:t})}
-$$
-
-那么我们需要算联合概率 $p(r_t, x_{1:t})$：
-
-$$
-\begin{aligned}
-    p(r_t, x_{1:t})&= \sum_{r_{t-1}} p(r_t, r_{t-1}, x_{1:t}) & \text{(边缘概率公式)} \\
-        &= \sum_{r_{t-1}} p(r_t, r_{t-1}, x_{1:t-1}, x_t) & \\
-        &= \sum_{r_{t-1}} p(r_t, x_t \mid r_{t-1}, x_{1:t-1}) p(r_{t-1}, x_{1:t-1}) & \text{(链式法则)} \\
-        &= \sum_{r_{t-1}} p(x_t \mid \cancel{r_t}, r_{t-1}, x_{1:t-1}) p(r_t \mid r_{t-1}, \cancel{x_{1:t-1}}) p(r_{t-1}, x_{1:t-1}) & \text{(链式法则)} \\
-        &= \sum_{r_{t-1}} p(x_t \mid r_{t-1}, x^{(r)}) p(r_t \mid r_{t-1}) p(r_{t-1}, x_{1:t-1}) & \text{(假设 1, 2)}
-\end{aligned}
-$$
-
-最后一步能成立依赖于以下两个假设：
-
-1. 前面提到的假设 1，即只用当前 partion 的数据来预测 $x_t$ 的分布：
-
-    $$
-    p(x_t \mid r_t, r_{t-1}, x_{1:t-1}) = p(x_t \mid r_{t-1}, x_{t-1}^{(r)}) \tag{\text{假设 1}}
-    $$
-
-    因为 $r_t$ 只依赖于 $r_{t-1}$（假设 2），所以这里 $r_t$ 也可以省掉。
-
-2. $r_t$ 只依赖于 $r_{t-1}$。即给定 $r_{t-1}$，$r_t$ 对其他所有变量都条件独立：
-
-    $$
-    p(r_t \mid r_{t-1}, x_{1:t-1}) = p(r_t \mid r_{t-1}) \tag{\text{假设 2}}
-    $$
-
-
-### 递推流程
-
-可以看到求 $p(x_{t+1} \mid x_{1:t})$ 的过程是一个递推的过程。在 $t$ 时刻，$p(r_{t-1}, x_{1:t-1})$ 已经计算出来了，现在我们要求 $p(x_{t+1} \mid r_t, x_t^{(r)})$，那么计算流程为：
-
-1. 计算变点的先验 $p(r_t \mid r_{t-1})$
-
-2. 计算 run length $r_t$ 的后验分布：$p(r_t \mid x_{1:t}) = \frac{p(r_t, x_{1:t})}{p(x_{1:t})}$
-
-    其中：
-
-    $$
-    p(r_t, x_{1:t}) = \sum_{r_{t-1}} \underbrace{p(x_t \mid r_{t-1}, x_{t-1}^{(r)})}_{\text{UPM}} \underbrace{p(r_t \mid r_{t-1})}_{\text{变点先验}} \underbrace{p(r_{t-1}, x_{1:t-1})}_{\text{已求得的信息}} \\[1pt]
-    $$
-
-3. 计算新数据点的分布 $p(x_{t+1} \mid x_{1:t})$：
-
-    $$
-    p(x_{t+1} \mid x_{1:t}) = \sum_{r_t} \underbrace{p(x_{t+1} \mid r_t, x_t^{(r)})}_{\text{UPM}} \underbrace{p(r_t \mid x_{1:t})}_{\text{已求得的信息}} \\[1pt]
-    $$
-
-可以看到，我们还需要计算的两个式子是：
-
-- $p(x_t \mid r_{t-1}, x_{t-1}^{(r)})$ 和 $p(x_{t+1} \mid r_t, x_t^{(r)})$：为了方便，我们按照本文~~抄~~参考的[博客](http://gregorygundersen.com/blog/2019/08/13/bocd/)的叫法，把它称为 Underlying Probabilistic Model（UPM），它的求法将在[这一节](#upm)解释
-
-- 变点先验 $p(r_t \mid r_{t-1})$：它的求法将在[这一节](#变点先验)解释
-
-这张图说明了这个递推流程：
-
-<img src="/img/in-post/2020-08-22/message_passing.png" width="400px" alt="message passing" />
-
-<p class="desc">图片来源：<a href="http://gregorygundersen.com/blog/2019/08/13/bocd/" target="_blank">Blog: Bayesian Online Changepoint Detection</a></p>
-
-
-当然，在开始这个递推流程之前，我们需要手动定义初始值 $p(r_0, x = \empty) = p(r_0)$，定义方式将在[这一节](#递推初始值)解释。
-
-
-## 变点先验
-
-贝叶斯方法的特点就是能利用先验信息，所以我们可以把我们对变点的先验估计通过 hazard function 塞进模型里。
-
-我们假设：
-
-$$
-p(r_t \mid r_{t-1}) = 
-\begin{cases}
-   H(r_{t-1} + 1) &\text{if } r_t = 0 \\
-   1 - H(r_{t-1} + 1) &\text{if } r_t = r_{t-1} + 1 \\
-   0 &\text{otherwise}
-\end{cases}
-$$
-
-$H(\tau)$ 是 hazard function，描述的是个体在 $\tau$ 时刻死亡的概率（...）。当然“死亡”这个词可以换成别的什么特殊事件，比如在这里 $H(\tau)$ 描述的就是在 run length $= \tau$ 时（在这之前都没出现变点）出现变点的概率。
-
-### Survival Function
-
-设 $T \geq 0$ 是一个表示当前 run length 长度的随机变量。$S(\tau)$ 是 survival function，表示 run length 超过 $\tau$ 的概率：
-
-$$
-S(\tau) = P(T \geq \tau) = 1 - F(\tau) = \sum_{\tau' = \tau}^\infty f(\tau')
-$$
-
-其中 $F(\tau) = P(T < \tau)$。$f(\tau)$ 表示当前 run length $= \tau$ 的概率，是一个概率密度函数。可以看到有：
-
-$$
-f(\tau) = F'(\tau) = -\frac{d S(\tau)}{d \tau}
-$$
-
-
-### Hazard Function
-
-那么由 hazard function 的定义：
-
-$$
-\begin{aligned}
-    H(\tau) &= \lim_{\Delta \tau \rarr 0} \frac{p(\tau \leq T < \tau + \Delta \tau \mid T \geq \tau)}{\Delta \tau} \\
-        &= \lim_{\Delta \tau \rarr 0} \frac{p(\tau \leq T < \tau + \Delta \tau)}{p(T \geq \tau) \Delta \tau} \\
-        &= \frac{f(\tau)}{S(\tau)}
-\end{aligned}
-$$
-
-这里 $f(\tau)$ 是我们自己定的一个先验。
-
-当 $f(\tau)$ 正好被定为一个指数分布（或几何分布（离散））时：
-
-$$
-f(\tau) = \lambda e^{- \lambda \tau}
-$$
-
-$$
-F(\tau) = 1- e^{- \lambda \tau}
-$$
-
-$$
-S(\tau) = 1- F(\tau) = e^{- \lambda \tau}
-$$
-
-此时 $H(\tau) = \frac{f(\tau)}{S(\tau)} = \lambda$ 是一个常数（但论文里面写的是 $\frac{1}{\lambda}$，我也不知道我哪里推错了...）。
-
-
-## 递推初始值
-
-我们需要给 $p(r_0)$ 赋一个初始值，分为两种情况：
-
-1. 第一个观测到的数据点之前（$t=0$）就是一个变点。论文中给的例子是对游戏数据序列建模，游戏开始的时刻一定是个变点。那么显然有：
-
-    $$
-    p(r_0 = 0) = 1
-    $$
-
-    但这个假设并不总是成立。
-
-2. 假设我们现在有最近一段时间的历史数据，并且我们认为第一个变点会在未来某个时刻出现。论文给的例子是对气象数据建模。这时初始值为归一化后的 survival function：
-
-    $$
-    p(r_0 = \tau) = \frac{1}{Z} \sum_{\tau' = \tau + 1}^\infty f(\tau')
-    $$
-
-    其中 $Z$ 是一个归一化常数。
-
-## UPM
-
-好的那么现在 $p(x_{t+1} \mid r_t, x_t^{(r)})$ 就是最后一个要算的东西了，我们把它写成边缘分布：
-
-$$
-p(x_{t+1} \mid r_t, x_t^{(r)}) = \int \underbrace{p(x_{t+1} \mid \eta)}_{\text{EF model}} \underbrace{p(\eta_t^{(r)} = \eta \mid r_t, x_t^{(r)})}_{\text{EF posterior}} d \eta \\[1pt]
-$$
-
-$\eta_t^{(r)}$ 表示在 $t$ 时刻 run length $= r$ 时的超参数，第一项的意义是 $x$ 服从参数为 $\eta$ 的**指数族分布（Exponential Family）**，然后对这个指数族分布建模。第二项是 $\eta$ 的后验。
-
-$\eta$ 的后验并不好计算，而且这里还要对每个 $\eta$ 求积分，也不好算。所以我们往往希望 $\eta$ 的先验跟它的似然**共轭（conjugate）**，使得先验与后验的形式相同，这样就能简化计算。
-
-
-### 共轭先验
-
-假设 $X$ 是已经观测到的数据，$\hat{x}$ 是要预测的新数据点，$\eta$ 是模型参数，$\alpha$ 是超参数。那么：
-
-$$
-p(\hat{x} \mid X, \alpha) = \int \underbrace{p(\hat{x} \mid \eta)}_{\text{model}} \underbrace{p(\eta \mid X, \alpha)}_{\text{posterior}} d \eta
-$$
-
-这里 $\eta$ 的先验跟它的似然是共轭的，所以 $\eta$ 的后验跟它的先验的形式相同，只是超参数不同：
-
-$$
-p(\eta \mid X, \alpha) = p(\eta \mid \alpha')
-$$
-
-那么有：
-
-$$
-\begin{aligned}
-    p(\hat{x} \mid X, \alpha) &= \int p(\hat{x} \mid \eta) p(\eta \mid X, \alpha) d \eta \\
-        &= \int p(\hat{x} \mid \eta) p(\eta \mid \alpha') d \eta \\
-        &= p(\hat{x} \mid \alpha')
-\end{aligned}
-$$
-
-也就是说 $\hat{x}$ 的后验跟它的先验的形式也是相同的。如果我们能算出 $\eta$ 的后验的超参数 $\alpha'$，就能在不直接算后验 $p(\eta \mid X, \alpha)$ 也不算积分的情况下直接算出 $p(\hat{x} \mid X, \alpha)$。
-
-而当 $\eta$ 的似然是指数族分布时，就一定能写出其共轭先验分布，且后验的超参数 $\alpha'$ 能够很轻松的求出来。
-
-
-
-### 指数族分布
-
-指数族是一类分布，包括高斯分布、伯努利分布、二项分布、泊松分布、Beta 分布、Dirichlet 分布、Gamma 分布等一系列分布。指数族分布可以写为统一的形式：
-
-$$
-\begin{aligned}
-    p(x \mid \eta) &= h(x) \exp (\eta^\top U(x) - A(\eta)) \\
-        &= \frac{1}{\exp(A(\eta))} h(x) \exp (\eta^\top U(x)) \\
-        &= g(\eta) h(x) \exp (\eta^\top U(x))
-\end{aligned}
-$$
-
-其中，$h(x)$ 是 underlying measure（没找到啥合适的翻译）；$U(x)$ 是充分统计量（sufficient statistic），包含样本集合的所有信息，如高斯分布中的均值 $\mu$ 和方差 $\sigma$；$g(\eta) = \frac{1}{\exp(A(\eta))}$ 是正则函数（normalizer）；$A(\eta)$ 是对数正则函数（log normalizer），用于保证：
-
-$$
-\frac{1}{\exp(A(\eta))} \int h(x) \exp (\eta^\top U(x)) dx = 1
-$$
-
-$A(\eta)$ 叫 log normalizer 这个名字是因为由上式可以推出：
-
-$$
-A(\eta) = \log \int h(x) \exp (\eta^\top U(x)) dx
-$$
-
-跟似然 $p(x \mid \eta)$ 共轭的 $\eta$ 的先验为：
-
-$$
-p(\eta \mid \chi, \nu) = f(\chi, \nu) g(\eta)^{\nu} \exp ( \eta^{\top} \chi )
-$$
-
-其中 $\chi, \nu$ 是超参数，$f(\chi, \nu)$ 取决于指数族分布的具体形式。
-
-由[贝叶斯公式](/2020/08/16/bayesian-neural-network/#贝叶斯估计)，后验正比于似然 $\times$ 先验，所以：
-
-$$
-\begin{aligned}
-    p(\eta \mid X, \chi, \nu) & \propto p(X \mid \eta) p(\eta \mid \chi, \nu) \\
-        & \propto \underbrace{\vphantom{\Bigg|} \left ( \Big ( \prod_{i=1}^N h(x_n) \Big ) g(\eta)^N \exp (\eta^\top \sum_{n=1}^N u(x_n)) \right )}_{\text{似然}} \underbrace{\vphantom{\Bigg|} \Big ( f(\chi, \nu) g(\eta)^{\nu} \exp ( \eta^{\top} \chi ) \Big )}_{\text{先验}} \\
-        & \propto \Big ( \prod_{i=1}^N h(x_n) \Big ) f(\chi, \nu) g(\eta)^{N + \nu} \exp \Big (\eta^\top \sum_{n=1}^N u(x_n) + \eta^{\top} \chi \Big ) \\
-        & \propto g(\eta)^{N + \nu} \exp \Big (\eta^\top \sum_{n=1}^N u(x_n) + \eta^{\top} \chi \Big )
-\end{aligned}
-$$
-
-最后一步是因为 $\Big ( \prod_{i=1}^N h(x_n) \Big ) f(\chi, \nu)$ 是跟 $\eta$ 无关的，所以可以去掉。
-
-可以看到后验 $p(\eta \mid X, \chi, \nu)$ 跟先验 $p(\eta \mid \chi, \nu)$ 的形式是一样的，只是超参数上有区别：
-
-$$
-\nu' = \nu_{\text{prior}} + N
-$$
-
-$$
-\chi' = \chi_{\text{prior}} + \sum_{n=1}^N u(x_n)
-$$
-
-所以如果似然是指数族分布，那么在先验的超参数上加一个项就可以得到后验的超参数，是种很简便的方法。
-
-
-### 又一个递推
-
-现在 $p(x_{t+1} \mid r_t, x_t^{(r)})$ 可以被表示成 $p(x_{t+1} \mid \nu_t^{(r)}, \chi_t^{(r)})$，相当于我们的目标变成了求 $\nu_t^{(r)}$ 和 $\chi_t^{(r)}$，而且要对每一个可能的 $r_t = r \leq t$（即 $X = x_t^{(r)} = x_{(t-r): t}$）都算一个 $\nu_t^{(r)}$ 和 $\chi_t^{(r)}$：
-
-$$
-\nu_t^{(r)} = \nu_{t-1}^{(r-1)} + 1
-$$
-
-$$
-\chi_t^{(r)} = \chi_{t-1}^{(r-1)} + u(x_t)
-$$
-
-$$
-\nu_t^0 = \nu_{\text{prior}}
-$$
-
-$$
-\chi_t^0 = \chi_{\text{prior}}
-$$
-
-这个递推的过程大概是这样：
-
-<img src="/img/in-post/2020-08-22/parameter_updates.png" width="450px" alt="parameter updates" />
-
-<p class="desc">图片来源：<a href="http://gregorygundersen.com/blog/2019/08/13/bocd/" target="_blank">Blog: Bayesian Online Changepoint Detection</a></p>
-
-
-
-## 完整算法
-
-有空再说，我先摸下🐟...
-
-
-## 参考
-
-- [Bayesian Online Changepoint Detection.](https://arxiv.org/pdf/0710.3742.pdf) *Ryan Prescott Adams and David J.C. MacKay.* arXiv 2007. (original paper)
-
-- [Bayesian Online Changepoint Detection](http://gregorygundersen.com/blog/2019/08/13/bocd/) (a blog by Gregory Gundersen)
-
-- [Bayesian online change point detection — An intuitive understanding](https://medium.com/scientya/bayesian-online-change-point-detection-an-intuitive-understanding-b2d2b9dc165b) (a blog on Medium)
-
-- [Survival Analysis: Techniques for Censored and Truncated Data.](https://books.google.nl/books?hl=zh-CN&lr=&id=aO7xBwAAQBAJ&oi=fnd&pg=PR1&ots=8jU8XPsdJP&sig=BQuvnchfXc587ejQr1dpJaCFQOw#v=onepage&q&f=false) *John P. Klein and Melvin L. Moeschberger.* Springer Science & Business Media, 2006.
-
-- [指数族分布](https://www.yuque.com/books/share/f4031f65-70c1-4909-ba01-c47c31398466/ioggkd)
Index: blog/posts/2020-03-17-papers-reading.md
===================================================================
diff --git a/blog/posts/2020-03-17-papers-reading.md b/blog/posts/2020-03-17-papers-reading.md
deleted file mode 100644
--- a/blog/posts/2020-03-17-papers-reading.md	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
+++ /dev/null	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
@@ -1,905 +0,0 @@
----
-layout: Post
-title: 三月大锅烩
-subtitle: "Papers Reading: Machine Translation / Text Classification / Image Captioning"
-author: Renovamen
-date: 2020-03-17
-headerImage: /img/in-post/2020-03-17/header.jpg
-permalinkPattern: /post/:year/:month/:day/:slug/
-tags:
-  - NLP
-  - CV
-  - Machine Translation
-  - Text Classification
-  - Image Captioning
-  - Image Aesthetic Captioning
----
-
-
-看过的关于机器翻译 / 文本摘要 / 图像描述的论文的总结，到时候大概也可以直接复制粘贴进毕业论文里。
-
-<!-- more -->
-
-## Machine Translation
-
-给定源语言句子 $x$，目标是最大化其对应的目标语言翻译 $y$ 的概率，即：
-
-$$
-\hat{y} = \arg \max_y p(y \mid x)
-$$
-
-
-### Seq2Seq 
-
-**Sequence to Sequence Learning with Neural Networks.** *Ilya Sutskeve, Oriol Vinyals and Quoc V. Le.* NIPS 2014. [[Paper]](https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)
-
-提出了 Sequence to Sequence 框架，由一个 encoder 和一个 decoder 组成。
-
-![seq2seq](/img/in-post/2020-03-17/machine-translation/seq2seq.png)
-
-
-#### Encoder
-
-一个 LSTM，用于把源语言句子 $x = (x_1, ... , x_{T_x})$ 编码成一个固定长度的向量 $c$：
-
-$$
-h_t = f_1 (x_t, h_{t-1}) 
-$$
-
-$$
-c = h_{T_x}
-$$
-
-即 LSTM 最后一个时间步输出的隐状态就是句子编码后的向量。\<EOS\> 是终止符，不用编码。
-
-
-#### Decoder
-
-一个 LSTM，用于生成目标语言翻译 $y = (y_1, ... , y_{T_y})$，第一个时间步的输入是 $c$，生成终止符 \<EOS\> 后停止句子生成。
-
-把[上述](#machine-translation)联合概率用链式法则分解后得到：
-
-$$
-p(y) = \prod_{t=1}^T p(y_t \mid \{ y_1, ..., y_{t-1} \}, c)
-$$
-
-每个时间步的条件概率为：
-
-$$
-p(y_t \mid \{ y_1, ..., y_{t-1} \}, c) = g(y_{t-1}, s_t, c)
-$$
-
-$$
-s_i = f_2 (s_{i-1}, y_{i-1})
-$$
-
-$g$ 是一个非线性函数，用于输出单词 $y_t$ 的概率（比如 softmax），$s_t$ 是 LSTM（decoder）在 $t$ 时刻的隐状态。
-
-
-### Seq2Seq + Attention
-
-**Neural Machine Translation by Jointly Learning to Align and Translate.** *Dzmitry Bahdanau, Kyunghyun Cho and Yoshua Bengio.* ICLR 2015. [[arXiv]](https://arxiv.org/pdf/1409.0473.pdf)
-
-首次把 attention 引入 seq2seq。
-
-<img src="/img/in-post/2020-03-17/machine-translation/seq2seq-attention.png" width="450px" alt="seq2seq attention" />
-
-#### Encoder
-
-encoder 是一个 BiLSTM，即有两个 LSTM：
-
-- 第一个把源句子正向输入（$x_1 \rightarrow x_{T_x}$），所有时间步输出的隐状态为 $(\overrightarrow{h_1}, ... , \overrightarrow{h_{T_x}})$
-
-- 第二个把源句子逆向输入（$x_{T_x} \rightarrow x_1$），所有时间步输出的隐状态为 $(\overleftarrow{h_1}, ... , \overleftarrow{h_{T_x}})$
-
-最终，encoder 每个时间步的输出就是把 $\overrightarrow{h_j}$ 和 $\overleftarrow{h_j}$ 拼起来：
-
-$$
-h_j = [\overrightarrow{h_j}; \overleftarrow{h_j}]
-$$
-
-所有时间步的输出为：
-
-$$
-(h_1, ..., h_{T_x})
-$$
-
-
-#### Decoder
-
-把每个时间步的条件概率定义为：
-
-$$
-p(y_i \mid y_1, ... , y_{i-1}, x) = g(y_{i-1}, s_i, c_i)
-$$
-
-$s_i$ 是 LSTM 在 $i$ 时刻的隐状态：
-
-$$
-s_i = f(s_{i-1}, y_{i-1}, c_i)
-$$
-
-$c_i$ 是 $i$ 时刻的 context vector，通过把 encoder 每个时间步的输出向量加权平均得到：
-
-$$
-c_i = \sum_{j=1}^{T_x} \alpha_{ij} h_j
-$$
-
-$\alpha_{ij}$ 是 $h_j$ 的权重，计算公式为：
-
-$$
-e_{ij} = a(s_{i-1}, h_j)
-$$
-
-$$
-\alpha_{ij} = \frac{\exp (e_{ij})}{\sum_{k=1}^{T_x} \exp (e_{ik})}
-$$
-
-$a$ 是一个 MLP，$\alpha_{ij}$ 由 $e_{ij}$ 归一化（softmax）后得到。相当于 $\alpha_{ij}$ 代表了在生成第 $i$ 个目标句子单词时，第 $j$ 个源句子单词的重要性。
-
-
-### Unsupervised NMT
-
-**Unsupervised Neural Machine Translation.** *Mikel Artetxe, et al.* ICLR 2018. [[arXiv]](https://arxiv.org/pdf/1710.11041.pdf) [[Code]](https://github.com/artetxem/undreamt)
-
-**Unsupervised Machine Translation Using Monolingual Corpora Only.** *Guillaume Lample, et al.* ICLR 2018. [[Paper]](https://research.fb.com/wp-content/uploads/2018/03/unsupervised-machine-translation-using-monolingual-corpora-only.pdf)
-
-
-## Text Classification
-
-### Hierarchical Attention Network
-
-**Hierarchical Attention Networks for Document Classification.** *Zichao Yang, et al.* NAACL 2016. [[Paper]](https://www.aclweb.org/anthology/N16-1174.pdf)
-
-- 用“词-句子-文档”的层次化结构来表示一篇文档，用词向量来表示句子向量，然后用句子向量来表示文档向量。
-
-- 两个层次的 attention (word attention 和 sentence attention)。动机是文档中不同的句子和单词的重要性不同，且词和句子的重要性依赖于上下文。
-
-<img src="/img/in-post/2020-03-17/text-classification/HAN.png" width="450px" alt="HAN" />
-
-
-#### Word Encoder
-
-双向 [GRU](/2019/02/15/rnn-with-its-friends/#gru)：
-
-$$
-\overrightharpoon{h}_{it} = \overrightharpoon{\text{GRU}} (x_{it}), t \in [1, T]
-$$
-
-$$
-\overleftharpoon{h}_{it} = \overleftharpoon{\text{GRU}} (x_{it}), t \in [T, 1]
-$$
-
-$$
-h_{it} = [\overrightharpoon{h}_{it}; \overleftharpoon{h}_{it}]
-$$
-
-$x_{ij} = W_e w_{ij}$ 是文档中第 $i$ 个句子的第 $t$ 个单词的词嵌入向量，$T$ 为该句子中的单词个数。
-
-
-#### Word Attention
-
-对每个 $h_{it}$ 计算一个权重（MLP + softmax），然后加权平均得到句子向量 $s_i$：
-
-$$
-u_{it} = \text{tanh} (W_w h_{it} + b_w)
-$$
-
-$$
-\alpha_{it} = \frac{\exp (u_{it}^{\top} u_w)}{\sum_t \exp (u_{it}^{\top} u_w)}
-$$
-
-$$
-s_i = \sum_t \alpha_{it} h_{it}
-$$
-
-softmax 中，$u_w$ 是一个随机初始化的 context vector，用于表示哪些词更重要。
-
-
-#### Sentence Encoder
-
-依然是双向 GRU，只不过输入为上一步得到的句子向量 $s_i$：
-
-$$
-\overrightharpoon{h}_i = \overrightharpoon{\text{GRU}} (s_i), t \in [1, L]
-$$
-
-$$
-\overleftharpoon{h}_i = \overleftharpoon{\text{GRU}} (s_i), t \in [L, 1]
-$$
-
-$$
-h_i = [\overrightharpoon{h}_i; \overleftharpoon{h}_i]
-$$
-
-其中，$L$ 为文档中的句子个数。
-
-#### Sentence Attention
-
-对每个 $h_i$ 计算一个权重（MLP + softmax），然后加权平均得到文档向量 $v$：
-
-$$
-u_i = \text{tanh} (W_s h_i + b_s)
-$$
-
-$$
-\alpha_{it} = \frac{\exp (u_i^{\top} u_s)}{\sum_t \exp (u_i^{\top} u_s)}
-$$
-
-$$
-v = \sum_t \alpha_i h_i
-$$
-
-$u_s$ 依然是是一个随机初始化的 context vector，用于表示哪些句子更重要。
-
-#### Document Classification
-
-最后把文档向量 $v$ 扔进 softmax 来进行分类：
-
-$$
-p = \text{softmax} (W_c v + b_c)
-$$
-
-损失函数为：
-
-$$
-L = - \sum_d \log p_{dj}
-$$
-
-$p_{dj}$ 是文档 $d$ 的真实标签 $j$ 出现的概率。
-
-
-## Image Captioning
-
-### Show and Tell
-
-**Show and Tell: A Neural Image Caption Generator.** *Oriol Vinyals, et al.* CVPR 2015. [[Paper]](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Vinyals_Show_and_Tell_2015_CVPR_paper.pdf) [[Code]](https://github.com/tensorflow/models/tree/master/research/im2txt)
-
-
-Google 出品，算是最早开用 CNN-LSTM 做 Image Captioning 这个坑的论文之一。
-
-**P.S.** 依然是在 CVPR 2015 上，Stanford 也发了篇模型核心结构差不多的论文：
-
-**Deep Visual-semantic Alignments for Generating Image Descriptions.** *Andrej Karpathy and Li Fei-Fei.* CVPR 2015. [[Paper]](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Karpathy_Deep_Visual-Semantic_Alignments_2015_CVPR_paper.pdf) [[NeuralTalk]](https://github.com/karpathy/neuraltalk) [[NeuralTalk2]](https://github.com/karpathy/neuraltalk2)
-
-但鉴于 NeuralTalk 的代码是用 Lua 和 Torch 写的，而我不会 Lua 和 Torch（...），所以这篇论文就没认真看......
-
-
-#### CNN-LSTM
-
-**模型目标：**
-
-$$
-\theta^* = \arg \max_{\theta} \sum_{(I,S)} \log p(S \mid I; \theta)
-$$
-
-$\theta$ 是模型参数，$I$ 是图像，$S$ 是对应的正确的图像描述。也就是要最大化正确描述的概率。
-
-为了解决解决 $S$ 的长度不定的问题，用条件概率的链式法则来把上述联合概率分解成以下形式，这里为了方便扔掉了模型参数 $\theta$：
-
-$$
-\log p(S \mid I) = \sum_{t=0}^N \log p(S_t \mid I, S_0, ... , S_{t-1})
-$$
-
-$S_0$ 是起始符，$S_N$ 是终止符。如果生成了终止符，则该句子生成结束。
-
-
-**LSTM：**
-
-在 LSTM 中，每个时间步的条件概率可以表示为：
-
-$$
-\log p(S_t \mid S_1, ... , S_{t-1}, I) = k(h_t, z_t)
-$$
-
-$k$ 是一个非线性函数，输出为单词 $S_t$ 的概率。$h_t$ 是 LSTM 在当前时间步的隐状态。$z_t$ 是图像特征，在这里是 CNN 最后一个全连接层输出的一个向量；在加了 Attention 机制的 LSTM 中则是每个时间步对 CNN 最后一个卷积层输出的特征图进行 Attention 操作后得到的一个向量，依赖于 $h_t$。
-
-新的 $x_t$ 输入后，隐状态更新的公式为：
-
-$$
-h_{t} = f(x_t, h_{t-1}, c_{t-1})
-$$
-
-$c_{t-1}$ 是 LSTM 在上一时间步的细胞状态。
-
-**CNN：**
-
-用来提图像特征的 CNN 直接用了 Inception V3：
-
-**Rethinking the Inception Architecture for Computer Vision.** *Christian Szegedy, et al.* CVPR 2016. [[Paper]](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Szegedy_Rethinking_the_Inception_CVPR_2016_paper.pdf) [[Code]](https://github.com/tensorflow/models/blob/master/research/slim/nets/inception_v3.py)
-
-#### LSTM
-
-在[另一篇文章](/post/2019/02/15/rnn-with-its-friends/#lstm)里理过 LSTM。
-
-<img src="/img/in-post/2020-03-17/img2txt/lstm.png" width="350px" alt="LSTM" />
-
-##### Training
-
-把 LSTM 按时间步展开就是这个样子：
-
-<img src="/img/in-post/2020-03-17/img2txt/cnn-lstm.png" width="450px" alt="CNN-LSTM" />
-
-这样看起来就像一个前馈网络了。
-
-假设输入的图片为 $I$，它的正确描述为 $S = (S_0, ... , S_N )$，则展开过程为：
-
-$$
-x_{-1} = \text{CNN}(I)
-$$
-
-$$
-x_t = W_e S_t, t \in \{ 0 ... N-1 \}
-$$
-
-$$
-p_{t+1} = \text{LSTM} (x_t), t \in \{ 0 ... N-1 \}
-$$
-
-其中，$S_t$ 是经过独热编码的单词，都是 $1 \times D$ 的向量，$D$ 是词典大小；$W_e$ 是 word embedding；$p_t$ 是每个时间步输出的所有单词的概率分布。
-
-图片 $I$ 只在 $t = -1$ 时输入一次，因为论文经过实验后发现如果每个时间步都输入一遍图像，模型会更容易过拟合和学习到图像的噪声。（[这里](https://github.com/ruotianluo/ImageCaptioning.pytorch/blob/master/models/OldModel.py)复现了这种做法）
-
-损失函数：
-
-$$
-L(I,S) = - \sum_{t=1}^N \log p_t (S_t)
-$$
-
-目标是通过调 CNN、LSTM 和 $W_e$ 的参数让 Loss 最小。
-
-**训练细节**：
-
-- 用在 ImageNet 上训练好的预训练模型来初始化 CNN 参数，效果提升明显；
-- 用在一个新闻语料库上训练好的预训练模型来初始化 $W_e$ 参数，效果提升不明显；
-- 尝试 dropout 和 ensembling，效果提升了一些；
-- 调 LSTM hidden units 的数量，最后设成了 512，embedding 维度也设成了 512；
-- 除了 CNN 以外，其他部分都用 SGD 来调参，随机初始化参数，固定学习率，无 momentum;
-- 词典中只保留出现次数 > 5 的单词
-
-
-##### Inference
-
-在测试生成句子时使用了 beam search，beam size 设为 20。当把 beam size 设为 1（相当于 greedy search）时，BLEU 值降了 2 点左右。
-
-
-#### Experiments
-
-<img src="/img/in-post/2020-03-17/img2txt/img2txt-result.png" width="400px" alt="result" />
-
-
-### Show, Attend and Tell
-
-**Show, Attend and Tell: Neural Image Caption Generation with Visual Attention.** *Kelvin Xu, et al.* ICML 2015. [[Paper]](http://proceedings.mlr.press/v37/xuc15.pdf) [[Code]](https://github.com/kelvinxu/arctic-captions)
-
-由于原版代码是用（我不会的）Theano 写的，所以这里是俩用（我大概会的）PyTorch 写的复现代码：
-
-- [sgrvinod/a-PyTorch-Tutorial-to-Image-Captioning](https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Image-Captioning)
-  
-  这个代码写得是真的好...
-
-- [ruotianluo/ImageCaptioning.pytorch](https://github.com/ruotianluo/ImageCaptioning.pytorch)
-  
-  实现了很多模型，作者还有一个名为 [self-critical.pytorch](https://github.com/ruotianluo/self-critical.pytorch) 的加强版 repo...
-
-
-首次把 Attention 机制用进 Image Captioning 中。
-
-在上述 Encoder-Decoder 结构中，Encoder 和 Decoder 之间唯一的联系只有一个固定长度的语义向量 $x_{-1}$，所以 Encoder 必须把原始输入的所有信息都压进 $x_{-1}$ 中。如果原始输入包含的信息较多， $x_{-1}$ 可能就无法表达所有信息。而且 $x_{-1}$ 携带的信息还可能被后面输入的信息覆盖掉。
-
-于是就有了 Attention 机制，最先把它用在 seq2seq 结构中的论文是这篇做机器翻译的：
-
-**Neural Machine Translation by Jointly Learning to Align and Translate.** *Dzmitry Bahdanau, KyungHyun Cho, and Yoshua Bengio.* arXiv 2014. [[arXiv]](https://arxiv.org/pdf/1409.0473.pdf)
-
-#### CNN
-
-CNN 用了 VGGNet。
-
-前面的论文是用全连接层输出的一个固定长度的向量当特征（高层特征），而这篇论文用了最后一个卷积层（用 Keras 的话说是 block5_conv3）的 $H \times W \times D$（$14 \times 14 \times 512$）的特征图来当特征（低层特征）：
-
-$$
-a = \{ \bold{a}_1, ..., \bold{a}_L \}, \bold{a}_i \in \reals^D
-$$
-
-<img src="/img/in-post/2020-03-17/show-attend-tell/vggnet-arrow.png" width="500px" alt="VGGNet" />
-
-<p class="desc">VGGNet 结构</p>
-
-其中 $H$ 和 $W$ 为特征图的高度和宽度，$D$ 为特征图的维度，$L = H \times W$。相当于对于图片的 $L$ 个位置各提一个特征，每个特征都是一个 $D$ 维向量（annotation vector）。
-
-于是接下来的 LSTM 就需要在这 $L$ 个位置的特征里选有用的，这就是 Attention 机制。
-
-#### LSTM + Attention
-
-以下是论文里给的 LSTM 结构图和推导公式：
-
-- LSTM 结构：
-
-  <img src="/img/in-post/2020-03-17/show-attend-tell/attention-lstm.png" width="400px" alt="LSTM" />
-
-- 推导公式：
-
-  $$
-  i_t = \sigma (W_i E y_{t-1} + U_i h_{t-1} + Z_i \hat{z}_t + b_i)
-  $$
-
-  $$
-  f_t = \sigma (W_f E y_{t-1} + U_f h_{t-1} + Z_f \hat{z}_t + b_f )
-  $$
-
-  $$
-  c_t = f_t c_{t-1} + i_t \text{tanh} (W_c E y_{t-1} + U_c h_{t-1} + Z_c \hat{z}_t + b_c)
-  $$
-
-  $$
-  o_t = \sigma (W_o E y_{t-1} + U_o h_{t-1} + Z_o \hat{z}_t + b_o)
-  $$
-
-  $$
-  h_t = o_t \text{tanh} (c_t)
-  $$
-
-但从代码实现来看（以原版代码为准），图应该画成这样（代码实现跟论文描述的出入会在后面提到）（图来自论文 [Adaptive Attention](#adaptive-attention)）：
-
-<img src="/img/in-post/2020-03-17/show-attend-tell/true-attention-lstm.png" width="400px" alt="True LSTM" />
-
-::: info 备注
-虽然在图和推导式里，上一步输出 $y_{t-1}$ 也参与了这一步的计算，但代码（原版和复现）里似乎没有参与。
-:::
-
-跟正常 LSTM 的区别是用 context vector $\hat{z}_t$ 来代替了当前输入 $x_t$。
-
-::: info 备注
-按论文里的描述是这样，即 $x_t$ 完全没有参与计算。但代码（原版和复现）里是把 $\hat{z}_t$ 和 $x_t$ 拼到了一起作为输入。
-:::
-
-$\hat{z}_t$ 由 $\phi$ 函数对 $\{ \bold{a}_1, ..., \bold{a}_L \}$ 进行一些加权得到，$\alpha_i$ 为 $\bold{a}_i$ 的权重：
-
-$$
-\hat{z}_t = \phi(\{\bold{a}_i\}, \{\alpha_i\})
-$$
-
-Soft Attention 和 Hard Attention 的不同在于 $\phi$ 的不同。在 **Soft Attention** 中：
-
-$$
-\hat{z}_t = \phi(\{\bold{a}_i\}, \{\alpha_i\}) = \beta \sum_i^L \alpha_{t,i} \bold{a}_i
-$$
-
-$\beta$ 是一个决定当前时间步要用多少 context 信息的门控信号：
-
-$$
-\beta = \sigma (f_{\beta} (h_{t-1}))
-$$
-
-相当于在 Soft Attention 中，$\alpha_{t,i}$ 代表图像的第 $i$ 个位置的特征 $\bold{a}_i$ 在 $t$ 时刻输入 Decoder 的信息所占的比例，即对 $\bold{a}_i$ 求加权平均。$\alpha_{t,i}$ 由 Attention 模型 $f_{att}$（也就是一个 MLP）计算得到：
-
-$$
-e_{ti} = f_{att}(\bold{a}_i, h_{t-1})
-$$
-
-然后把 $e_{ti}$ 归一化（softmax）后就得到了 $\alpha_{ti}$：
-
-$$
-\alpha_{ti} = \frac{\exp(e_{ti})}{\sum_{k=1}^L \exp(e_{tk})}
-$$
-
-
-除了标准化自带的 $\sum_i^L \alpha_{ti} = 1$ 这个限定以外，还对 $\alpha_{ti}$ 加了另一个限定，来避免图像某些部分的特征被忽略（论文里设的 $\tau = 1$）：
-
-$$
-\sum_t \alpha_{ti} \approx \tau, \tau \geq \frac{L}{D}
-$$
-
-所以 Soft Attention 模型的训练目标是要最小化以下惩罚函数：
-
-$$
-L_d = - \log(p(y \mid \bold{a})) + \lambda \sum_i^L (1 - \sum_t^C \alpha_{ti})^2
-$$
-
-细胞状态和隐状态初始值为（$f_{init, c}$ 和 $f_{init, h}$ 都是 MLP）：
-
-$$
-c_0 = f_{init, c} (\frac{1}{L} \sum_i^L \bold{a}_i)
-$$
-
-$$
-h_0 = f_{init, h} (\frac{1}{L} \sum_i^L \bold{a}_i)
-$$
-
-最终输出的单词概率分布为：
-
-$$
-p(y_t \mid \bold{a}, y_{t-1}) \propto  \exp (L_o (Ey_{t-1} + L_h h_t + L_z \hat{z}_t))
-$$
-
-其中，$L_o$、$L_h$、$L_z$、$E$ 都是需要学习的权重参数。
-
-::: info 备注
-似乎只有原版代码算是按照上面这个公式来算的单词概率（而且它依然没有考虑 $y_{t-1}$），俩复现代码都直接把 $h_t$ 扔进 softmax 完事，即：$y_t = \text{softmax}(h_t)$。
-:::
-
-
-#### Experiments
-
-![Result](/img/in-post/2020-03-17/show-attend-tell/attention-result.png)
-
-
-### Adaptive Attention
-
-**Knowing When to Look: Adaptive Attention via A Visual Sentinel for Image Captioning.** *Jiasen Lu, et al.* CVPR 2017. [[Paper]](http://openaccess.thecvf.com/content_cvpr_2017/papers/Lu_Knowing_When_to_CVPR_2017_paper.pdf) [[Code]](https://github.com/jiasenlu/AdaptiveAttention)
-
-
-不是每个单词的生成都需要利用图像特征，有的词的生成只需要依赖语义信息，如“the”、“of”等词，和跟在“talking on a cell”后面的“phone”等词。因此该论文的 Adaptive Attention 机制能决定当前时间步要用多少图像特征和多少语义信息。
-
-#### CNN
-
-用了 ResNet，最后一个卷积层输出 $2048 \times 7 \times 7$ 的特征图，表示为：
-
-$$
-A = \{ a_1, ..., a_k \}, a_i \in R^{2048}
-$$
-
-对每个向量做以下变换：
-
-$$
-v_i = \text{ReLU}(W_a a_i) 
-$$
-
-则最终的图像特征为：
-
-$$
-V = [v_1, ... , v_k]
-$$
-
-论文还算了一个全局图像特征，即把特征图中所有向量做个算术平均，然后做个类似的变换：
-
-$$
-a^g = \frac{1}{k} \sum_{i=1}^k a_i
-$$
-
-$$
-v^g = \text{ReLU} (W_b a^g)
-$$
-
-然后 LSTM 每个时间步的输入为把 word embedding 和 $v^g$ 拼到一起后的结果，即：
-
-$$
-x_t = [w_t; v^g]
-$$
-
-
-#### Spatial Attention
-
-首先对 Attention 机制做了一些修改：
-
-<img src="/img/in-post/2020-03-17/adaptive-attention/spatial-attention.png" width="500px" alt="Spatial Attention" />
-
-<p class="desc">(a)：Show, Attend and Tell 网络结构，(b)：该论文的 Spatial Attention 网络结构</p>
-
-与[上一篇论文](#show-attend-and-tell)的不同：
-
-- 计算 context vector $c_t$ 时用了 $h_t$ 而不是 $h_{t-1}$，论文认为这样 $c_t$ 就可以看作 $h_t$ 的残差连接，可以在生成下一个词时降低不确定性和提供当前时刻隐状态的信息，灵感来源于 [ResNet](http://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)
-
-
-- $c_t$ 没有输入 LSTM
-
-context vector $c_t$ 定义为：
-
-$$
-c_t = g(V, h_t)
-$$
-
-$V = [v_1, ... , v_k] , v_i \in R^d$ 是[上一步](#cnn-1)中操作出来的图像特征，$g$ 是 Attention 模型。
-
-$g$ 的具体实现如下，先算权重 $\alpha_t$（MLP + softmax）：
-
-$$
-z_t = w^T_h \text{tanh}(W_v V + (W_g h_t) \frak{1}^T) \tag{1}
-$$
-
-$$
-\alpha_t = \text{softmax}(z_t)
-$$
-
-
-$\frak{1} \in R^k$ 是一个元素全为 1 的向量，目的是跟 $W_g h_t$ 相乘得到 $k \times k$ 的矩阵。$W_v, W_g \in R^{k \times d}$
-和 $w_h \in R^k$ 都是要学习的权重参数。
-
-然后对 $V$ 加权平均，得到 $c_t$：
-
-$$
-c_t = \sum_{i=1}^k \alpha_{ti} v_{ti}
-$$
-
-
-#### Adaptive Attention
-
-<img src="/img/in-post/2020-03-17/adaptive-attention/adaptive-attention.png" width="400px" alt="Adaptive Attention" />
-
-在 LSTM 上新增了一个叫 visual sentinel 的向量 $s_t$，用于记录一部分的细胞状态：
-
-$$
-g_t = \sigma (W_x x_t + W_h h_{t-1})
-$$
-
-$$
-s_t = g_t \odot \text{tanh} (m_t)
-$$
-
-$g_t$ 是个门控信号，$m_t$ 是 $t$ 时刻的细胞状态，$\sigma$ 是 sigmoid 激活函数。跟 [LSTM 输出门](/2019/02/15/rnn-with-its-friends/#输出门)公式的形式是一样的，但是分别由不同的权重控制。
-
-于是 Adaptive Attention 中的 context vector $\hat{c}_t$ 为：
-
-$$
-\hat{c}_t = \beta_t s_t + (1 - \beta_t) c_t
-$$
-
-$\beta_t \in [0,1]$ 是一个控制 $t$ 时刻要利用多少 $s_t$（语义信息）和 $c_t$（图像特征）的门控信号（sentinel gate）。为了算出 $\beta_t$，把 Attention 权重的计算公式也做了修改，新的权重 $\hat{\alpha}$ 为：
-
-$$
-\hat{\alpha}_t = \text{softmax}([z_t; w^T_h \text{tanh}(W_s s_t + (W_g h_t))]) 
-$$
-
-相当于把 $z_t$ 跟 $w^T_h \text{tanh}(W_s s_t + (W_g h_t))$ 拼了起来。这里的 $W_g$ 跟公式 $(1)$ 中的 $W_g$ 是一样的，同时虽然论文中没说，但 $w^T_h$ 的确也是一样的。
-
-$\hat{\alpha}_t$ 有 $k+1$ 个元素，则 $\beta_t$ 为：
-
-$$
-\beta_t = \hat{\alpha}_t[k+1]
-$$
-
-单词概率分布为：
-
-$$
-p_t = \text{softmax} (W_p (\hat{c}_t + h_t))
-$$
-
-
-#### Experiments
-
-![result](/img/in-post/2020-03-17/adaptive-attention/adaptive-attention-result.png)
-
-
-### Self-critical
-
-**Self-critical Sequence Training for Image Captioning.** *Steven J. Rennie, et al.* CVPR 2017. [[Paper]](http://openaccess.thecvf.com/content_cvpr_2017/papers/Rennie_Self-Critical_Sequence_Training_CVPR_2017_paper.pdf) 
-
-Pytorch 复现：[ruotianluo/self-critical.pytorch](https://github.com/ruotianluo/self-critical.pytorch) 
-
-
-之前的方法都是用最大似然进行语言建模，在训练时最大化模型生成的单词序列的联合概率，从而最小化交叉熵损失。这种方法存在两个问题：
-
-- 曝光偏差（exposure bias）：训练时用了 teacher forcing，即解码器每个时刻的输入都是训练集中的真实单词（ground truth），而测试时，解码器每个时刻的输入是自己上一时刻生成的单词，如果某一个单词预测得不够准确，之后所有单词的预测都会受到影响；
-
-- 训练目标和评价准则不匹配：训练时用的交叉熵损失函数，而验证时用的是 BLEU、ROUGE、METEOR、CIDEr 之类的指标，导致模型训练时无法做到充分的优化评估指标。
-
-于是一个自然的想法是直接优化评估指标（CIDEr）。但由于生成单词的操作不可微，所以不能用一般的反向传播梯度下降来优化这些指标，因此考虑用强化学习（中的 Policy Gradient 方法）来优化。
-
-
-#### Policy Gradient 
-
-如果把图像描述问题看成强化学习问题：
-
-- agent：decoder
-- environment：单词和图像特征
-- policy：$p_{\theta}$，由模型参数 $\theta$ 决定
-- action：对下一个单词的预测
-- state：decoder 要更新的各种状态，如 LSTM 隐状态和细胞状态、 attention 权重等
-- reward：$r$，CIDEr 值
-
-训练目标是最大化期望 reward，因为要用梯度下降，所以写成最小化负期望 reward：
-
-$$
-L(\theta) = - \mathbb{E}_{w^s \thicksim p_{\theta}} [r(w^s)] = - \sum_{w^s} p_{\theta}(w^s) r(w^s)
-$$
-
-其中，$w^s = (w_1^s, ... , w_T^s)$ 是生成的句子，$r(w^s)$ 是 $w^s$ 上的 $\gamma$ 折扣累积 reward：
-
-$$
-r(w^s) = r_1 + \gamma r_2 + \gamma_1 r_3 + ... +  \gamma_{T-1} r_T
-$$
-
-对 $L(\theta)$ 求梯度：
-
-$$
-\begin{aligned}
-  \nabla_{\theta} L(\theta) = - \nabla_{\theta} \mathbb{E}_{w^s \thicksim p_{\theta}} [r(w^s)] &= - \nabla_{\theta} \sum_{w^s} p_{\theta}(w^s) r(w^s) \\
-  &= - \sum_{w^s} \nabla_{\theta}  p_{\theta}(w^s) r(w^s) \\
-  &= - \sum_{w^s} p_{\theta}(w^s) \frac{\nabla_{\theta} p_{\theta}(w^s)}{p_{\theta}(w^s)} r(w^s)\\
-  &= - \sum_{w^s} p_{\theta}(w^s) \nabla_{\theta} \log p_{\theta}(w^s) r(w^s)\\
-  &= - \mathbb{E}_{w^s \thicksim p_{\theta}} [r(w^s) \nabla_{\theta} \log p_{\theta}(w^s)]
-\end{aligned}
-$$
-
-推导过程参考：[Deep Reinforcement Learning: Pong from Pixels](http://karpathy.github.io/2016/05/31/rl/)
-
-实际训练时，会用蒙特卡洛的思想从 $p_{\theta}$ 中按概率随机采样出一个单词序列 $w^s = (w_1^s, ... , w_T^s)$ 来估计出梯度的近似值：
-
-$$
-\nabla_{\theta} L(\theta) \approx -r(w^s) \nabla_{\theta} \log p_{\theta} (w^s)
-$$
-
-因为采样的每一步都具有较大的随机性，可能会使最终得到的样本之间差异巨大，所以一般认为这种基于蒙特卡洛采样的近似方法会导致估计出的梯度有较高的方差。于是为了引入了一个 baseline $b$ 来减小方差，即：
-
-$$
-\nabla_{\theta} L(\theta) = - \mathbb{E}_{w^s \thicksim p_{\theta}} [(r(w^s) - b) \nabla_{\theta} \log p_{\theta}(w^s)]
-$$
-
-只要 $b$ 不依赖于 $w^s$，减去一个 $b$ 并不会改变梯度的值，证明过程为：
-
-$$
-\begin{aligned}
-  \mathbb{E}_{w^s \thicksim p_{\theta}} [b \nabla_{\theta} \log p_{\theta}(w^s)] &= b \sum_{w_s} \nabla_{\theta} p_{\theta}(w^s) \\
-  &= b \nabla_{\theta} \sum_{w_s}  p_{\theta}(w^s) \\
-  &= b \nabla_{\theta} 1 = 0
-\end{aligned}
-$$
-
-所以估计出的梯度为：
-
-$$
-\nabla_{\theta} L(\theta) \approx -(r(w^s) - b) \nabla_{\theta} \log p_{\theta} (w^s)
-$$
-
-由链式法则可以得到：
-
-$$
-\nabla_{\theta} L(\theta) = \sum_{t=1}^T \frac{\partial L(\theta)}{\partial s_t} \frac{\partial s_t}{\partial \theta}
-$$
-
-其中 $s_t$ 是 softmax 的输入，是一个长度为词典大小的向量，表示了 $t$ 时刻词典中每个单词的分数。
-
-把 $\frac{\partial L(\theta)}{\partial s_t}$ 近似一下可以得到：
-
-$$
-\frac{\partial L(\theta)}{\partial s_t} \approx (r(w^s)-b)(p_{\theta}(w_t \mid h_t) - 1_{w_t^s}) \tag{2}
-$$
-
-其中 $1_{w_t^s}$ 是单词 $w_t^s$ 的独热编码向量。这个近似相当于把 $w_t^s$ 当成了 $t$ 时刻 $p_{\theta}(w_t \mid h_t)$ 的目标输出，在 [MIXER 的论文](https://arxiv.org/pdf/1511.06732.pdf)里有解释。
-
-
-因为公式 $(2)$ 的第二项 $(p_{\theta}(w_t \mid h_t) - 1_{w_t^s})$ 一定小于 0，所以当样本的 reward 大于 baseline $b$ 时，梯度为负，梯度下降时就会提高单词 $w_t^s$ 的分数，否则就会抑制 $w_t^s$ 的分数。一般来说会用对当前模型的 reward 的平均值的估计函数作为 baseline，如在 MIXER 中，baseline $\bar{r}_t$ 是一个线性回归模型，通过优化均方误差 $\lVert \bar{r}_t - r \rVert^2$ 得到。
-
-
-#### SCST
-
-**self-critical sequence training**
-
-论文把 baseline 定义为当前模型通过 greedy decoding 得到的句子 $\hat{w}$ 的reward。所以叫 self-critical，因为 baseline 也是自己生成的，相当于自己跟自己比。于是有：
-
-$$
-\frac{\partial L(\theta)}{\partial s_t} \approx (r(w^s) - r(\hat{w}))(p_{\theta}(w_t \mid h_t) - 1_{w_t^s})
-$$
-
-![self-critical](/img/in-post/2020-03-17/self-critical/self-critical.png)
-
-论文认为这样做的优点是：
-
-- 不用另外训练一个模型来当 baseline，只需要用现有模型 inference 一遍，降低了训练复杂度
-- 训练和测试阶段的一致性，都用的同样的生成方法（但训练时不是随机采样吗...）
-- 梯度方差低于 MIXER，训练得更快（用 SGD 时）
-
-用强化学习的方法训练之前，会先用交叉熵损失进行预训练。
-
-
-#### Experiments
-
-
-- 与以优化交叉熵损失（XE）为目标的模型和用 MIXER 方法训练的模型的对比实验：
-
-  <img src="/img/in-post/2020-03-17/self-critical/sc-result1.png" width="400px" alt="self-critical result1" />
-
-- 尝试 curriculum learning，即先对最后一个单词以优化 CIDEr 为目标进行训练，前面的词则以优化交叉熵损失为目标进行训练，然后每个 epoch 增加一个用 CIDEr 进行训练的单词。但这种方法至少在 MSCOCO 上对效果没有提升。
-
-- 尝试以优化别的指标为目标，但优化 CIDEr 的效果是最好的，能把所有指标都往上拉：
-
-  <img src="/img/in-post/2020-03-17/self-critical/sc-result2.png" width="450px" alt="self-critical result2" />
-
-
-- 发现 beam search 对 RL 训练出来的模型效果提升很小：
-
-  <img src="/img/in-post/2020-03-17/self-critical/sc-result3.png" width="450px" alt="self-critical result3" />
-
-  作为对比，这是 beam search 对用交叉熵损失训练出来的模型效果提升：
-
-  <img src="/img/in-post/2020-03-17/self-critical/sc-result4.png" width="450px" alt="self-critical result4" />
-
-- 似乎能对 objects out-of-context (OOOC) 的图片生成比较好的结果
-
-
-## Image Aesthetic Captioning
-
-### Aesthetic Critiques
-
-**Aesthetic Critiques Generation for Photos.** *Kuang-Yu Chang, Kung-Hung Lu, and Chu-Song Chen.* ICCV 2017. [[IEEE]](https://ieeexplore.ieee.org/document/8237642) [[Paper]](https://www.iis.sinica.edu.tw/~kuangyu/iccv17_aesthetic_critiques.pdf) [[Code]](https://github.com/kunghunglu/DeepPhotoCritic-ICCV17) [[Dataset]](https://github.com/ivclab/DeepPhotoCritic-ICCV17)
-
-开图像美感描述这个坑的第一篇论文，数据集 PCCD 的提出者（虽然我并没有找到这个数据集）。该论文考虑从不同美学角度来对图片进行美感描述，对每个角度而言大概就跟 Image Captioning 差不多了。
-
-训练数据结构：
-
-$$
-D = (\Phi_i, C_i, a_i), i \in \{ 1 ... N \}
-$$
-
-
-$\Phi_i$ 是第 $i$ 张图片，$C_i$ 是它的描述（同一张图片可能有多个不同角度的描述），$a_i$（$i \in \{1 ... L\}$）是该描述的角度。在此之外，还有一个 $p_{i,l} \in [0, 1]$ 来描述图片 $\Phi_i$ 在角度 $l$ 上的美感分数。
-
-
-#### Aspect-oriented
-
-**Baseline - Aspect-oriented (AO) Approach**
-
-AO 中，训练数据中每张图都只带有一个角度的描述，即 $(\Phi_i, C_i, l)$。然后用 CNN-LSTM 在每个角度的数据上进行训练。
-
-相当于要对 $L$ 个角度各建一个 CNN-LSTM 模型。关于 CNN-LSTM 可以参考 [Show and Tell](#show-and-tell) 那篇论文。
-
-CNN 还会用 $\{ (\Phi_i; p_{i,l}) \}$ 进行训练。在测试时，它会输出图片在每个角度上的美感分数，然后把得分最高的角度 $l^*$ 所对应的 CNN-LSTM 模型的输出结果当做最终结果。流程图如下：
-
-<img src="/img/in-post/2020-03-17/pccd/ao.png" width="400px" alt="ao-approach" />
-
-#### Aspect-fusion
-
-AO 只能输出一个角度的描述，比较单一。为了解决这个问题，论文先尝试把整个数据集都扔进 CNN-LSTM 训练，但效果不好。
-
-**Aspect-fusion (AF) Approach**
-
-于是论文决定在测试时把 AO 中每个角度的 CNN-LSTM 模型输出的隐状态 $h_l = \{ h_{l,t} \mid t = 1 ... T, l = 1 ... L \}$ 用 Soft Attention 融合一下之后，当做输入扔进一个新的 LSTM 中，于是新的 LSTM 的递推公式为：
-
-$$
-(g_{\tau}, y_{\tau} ) = F(g_{\tau-1}, x_{\tau}, s_{\tau} )
-$$
-
-$y_{\tau}$ 为概率分布，$x_{\tau}$ 为当前输入，$g_{\tau - 1}$ 为上一时刻的隐状态，$s_{\tau}$ 为 Soft Attention 融合出来的 context vector。
-
-
-**Soft Attention**
-
-$s_{\tau}$ 相当于是对 $h_{lt}$ 求加权平均：
-
-$$
-s_{\tau} = \sum_{l=1}^{L} \sum_{t=1}^{T} \alpha_{lt}^{\tau} (h, g_{\tau-1}) h_{lt}
-$$
-
-其中，权重 $\alpha_{lt}^{\tau}$ 需要在 Soft Attention 模型中生成：
-
-$$
-e_{lt}^{\tau} = A(g_{\tau-1}, h_{lt}) = W_{\gamma} (Ug_{\tau-1} + Vh_{lt})
-$$
-
-$$
-\alpha_{lt}^{\tau} = \frac{ \exp (e_{lt}^{\tau}) }{ \sum_{p=1}^L \sum_{q=1}^T \exp (e_{pq}^{\tau}) }
-$$
-
-
-其中，$\gamma$ 是 ReLU 激活函数，$W \in R^{n \times n}$、$U \in R^{n \times n}$ 和 $V \in R^{n \times n}$ 是需要学习的权重，$n$ 是 LSTM 隐藏层大小（论文里面设的 768）。
-
-流程图如下（自行加了一些不知对不对的标注）：
-
-<img src="/img/in-post/2020-03-17/pccd/af.jpg" width="600px" alt="af-approach" />
-
-
-相当于论文认为 CNN-LSTM 输出的隐状态可以被看做每个角度的输入的深层特征，然后 Soft Attention 机制又可以很好的把它们融合到一起。
-
-
-**困惑**：按照代码里面的写法，第二个 LSTM 明明已经是在生成融合各个角度之后的句子了，却依然把每个角度的句子分别输入和用来算损失，感觉说不通，虽然的确也没有角度融合后的 ground truth 就是了...
-
-
-#### PCCD
-
-图片和评论来源于 [GuruShots](https://gurushots.com/)，评论被分为了 7 个角度，每个角度都有评分（评分范围为 1-10）：
-
-<img src="/img/in-post/2020-03-17/pccd/pccd.png" width="450px" alt="PCCD" />
-
-
-#### Experiments
-
-因为不是每个角度都有评论，所以实验时论文只选了 3 个角度（composition and perspective、color and lighting、subject of photo）。为了控制词典大小，词典中只保留出现次数 > 5 的单词，其他单词会被映射为 `UNK`。
-
-论文直接用了 [NeuralTalk2](#show-and-tell) 来当 CNN-LSTM 模型，拿了在 MSCOCO 数据集上预训练好的模型在 PCCD 上 fine-tune（只 fine-tune 了 LSTM 部分，CNN 部分保持不变）。
-
-评估指标用了 [SPICE](https://panderson.me/images/SPICE.pdf)。
-
-
-实验结果：
-
-<img src="/img/in-post/2020-03-17/pccd/pccd-result.png" width="450px" alt="result" />
Index: blog/posts/2020-08-16-bayesian-neural-network.md
===================================================================
diff --git a/blog/posts/2020-08-16-bayesian-neural-network.md b/blog/posts/2020-08-16-bayesian-neural-network.md
deleted file mode 100644
--- a/blog/posts/2020-08-16-bayesian-neural-network.md	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
+++ /dev/null	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
@@ -1,414 +0,0 @@
----
-layout: Post
-title: 贝叶斯神经网络
-subtitle: "万恶的贝叶斯嗷，真的学得会吗"
-author: Renovamen
-date: 2020-08-16
-headerImage: /img/in-post/2020-08-16/header.png
-permalinkPattern: /post/:year/:month/:day/:slug/
-tags:
-  - Machine Learning
-  - Deep Learning
-  - Math
-  - Bayesian
----
-
-Radford Neal: I don't necessarily think that the Bayesian method is the best thing to do in all cases...<!-- more -->
-
-Geoff Hinton: Sorry Radford, my prior probability for you saying this is zero, so I couldn't hear what you said.
-
-
-## 关于贝叶斯估计
-
-$X$ 的概率密度函数为 $p_\theta(X)$，现在观测到了一组样本 $(X_1, X_2, \dots, X_n) = (x_1, x_2, \dots, x_n)$，要估计参数 $\theta$。
-
-### 极大似然估计
-
-**极大似然估计（Maximum Likelihood Estimation，MLE）**，频率学派的思想。频率学派的观点是：模型参数 $\theta$ 存在唯一真值，只是这个真值是未知的。如果当 $\theta = 
-\hat{\theta}_{\text{MLE}}$ 时，事件 $(X_1, X_2, \dots, X_n) = (x_1, x_2, \dots, x_n)$ 发生的可能性最大，那么就说 $\hat{\theta}_{\text{MLE}}$ 是 $\theta$ 的极大似然估计。
-
-$$
-\begin{aligned}
-  \hat{\theta}_{\text{MLE}}&= \arg \max_\theta p_\theta(x) \\
-    &= \arg \max_\theta \prod_{i=1}^n p_\theta(x_i) \\
-    &= \arg \max_\theta \log \prod_{i=1}^n p_\theta(x_i) \\
-    &= \arg \max_\theta \sum_{i=1}^n \log p_\theta(x_i) \\
-    &= \arg \min_\theta - \sum_{i=1}^n \log p_\theta(x_i)
-\end{aligned}
-$$
-
-也就是说最后需要优化的是 Negative Log Likelihood (NLL)。经常看到的用频率学派的方法求抛硬币概率的问题，本质上就是在优化 NLL：
-
-抛硬币可以看做参数为 $\theta$ 的 Bernoulli 分布：
-
-$$
-p_\theta(x_i) = 
-
-\begin{cases}
-  \theta &x_i = 1 \\
-  1 - \theta &x_i = 0
-\end{cases}
-
-= \theta^{x_i} (1 - \theta)^{1-x_i}
-$$
-
-那么 NLL：
-
-$$
-\text{NLL} = - \sum_{i=1}^n \log p_\theta(x_i) = - \sum_{i=1}^n \log \theta^{x_i} (1 - \theta)^{1-x_i}
-$$
-
-令导数为 0 来求极值：
-
-$$
-\text{NLL}' = - \sum_{i=1}^n \left (\frac{x_i}{\theta} + (1-x_i) \frac{-1}{1 - \theta} \right ) = 0
-$$
-
-$$
-\rArr \frac{\sum_{i=1}^n x_i}{\theta} - \frac{n - \sum_{i=1}^n x_i}{1 - \theta}  = 0
-$$
-
-$$
-\rArr \theta = \frac{\sum_{i=1}^n x_i}{n}
-$$
-
-即 $\theta$ 为正面的次数除以总共的抛硬币次数。
-
-### 贝叶斯估计
-
-**贝叶斯估计（Bayesian Estimation）**，贝叶斯学派的思想。贝叶斯学派认为 $\theta$ 也是随机的，和一般的随机变量没有本质区别，因此只能根据观测样本去估计参数 $\theta$ 的分布。其基础是贝叶斯公式：
-
-$$
-p(\theta \mid x) = \frac{p(x \mid \theta)p(\theta)}{p(x)}
-$$
-
-$$
-p(x) = \sum_\theta p(x \mid \theta)p(\theta)
-$$
-
-$$
-\hat{\theta}_{\text{BE}} = \mathbb{E}[p(\theta \mid x)]
-$$
-
-其中：
-
-- $p(\theta)$：**先验（prior）**，指在没有观测到任何数据时对 $\theta$ 的预先判断，比如认为硬币大概率是均匀的，所以 $\theta$ 的先验可以是最大值取在 0.5 处的 Beta 分布；
-- $p(x \mid \theta)$：**似然（likelihood）**，假设 $\theta$ 已知后，观测数据应该是什么样子；
-- $p(\theta \mid x)$：**后验（posterior）**，最终的参数分布；
-- $p(x)$，样本的先验，一个常量（和要估计的参数无关）。
-
-相当于贝叶斯估计是在 $\theta$ 服从先验分布 $p(\theta)$ 的前提下，然后根据观测到的样本去校正先验分布，最终得到后验分布 $p(\theta \mid x)$，然后取后验分布的期望作为参数的估计值。
-
-如果先验是均匀分布，则贝叶斯估计等价于极大似然，因为先验是均匀分布相当于对参数没有任何预判。
-
-
-
-### 最大后验估计
-
-贝叶斯估计估计的是 $\theta$ 的后验分布，而**最大后验估计**（Maximum a Posteriori，MAP）考虑的是后验分布极大化时 $\theta$ 的取值：
-
-$$
-\begin{aligned}
-  \hat{\theta}_{\text{MAP}}&= \arg \max_\theta p(\theta \mid x) \\
-    &= \arg \min_\theta - \log p(\theta \mid x) \\
-    &=  \arg \min_\theta - \log \frac{p(x \mid \theta)p(\theta)}{p(x)}\\
-    &=  \arg \min_\theta - \log p(x \mid \theta) - \log p(\theta) + \log p(x)\\
-    &=  \arg \min_\theta - \log p(x \mid \theta) - \log p(\theta)
-\end{aligned}
-$$
-
-$- \log p(x \mid \theta)$ 就是 NLL，所以相比 MLE，MAP 就是在优化时多了一个先验项 $p(\theta)$。在有的情况下，$- \log p(\theta)$ 可以看做用 MLE 时结构化风险里的正则化项，比如当先验是一个高斯分布：
-
-$$
-\\[2px]
-p(\theta) = \text{constant} \times e^{- \frac{\theta^2}{2 \sigma^2}}
-$$
-
-constant 是一个参数无关的常数项，在上式中它相当于 $\frac{1}{\sqrt{2 \pi} \sigma}$。那么：
-
-$$
-- \log p(\theta) = \text{constant} + \frac{\theta^2}{2 \sigma^2}
-$$
-
-这时的 $- \log p(\theta)$ 就相当于一个 L2 正则化项（倾向于取小值）。
-
-而当先验是一个拉普拉斯分布（Laplace Distribution）时，$- \log p(\theta)$ 相当于一个 L1 正则化（倾向于取 0 使权重稀疏）。
-
-MAP 提供了一个直观的方法来设计复杂但可解释的正则化项，比如可以通过把混合高斯分布作为先验来得到更复杂的正则化项。
-
-
-## 贝叶斯神经网络
-
-这一节主要基于论文：
-
-**Weight Uncertainty in Neural Networks.** *Charles Blundell, et al.* ICML 2015. [[Paper]](https://arxiv.org/pdf/1505.05424.pdf)
-
-在看这一节之前，或许先去看看[概率图模型](https://note.zxh.io/ai/ml/pcg/)中的贝叶斯网络部分比较好。
-
-优点：
-
-- 贝叶斯神经网络中的权重都是随机变量，做预测的时候用的是采样后的权重，所以可以集成某权重分布上的多组神经网络进行预测，相当于 ensemble。
-
-- 反应数据中的不确定性（aleatoric uncertainty）
-
-  - [Deep Learning Is Not Good Enough, We Need Bayesian Deep Learning for Safe AI](https://alexgkendall.com/computer_vision/bayesian_deep_learning_for_safe_ai/)
-
-  - [贝叶斯神经网络建模两类不确定性](https://zhuanlan.zhihu.com/p/88654038)
-
-- 为权重引入不确定性进行正则化
-
-
-### 神经网络模型
-
-这是一个神经元：
-
-<img src="/img/in-post/2020-08-16/neuron.png" width="400px" alt="neuron" />
-
-一般的神经网络中，$w$ 和 $b$ 都是确定的值。对于数据集 $D = \{(x_1, y_1), \dots, (x_n, y_n)\}$，其学习可以视作是一个极大似然估计：
-
-$$
-\begin{aligned}
-  w_{\text{MLE}}&= \arg \max_w \log p(D \mid w) \\
-    &= \arg \max_w \sum_{i=1}^n \log p(y_i \mid x_i, w)
-\end{aligned}
-$$
-
-有些时候我们对 $w$ 有一些偏好，于是如[之前](#最大后验估计)所说，引入先验（最大后验估计）可以引入正则化项：
-
-$$
-\begin{aligned}
-  w_{\text{MAP}}&= \arg \max_w \log p(w \mid D) \\
-    &= \arg \max_w \log p(D \mid w) + \log p(w)
-\end{aligned}
-$$
-
-
-### 气氛突然贝叶斯了起来
-
-而在**贝叶斯神经网络**（Bayesian Neural Network，BNN）中，$w$ 和 $b$ 由确定的值变为了分布，因此概率模型就变为了：
-
-$$
-p(y \mid x) = \mathbb{E}_{p(w \mid D)} [p(y \mid x, w)]
-$$
-
-那么存在两个问题：
-
-- 后验 $p(w \mid D)$ 是 intractable 的。由贝叶斯公式：
-
-  $$
-  p(w \mid D) = \frac{p(D \mid w)p(w)}{p(D)}
-  $$
-
-  而输入数据分布 $p(D)$ 通常是是 intractable 的，因为这相当于要对所有可能的 $w$ 求和（或积分）：
-
-  $$
-  p(D) = \sum_w p(D \mid w)p(w)
-  $$
-
-- 期望 $p(y \mid x)$ 也不好求，因为这相当于要对每一个可能的 $p(w \mid D)$ 计算神经网络的预测值
-
-朋友，搞不定的分布就上**变分推断**，乌拉！（不是
-
-
-### 变分推断
-
-对于第一个问题求后验 $p(w \mid D)$，可以用变分推断（variational inference）来解决。变分推断可以参考[这里](https://note.zxh.io/ai/ml/pcg/variational-inference.html)，其思想是用一个由参数 $\theta$ 控制的分布 $q(w \mid \theta)$ 来近似 $p(w \mid D)$，这两个分布之间的 KL 散度要尽可能小：
-
-$$
-\begin{aligned}
-  \theta^\text{*} &= \arg \min_\theta \text{KL} [q(w | \theta) \| p(w | D)] \\
-    &= \arg \min_\theta \sum_w q(w | \theta) \log \frac{q(w | \theta)}{p(w | D)} \\
-    &= \arg \min_\theta \sum_w q(w | \theta) \log \frac{q(w | \theta)p(D)}{p(D | w)p(w)} \\
-    &= \arg \min_\theta \sum_w q(w | \theta) \log \frac{q(w | \theta)}{p(w)} - \sum_w q(w | \theta) \log p(D | w) + \sum_w q(w | \theta) \log p(D) \\
-    &= \arg \min_\theta \text{KL} [q(w | \theta) \| p(w)] - \mathbb{E}_{q(w|\theta)} [\log p(D|w)]
-\end{aligned}
-$$
-
-写成目标函数就是：
-
-$$
-F(D,\theta) = \underbrace{\text{KL} [q(w \mid \theta) \| p(w)]}_{\text{complexity
-cost}} - \underbrace{\mathbb{E}_{q(w \mid \theta)} [\log p(D \mid w)]}_{\text{likelihood cost}} \tag{1}
-$$
-
-这个函数也被称为 variational free energy，就是 ELBO 加个负号。所以我们要最大化 ELBO，但要最小化 variational free energy。
-
-式 (1) 可以被看做两种代价的组合：
-
-- complexity cost：权重和其先验的差距
-
-- likelihood cost：对样本的拟合程度
-
-相当于既要尽可能拟合样本，又要尽可能符合先验，在两种代价中取平衡，是一个 trade-off 的过程，可以看做正则化。
-
-式 (1) 是个优化问题，所以可以上梯度下降。但在这之前，还有一些问题需要解决，因为式 (1) 没法求梯度。
-
-### 蒙特卡洛采样
-
-式 (1) 的第一项中，$q(w \mid \theta)$ 是个我们自己定的分布（通常是高斯分布），$p(w)$ 是个我们自己定的先验（通常也是高斯分布），都有闭式解，可以直接对 $\theta$ 求梯度。
-
-主要问题在第二项 $\mathbb{E}_{q(w \mid \theta)} [\log p(D \mid w)]$ 上。这是个期望，它不好求，那么算它的时候一般会喜闻乐见地用蒙特卡洛采样来近似，即根据 $q(w \mid \theta)$ 采样 M 个 $w_i$，然后有：
-
-$$
-\mathbb{E}_{q(w \mid \theta)} [\log p(D \mid w)] \approx \frac{1}{M} \sum_{i=1}^M \log p(D \mid w_i)
-$$
-
-于是近似之后这一项就变得跟参数 $\theta$ 无关了，梯度下降时这一项关于 $\theta$ 的梯度会为 0。这是因为 $z$ 和 $\theta$ 之间不是确定性函数关系，而是一种采样的关系。于是就有一种叫**重参数化**的 trick，把这种采样的关系转变成确定性函数关系。
-
-### 重参数化
-
-**重参数化**（reparameterization）是[变分自编码器（Variational Auto-Encoder, VAE）](https://note.zxh.io/ai/dl/generative-models/vae.html)引入的操作。先引入一个分布为 $p(\epsilon)$ 的随机变量 $\epsilon$，然后把期望 $\mathbb{E}_{q(w \mid \theta)} [\log p(D \mid w)]$ 重写为：
-
-$$
-\mathbb{E}_{q(w \mid \theta)} [\log p(D \mid w)] = \mathbb{E}_{p(\epsilon)} [\log p(D \mid t(\theta, \epsilon))]
-$$
-
-其中 $w \triangleq t(\theta, \epsilon)$，是一个确定性函数，这样就可以先从 $p(\epsilon)$ 中采样出 $\epsilon$，然后可导地引入 $w$。例如 $q(w \mid \theta) = \mathcal{N}(\mu, \sigma^2)$，$\mu, \sigma$ 依赖于参数 $\theta$，那么可以把 $w$ 写为：
-
-$$
-w \triangleq t(\theta, \epsilon) = \mu + \sigma \odot \epsilon
-$$
-
-其中 $\epsilon \thicksim \mathcal{N}(0, 1)$。
-
----
-
-而该论文对此作了推广。对于期望 $\mathbb{E}_{q(w \mid \theta)} [\log p(D \mid w)]$，它的梯度 $\frac{\partial}{\partial \theta} \mathbb{E}_{q(w \mid \theta)} [\log p(D \mid w)]$ 不好直接算，采样之后梯度又为 0，那么能不能把求导移到期望里面去：$\mathbb{E}_{q(w \mid \theta)} [\frac{\partial}{\partial \theta} \log p(D \mid w)]$？
-
-并不能，因为期望（积分）是跟参数 $\theta$ 有关的，而 $\log p(D \mid w)$ 是与 $\theta$ 无关的，把求导移进去的话梯度又为 0 了。因此该论文把 $w$ 写为 $t(\theta, \epsilon)$，其中 $\epsilon \thicksim q(\epsilon)$。然后它证明了对于函数 $f(w, \theta)$，只要有 $q(\epsilon)d \epsilon = q(w \mid \theta)dw$，就有：
-
-$$
-\begin{aligned}
-  \frac{\partial}{\partial \theta} \mathbb{E}_{q(w \mid \theta)} [f(w, \theta)] &= \frac{\partial}{\partial \theta} \int f(w, \theta)q(w \mid \theta) dw \\
-    &= \frac{\partial}{\partial \theta} \int f(w, \theta) q(\epsilon)d \epsilon\\
-    &= \mathbb{E}_{q(\epsilon)} \left [\frac{\partial f(w, \theta)}{\partial w} \frac{\partial w}{\partial \theta} +  \frac{\partial f(w, \theta)}{\partial \theta} \right ]
-\end{aligned}
-$$
-
-这时就可以把求导移进期望里了。从直觉上来理解的话，现在 $\mathbb{E}_{q(w \mid \theta)} [\log p(D \mid w)]$ 可以写成：
-
-$$
-\mathbb{E}_{q(w \mid \theta)} [\log p(D \mid w)] = \mathbb{E}_{q(\epsilon)} [\log p(D \mid t(\theta, \epsilon))]
-$$
-
-那么现在期望就和 $\theta$ 无关，而似然则和 $\theta$ 有关了，于是就可以把求导移进去了。
-
----
-
-论文里令 $f(w \mid \theta) = \log q(w \mid \theta) - \log p(w)p(D \mid w)$，则：
-
-$$
-F(D,\theta) = \mathbb{E}_{q(w \mid \theta)} [f(w \mid \theta)] \approx \sum_{i=1}^n \log q(w_i \mid \theta) - \log p(w_i) - \log p(D \mid w_i)
-$$
-
-这个近似把 KL 散度也蒙特卡洛了，这种做法摆脱了对 KL 散度有闭式解的要求。虽然在很多情况下 KL 散度能写出闭式解，但这样可以适配更多的先验后验分布形式。
-
-
-### 梯度下降
-
-为了计算方便，论文用了平均场近似（mean-field approximation）。即令变分后验 $q(w \mid \theta)$ 为一个[平均场分布族](https://note.zxh.io/ai/ml/pcg/variational-inference.html#平均场分布族)，即认为各个参数 $w_i$ 之间相互独立，每个参数 $w_i$ 都服从高斯分布（也即协方差矩阵除了对角线以外都为 0，所以原文用的是 diagonal Gaussian distribution 这个词），那么有：
-
-$$
-q(w \mid \theta) = \prod_i q_i(w_i \mid \theta) = \prod_i \mathcal{N}(w_i \mid \mu_i, \sigma_i^2)
-$$
-
-按照之前说的重参数化操作，$w_i$ 可以写为：
-
-$$
-w_i = \mu_i + \sigma_i \odot \epsilon_i
-$$
-
-$$
-\epsilon_i \thicksim \mathcal{N}(0, 1)
-$$
-
-然后令 $f(w \mid \theta) = \log q(w \mid \theta) - \log p(w) - p(D \mid w)$。因为最大化 $p(D \mid w)$ 跟最小化 $L(w)$ 是一回事，所以也可以写成 $f(w \mid \theta) = \log q(w \mid \theta) - \log p(w) + L(w)$。
-
-而 $\theta = (\mu, \sigma)$，那么分别对 $\mu$ 和 $\sigma$ 求梯度：
-
-$$
-\Delta_{\mu} = \frac{\partial f(w, \theta)}{\partial w} +  \frac{\partial f(w, \theta)}{\partial \mu}
-$$
-
-$$
-\Delta_{\sigma} = \frac{\partial f(w, \theta)}{\partial w} \cdot \epsilon +  \frac{\partial f(w, \theta)}{\partial \sigma}
-$$
-
-为了保证 $\sigma$ 非负，论文又把 $\sigma$ 写成了 $\sigma = \log (1 + \exp(\rho))$，所以现在变成了 $\theta = (\mu, \rho)$，关于 $\rho$ 的梯度为：
-
-$$
-\Delta_{\rho} = \frac{\partial f(w, \theta)}{\partial w} \frac{\epsilon}{1 + \exp(- \rho)} +  \frac{\partial f(w, \theta)}{\partial \rho}
-$$
-
-然后按梯度下降更新 $\mu, \rho$ 即可：
-
-$$
-\mu \larr \mu - \alpha \Delta_{\mu}
-$$
-
-$$
-\rho \larr \rho - \alpha \Delta_{\rho}
-$$
-
-## 胡思乱想
-
-### 0x00
-
-打算理 BNN 是因为看到了一篇论文：
-
-**Uncertainty-guided Ccontinual Learning with Bayesian Neural Networks.** *Sayna Ebrahimi, et al.* ICLR 2020. [[Paper]](https://arxiv.org/pdf/1906.02425.pdf) [[Code]](https://github.com/SaynaEbrahimi/UCB)
-
-个人觉得它的思想非常简洁，就是对 BNN 参数更新的学习率 $\alpha$ 做了修改，以至于让我这种菜鸡都能立马理解，甚至觉得我要是早点入这个坑我也能想出这个 idea（不是没有我没这样说过
-
-方差 $\sigma_i$ 可以被看做参数 $w_i$ 的不确定度（uncertainty），方差越大说明这个参数对当前任务越重要，那么在后面的任务中它的更新幅度就应该小一点，反之则应该大一点。也就是说参数重要性 $\Omega$ 被定义为：
-
-$$
-\Omega_i \propto \frac{1}{\sigma_i}
-$$
-
-而与一般的 regularization-based continual learning 方法加正则项的做法不同，这篇论文直接通过控制学习率来控制更新幅度，不过它只更新了 $\mu$ 的学习率，$\rho$ 的学习率则一直保持不变：
-
-$$
-\alpha_i^\mu \larr \frac{\alpha_i^\mu}{\Omega_i} 
-$$
-
-### 0x01
-
-贝叶斯神经网络是一种深度学习方法，诞生在一个 Autograd 工具大行其道的时代，因此对于最小化 $\mathbb{E}_{q(w \mid \theta)} [f(w, \theta)]$ 这个优化问题，它可以直接上梯度下降。
-
-还有一种贝叶斯系方法叫 ADF（Assumed Density Filtering），或者叫它在线变分贝叶斯（Online Variational Bayes）可能还更容易理解一点。在第 $n$ 个数据集 $D_n$ 上估计参数时，它会把 $f(w, \theta)$ 中的参数先验 $p_n(w)$ 替换为上一个数据集上的参数后验 $p_{n-1}(w \mid D_{n-1}) = q_{n-1}(w)$。
-
-在 ADF 诞生的那个年代，深度学习还是个冷门领域，也并没有什么 Autograd 工具能给你用。因此 ADF 在求极小值时直接用了“使导数为 0”这种硬核方法：
-
-$$
-\frac{\partial}{\partial \theta} \mathbb{E}_{q(w \mid \theta)} [f(w, \theta)] = \mathbb{E}_{q(\epsilon)} \left [\frac{\partial f(w, \theta)}{\partial w} \frac{\partial w}{\partial \theta} +  \frac{\partial f(w, \theta)}{\partial \theta} \right ] = 0
-$$
-
-因为 $q$ 是指数族分布，所以上式是有闭式解的，只是推导过程比较复杂，感兴趣的话可以看看[这篇文章](https://zhuanlan.zhihu.com/p/150187256)。之所以提到这个，是因为下面这篇论文就是套的 ADF 框架，并直接通过闭式解来更新参数：
-
-**Task Agnostic Continual Learning Using Online Variational Bayes.** *Chen Zeno, et al.* arXiv 2018. [[Paper]](https://arxiv.org/pdf/1803.10123.pdf) [[Code]](https://github.com/igolan/bgd)
-
-而用贝叶斯性来做 continual learning 的开山之作 VCL 跟上面那篇论文的主要不同点在于，VCL 在更新参数时用了梯度下降，相当于在套 ADF 框架的同时又利用了 Autograd 的好处：
-
-**Variational Continual Learning.** *Cuong V. Nguyen, et al.* ICLR 2018. [[Paper]](https://openreview.net/pdf?id=BkQqq0gRb) [[Code]](https://github.com/nvcuong/variational-continual-learning)
-
-当然 VCL 还采样了一部分旧数据作为 coreset，coreset 也会被用于当前任务的训练，这种喜闻乐见的方法可以提高效果。
-
-然后有空的话我或许会理一理 ADF...
-
-
-
-
-## 参考
-
-- [聊一聊机器学习的 MLE 和 MAP：最大似然估计和最大后验估计](https://zhuanlan.zhihu.com/p/32480810)
-
-- [Weight Uncertainty in Neural Networks.](https://arxiv.org/pdf/1505.05424.pdf) *Charles Blundell, et al.* ICML 2015.
-
-- [贝叶斯深度学习是什么，和传统神经网络有何不同？](https://www.zhihu.com/question/352295592)
-
-- [Deep Learning Is Not Good Enough, We Need Bayesian Deep Learning for Safe AI](https://alexgkendall.com/computer_vision/bayesian_deep_learning_for_safe_ai/)
-  
-- [贝叶斯神经网络建模两类不确定性](https://zhuanlan.zhihu.com/p/88654038)
-
-- [Bayesian Neural Networks：贝叶斯神经网络](https://zhuanlan.zhihu.com/p/81170602)
Index: blog/posts/2021-06-12-svm.md
===================================================================
diff --git a/blog/posts/2021-06-12-svm.md b/blog/posts/2021-06-12-svm.md
deleted file mode 100644
--- a/blog/posts/2021-06-12-svm.md	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
+++ /dev/null	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
@@ -1,523 +0,0 @@
----
-layout: Post
-title: 支持向量机
-subtitle: Support Vector Machine (SVM)
-author: Renovamen
-date: 2021-06-12
-headerImage: /img/in-post/2021-06-12/header.jpg
-permalinkPattern: /post/:year/:month/:day/:slug/
-tags:
-  - Machine Learning
----
-
-SVM（Support Vector Machine，支持向量机）是一种二类分类模型，目标是在特征空间上找到间隔最大化的超平面。
-
-<!-- more -->
-
-## 线性可分 SVM
-
-### 线性可分与超平面
-
-考虑一个二维平面，平面上有两种不同的数据（红点和蓝点）。如果可以用一条直线将这两类数据分开，那么称这些数据是**线性可分**的，这条直线就相当于一个**超平面（Hyperplane）**。
-
-<img src="/img/in-post/2021-06-12/linearly-separable.png" width="300px" alt="linearly separable data" />
-
-扩展到 $n$ 维空间后，给定一个二分类器数据集 $D = \{ (x_i, y_i) \}_{i=1}^n$，其中 $y_i \in \{ +1, -1 \}$，如果存在一个超平面 $w^T x + b = 0$ 将两类样本分开，且对于每个样本都有 $y_i (w^T x_i + b) > 0$，则称这两类样本是线性可分的。
-
-
-### 最大间隔与支持向量
-
-接下来的问题是如何确定这个超平面。从直观上而言，这个超平面应该以最大间隔把两类样本分开，因此我们需要寻找**最大间隔超平面**。
-
-
-#### 支持向量
-
-我们定义 $\gamma$ 为所有样本到超平面的最短距离。如果 $\gamma$ 越大，则超平面对两个数据集的划分越稳定，不容易受噪声等因素影响。SVM 的目标是寻找一个超平面使得 $\gamma$ 最大，即下图中的实线。
-
-这些离超平面最近的点（虚线上的点）被称为**支持向量**（support vector），可以看到实际上 SVM 的解只受支持向量的影响，与数据集中的其他点无关。
-
-两条虚线之间的区域被称为**间隔**（margin），距离为 $2 \gamma$。
-
-<img src="/img/in-post/2021-06-12/support-vectors.png" width="450px" alt="support vectors" />
-
-
-#### 几何间隔
-
-初中几何告诉我们，二维空间中的一点 $(m, n)$ 到直线 $Ax + By + C = 0$ 的距离公式是：
-
-$$
-\frac{| Am + Bn + C |}{\sqrt{A^2 + B^2}}
-$$
-
-扩展到 n 维空间后，样本 $x_i$ 到直线 $w^T x + b = 0$ 的距离为：
-
-$$
-\frac{| w^T x_i + b |}{\| w \|} = \frac{y_i(w^T x_i + b)}{\| w \|}
-$$
-
-其中 $\| w \|$ 是 $w$ 的 $\ell_2$ 范数，即 $\sqrt{w_1^2 + \dots + w_n^2}$。
-
-
-### 优化问题
-
-现在我们可以得到以下优化目标：
-
-$$
-\begin{aligned}
-  \max_{w,b} &\quad \gamma \\
-  \text{s.t.} &\quad \frac{y_i(w^T x_i + b)}{\| w \|} \geq \gamma
-\end{aligned}
-$$
-
-由于同时缩放 $w \to kw$ 和 $b \to kb$ 不会改变样本到超平面的距离，我们可以限制 $\| w \| \cdot \gamma = 1$，则上式等价于：
-
-$$
-\begin{aligned}
-  \max_{w,b} &\quad \frac{1}{\| w \|} \\
-  \text{s.t.} &\quad y_i(w^T x_i + b) \geq 1
-\end{aligned}
-$$
-
-为了后面计算方便，再做一点转换：
-
-$$
-\begin{aligned}
-  \min_{w,b} &\quad \frac{1}{2} \| w \|^2 \\
-  \text{s.t.} &\quad 1 - y_i(w^T x_i + b) \leq 0
-\end{aligned}
-$$
-
-
-### 对偶问题
-
-现在的目标函数是二次的，约束条件是线性的，所以它是一个凸二次规划问题。由于这个问题的特殊结构，这里通过拉格朗日对偶性（Lagrange duality）将其转换为对偶问题（dual problem）进行求解，这样做的优点在于：
-
-- 对偶问题更容易求解，减小计算复杂度
-- 可以自然的引入核函数，从而推广到非线性分类问题
-
-
-#### 拉格朗日乘子法
-
-我们面对的问题是不等式约束，令：
-
-$$
-\begin{aligned}
-  L(x, w, b, \lambda) &= \underbrace{f(x)}_{\text{要优化的函数}} + \sum_{i=1}^n \lambda_i \underbrace{g_i(x)}_{\text{约束条件}} \\
-    &= \frac{1}{2} \| w \|^2 + \sum_{i=1}^n \lambda_i \Big (1 - y_i(w^T x_i + b) \Big ) 
-\end{aligned}
-$$
-
-函数 $L(x,  w, b, \lambda)$ 为广义拉格朗日函数（将约束条件融合到目标函数里去，从而只用一个函数表达式来表达问题），$\lambda \geq 0$ 为拉格朗日乘子。
-
-按照拉格朗日乘子法的思路，可以用 $L(x,  w, b, \lambda)$ 对 $x$ 和 $\lambda$ 求偏导得到鞍点：
-
-$$
-\begin{cases}
-  \frac{\partial L}{\partial x_i} &i = 1, 2, \dots, n \\
-  \frac{\partial L}{\partial \lambda_k} &k = 1, 2, \dots, l
-\end{cases}
-$$
-
-再根据问题本身的具体情况检验出极值点。但这里共有 $n+l$ 个优化变量，如果全部求偏导工作量太大，所以考虑将原问题转化成其对偶问题进行求解。
-
-
-#### 极小极大问题
-
-定义一个函数：
-
-$$
-\theta_P(x) = \max_{\lambda_i \geq 0} L(x,  w, b, \lambda)
-$$
-
-容易得到：
-
-- 假设第 $i$ 个约束条件没有被满足，即 $g_i(x) > 0$，则可以使 $\lambda_i \to + \infty$，从而 $\theta_P(x) = + \infty$
-- 假设所有约束条件都满足了，则可以使 $\lambda_i \to 0$，从而 $\theta_P(x) = \frac{1}{2} \| w \|^2$
-
-所以极小化问题：
-
-$$
-\min_{w,b} \theta_P(x) = \min_{w,b} \max_{\lambda_i \geq 0} L(x,  w, b, \lambda)
-$$
-
-与原始最优化问题等价，即有相同的解（因为当趋向无穷时，问题无解，所以必须满足约束条件）。上式称为广义拉格朗日函数的**极小极大问题**，也是我们们要优化的**原始问题**。
-
-
-#### 强对偶性
-
-如果直接求解上述优化问题，需要考虑 $\min$ 的 $w$ 和 $b$，但这里我们可以通过强对偶转换把 $w$ 和 $b$ 化简掉，减小计算复杂度。
-
-原始问题的对偶问题为：
-
-$$
-\max_{\lambda_i \geq 0} \min_{w,b} L(x,  w, b, \lambda)
-$$
-
-如果原始问题与对偶问题都有最优解，容易推出：
-
-$$
-\underbrace{\max_{\lambda_i \geq 0} \min_{w,b} L(x,  w, b, \lambda)}_{\text{对偶问题}} \leq \underbrace{\min_{w,b} \max_{\lambda_i \geq 0} L(x,  w, b, \lambda)}_{\text{原始问题}} \\[1pt]
-$$
-
-这个性质叫**弱对偶性**（weak duality），对于所有优化问题都成立，即使原始问题非凸。但如果我们希望将原始问题转换为对偶问题求解，就要求它们必须满足**强对偶性**（strong duality）：
-
-$$
-\max_{\lambda_i \geq 0} \min_{w,b} L(x,  w, b, \lambda) = \min_{w,b} \max_{\lambda_i \geq 0} L(x,  w, b, \lambda)
-$$
-
-在满足以下两个条件的时候，可以进行强对偶转换：
-
-- **Slater 条件**：当主问题为凸优化问题, 即 $f$ 和 $g_i$ 为凸函数，$h_j$ 为仿射函数（$h_j(x) = 0$，SVM 里没有这个约束），且可行域中至少有一点使不等式约束严格成立时，对偶问题等价于主问题。
-
-  证明过程可以参考 [Convex Optimization](https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf) 5.3.2 节。
-
-  Slater 条件是强对偶成立的充分条件（强对偶成立的一种情况，并不是唯一的情况），确保了鞍点的存在。
-
-  显然，$f(x) = \frac{1}{2} \| w \|^2$ 和 $g_i(x) = 1 - y_i(w^T x_i + b)$ 都是凸函数，所以 SVM 满足 Slater 条件。
-
-- **KKT 条件**：取极值的充分条件，确保鞍点一定是最优解；当原问题是凸优化问题时，KKT 条件是取极值的充要条件。它要求原问题在最优值处必须满足：
-
-  - 拉格朗日乘子非负：$\lambda_i \geq 0$
-  - 约束条件满足：$g_i(x) < 0 \rArr 1 - y_i(w^T x_i + b) \leq 0$
-  - 互补松弛 (complementary slackness)：$\lambda_i g_i(x) = 0$
-  
-  KKT 条件的细节可以看[这里](https://zhuanlan.zhihu.com/p/38182879)。
-
-
-#### 对偶问题求解
-
-总结一下，我们要优化的是：
-
-$$
-\max_{\lambda_i \geq 0} \min_{w,b} \left [ \frac{1}{2} \| w \|^2 + \sum_{i=1}^n \lambda_i \Big (1 - y_i(w^T x_i + b) \Big ) \right ]
-$$
-
-
-##### 极小化
-
-先固定 $\lambda$，让 $L$ 关于 $w$ 和 $b$ 最小化，所以使 $w, b$ 的偏导等于零：
-
-$$
-\begin{gathered}
-  \frac{\partial L}{\partial w} = w - \sum_{i=1}^n \lambda_i x_i y_i = 0 \rArr w = \sum_{i=1}^n \lambda_i x_i y_i \\
-  \frac{\partial L}{\partial b} = \sum_{i=1}^n \lambda_i y_i = 0
-\end{gathered}
-$$
-
-把上述结果代回函数中：
-
-$$
-\min_{w,b} L(x,  w, b, \lambda) = \sum_{i=1}^n \lambda_i - \frac{1}{2} \sum_{i=1,j=1}^n \lambda_i \lambda_j y_i y_j x_i^T x_j
-$$
-
-::: details 证明
-$$
-\begin{aligned}
-  L(x,  w, b, \lambda) &= \frac{1}{2} \| w \|^2 + \sum_{i=1}^n \lambda_i \Big (1 - y_i(w^T x_i + b) \Big ) \\
-    &= \frac{1}{2} w^T w - \sum_{i=1}^n \lambda_i y_i w^T x_i - \underbrace{\sum_{i=1}^n \lambda_i y_i b}_{\text{代入} (2)} + \sum_{i=1}^n \lambda_i \\
-    &= \frac{1}{2} w^T \underbrace{\sum_{i=1}^n \lambda_i x_i y_i}_{\text{代入} (1)} - w^T  \sum_{i=1}^n \lambda_i y_i x_i + \sum_{i=1}^n \lambda_i \\
-    &= - \frac{1}{2} w^T \sum_{i=1}^n \lambda_i x_i y_i + \sum_{i=1}^n \lambda_i \\
-    &= - \frac{1}{2} \left (\sum_{i=1}^n \lambda_i x_i y_i \right )^T \sum_{i=1}^n \lambda_i x_i y_i + \sum_{i=1}^n \lambda_i \\
-    &= - \frac{1}{2} \underbrace{\sum_{i=1}^n \lambda_i y_i (x_i)^T}_{\lambda_i, y_i \text{ 都是实数，转置后与自身一样}} \sum_{i=1}^n \lambda_i y_i x_i + \sum_{i=1}^n \lambda_i \\
-    &= \sum_{i=1}^n \lambda_i - \frac{1}{2} \sum_{i=1,j=1}^n \lambda_i \lambda_j y_i y_j x_i^T x_j \\
-\end{aligned}
-$$
-:::
-
-可以看到 $w, b$ 已经被化简掉了，只要求出 $\lambda$ 就可以了。
-
-原问题的复杂度是与样本维度（即 $w$ 的维度）相关的，而转换成对偶问题后，复杂度就与样本维度无关，而只与样本数量有关了。在求解非线性问题时，会涉及到用核函数升维，升维后的样本维度往往远大于样本数量，这时在对偶问题下求解计算复杂度会小很多。
-
-
-##### 极大化（SMO）
-
-现在要让 $L$ 关于 $\lambda$ 最大化，即：
-
-$$
-\begin{aligned}
-  \max_{\lambda_i \geq 0} &\quad \sum_{i=1}^n \lambda_i - \frac{1}{2} \sum_{i=1,j=1}^n \lambda_i \lambda_j y_i y_j x_i^T x_j \\
-  \text{s.t.} &\quad \sum_{i=1}^n \lambda_i y_i = 0
-\end{aligned}
-$$
-
-把上式转换为求解极小：
-
-$$
-\begin{aligned}
-  \min_{\lambda_i \geq 0} &\quad \frac{1}{2} \sum_{i=1,j=1}^n \lambda_i \lambda_j y_i y_j x_i^T x_j - \sum_{i=1}^n \lambda_i \\
-  \text{s.t.} &\quad \sum_{i=1}^n \lambda_i y_i = 0
-\end{aligned}
-$$
-
-这个优化问题属于二次规划问题，可以用 **SMO**（序列最小优化算法，Sequential Minimal Optimization) 算法求解，其核心思想是：每次只优化一个参数，固定其他参数，仅求当前这个优化参数的极值。
-
-但因为有约束条件 $\sum_{i=1}^n \lambda_i y_i = 0$，没法一次只变动一个参数，所以这里一次优化两个参数。只有两个变量的二次规划问题存在解析解。
-
-选择两个需要更新的参数 $\lambda_i, \lambda_j$，那么 SMO 这一步的优化目标为：
-
-$$
-\begin{gathered}
-  \begin{split}   
-    \min_{\lambda_i \geq 0} \quad & \frac{1}{2} (\lambda_i^2 y_i^2 x_i^T x_i + \lambda_j^2 y_j^2 x_j^T x_j) + \lambda_i \lambda_j y_i y_j x_i^T x_j - (\lambda_i + \lambda_j) \\
-      &+ \lambda_i y_i \sum_{k \not = i, j} \lambda_k y_k x_i^T x_k + \lambda_j y_j \sum_{k \not = i, j} \lambda_k y_k x_j^T x_k
-  \end{split} \\
-  \text{s.t.} \quad \lambda_i y_i + \lambda_j y_j = c
-\end{gathered}
-$$
-
-其中 $c = - \sum_{k \not = i, j} \lambda_k y_k$。可以由 $(4)$ 得到 $\lambda_j = \frac{c - \lambda_i y_i}{y_j}$，由此可以消去 $\lambda_j$，这时目标问题就被转换为了只有一个约束条件 $\lambda_i$ 的最优化问题。
-
-SMO 的具体流程就直接去看《统计学习方法》7.4 节吧，或者[这里](https://zhuanlan.zhihu.com/p/32152421)也总结了一下，咕咕咕。
-
-
-### 求 w 和 b
-
-现在已经通过 SMO 求得了最优解 $\lambda^*$，现在需要算出 $w$ 和 $b$。
-
-由公式 $(1)$ 可以求得 $w$。
-
-::: info 支持向量
-支持向量是 $\lambda_i > 0$ 对应的样本
-:::
-
-::: details 证明
-由 KKT 条件可以得到：
-
-$$
-\lambda_i (1 - y_i(w^T x_i + b)) = 0
-$$
-
-所以当 $\lambda_i > 0$ 时：
-
-$$
-1 - y_i(w^T x_i + b) = 0 \rArr y_i(w^T x_i + b) = 1
-$$
-
-所以样本 $x_i$ 是支持向量。
-:::
-
-所以根据 $\lambda_i > 0$ 随便找个支持向量 $x_s$，然后带入 $y_s(w^T x_s + b) = 1$ 求出 $b$ 即可：
-
-$$
-\begin{gathered}
-  y_s(w^T x_s + b) = 1 \\
-  \rArr y_s^2(w^T x_s + b) = y_s \\
-  \rArr w^T x_s + b = y_s \\
-  \rArr b = y_s - w^T x_s
-\end{gathered}
-$$
-
-考虑到鲁棒性，可以用支持向量的均值来算 $b$：
-
-$$
-b = \frac{1}{|S|} \sum_{s \in S} (y_s - w^T x_s)
-$$
-
-其中 $S$ 是所有支持向量的集合。然后最大间隔超平面 $w^T + b = 0$ 就算出来了。
-
----
-
-之前我们从直觉上得出了 SVM 的参数只受支持向量的影响，与其他样本无关这个结论。现在我们可以从数学上证明一下这个结论：
-
-::: info SVM 的参数仅由支持向量决定，与其他样本无关
-由于支持向量是 $\lambda_i > 0$ 对应的样本，所以：
-
-$$
-\begin{aligned}
-  w &= \sum_{i=1}^n \lambda_i x_i y_i \\
-    &= \sum_{i: \lambda_i = 0} 0 \cdot x_i y_i + \sum_{i: \lambda_i > 0} \lambda_i x_i y_i \\
-    &= \sum_{i \in S} \lambda_i x_i y_i
-\end{aligned}
-$$
-:::
-
-也就是说我们只需要保存支持向量以供预测。
-
-
-
-## 软间隔
-
-到目前为止的推导都是基于数据线性可分的假设下进行的，这个假设下的间隔叫**硬间隔**（hard margin）。但这个假设可能不成立：
-
-<img src="/img/in-post/2021-06-12/soft-margin.jpg" width="350px" alt="soft margin" />
-
-虽然理论上我们总能找到一个高维映射（核函数）使数据线性可分，但在实际应用中，寻找这样一个合适的核函数可能会很难。同时由于数据中通常有噪声存在，一味追求数据线性可分可能会使模型过拟合。所以我们引入了**软间隔**（soft margin），允许部分样本分类错误（上图中的小红点和小蓝点），即不满足约束条件 $1 - y_i(w^T x_i + b) \leq 0$。
-
-为了度量这个间隔软到何种程度，我们为每个样本引入一个**松弛变量**（slack variable）$\xi_i \geq 0$：
-
-$$
-1 - y_i(w^T x_i + b) - \xi_i \leq 0
-$$
-
-并且我们希望分类错误的样本要尽可能少。所以现在优化目标变成了：
-
-$$
-\begin{aligned}
-  \min_{w,b} &\quad \frac{1}{2} \| w \|^2 + C \sum_{i=1}^n \xi_i \\
-  \text{s.t.} &\quad 1 - y_i(w^T x_i + b) - \xi_i \leq 0, \xi_i \geq 0
-\end{aligned}
-$$
-
-其中 $C$ 是一个大于 0 的常数，可以理解为错误样本的惩罚程度。特殊情况，当 $C$ 无穷大时，$\xi$ 就会无穷小，相当于线性可分 SVM。
-
-
-### 拉格朗日函数
-
-这样拉格朗日函数就变为了：
-
-$$
-L(x, w, b, \lambda, \xi) = \frac{1}{2} \| w \|^2 + C \sum_{i=1}^n \xi_i + \sum_{i=1}^n \lambda_i \Big (1 - \xi_i - y_i(w^T x_i + b) \Big ) - \sum_{i=1}^n \mu_i \xi_i
-$$
-
-其中 $\lambda_i \geq 0, \mu_i \geq 0$ 为拉格朗日乘子。
-
-
-### 强对偶性
-
-通过强对偶性把优化问题转换为：
-
-$$
-\max_{\lambda_i \geq 0, \mu_i \geq 0} \min_{w, b, \xi} L(x, w, b, \lambda, \xi)
-$$
-
-
-### 对偶问题求解
-
-跟线性 SVM 一样，先固定 $\lambda, \mu$，让 $L$ 关于 $w, b, \xi_i$ 最小化，即使 $w, b, \xi_i$ 的偏导为零：
-
-$$
-\begin{gathered}
-  \frac{\partial L}{\partial w} = w - \sum_{i=1}^n \lambda_i x_i y_i = 0 \rArr w = \sum_{i=1}^n \lambda_i x_i y_i \\
-  \frac{\partial L}{\partial b} = \sum_{i=1}^n \lambda_i y_i = 0 \\
-  \frac{\partial L}{\partial \xi_i} = C - \lambda_i - \mu_i = 0 \rArr \lambda_i + \mu_i = C \\
-\end{gathered}
-$$
-
-把上面的式子代入拉格朗日函数得到：
-
-$$
-\min_{w, b, \xi} L(x, w, b, \lambda, \xi) = \sum_{i=1}^n \lambda_i - \frac{1}{2} \sum_{i=1,j=1}^n \lambda_i \lambda_j y_i y_j x_i^T x_j
-$$
-
-可以看到 $\mu$ 被化简掉了，所以只需要最大化 $\lambda$ 就好。转换成求解极小：
-
-$$
-\begin{aligned}
-  \min_{\lambda_i \geq 0} &\quad \frac{1}{2} \sum_{i=1,j=1}^n \lambda_i \lambda_j y_i y_j x_i^T x_j - \sum_{i=1}^n \lambda_i \\
-  \text{s.t.} &\quad \sum_{i=1}^n \lambda_i y_i = 0, \lambda_i + \mu_i = C
-\end{aligned}
-$$
-
-因为 $\mu_i \geq 0$，所以 $\lambda_i = C - \mu_i < C$，于是 $\mu_i$ 被消去了，所以上式现在写做：
-
-$$
-\begin{aligned}
-  \min_{\lambda_i \geq 0} &\quad \frac{1}{2} \sum_{i=1,j=1}^n \lambda_i \lambda_j y_i y_j x_i^T x_j - \sum_{i=1}^n \lambda_i \\
-  \text{s.t.} &\quad \sum_{i=1}^n \lambda_i y_i = 0, \lambda_i < C
-\end{aligned}
-$$
-
-可以看到这个式子相比硬间隔的版本只是多了一个约束条件 $\lambda_i < C$。然后用 SMO 算法得到最优解 $\lambda^*$ 即可。
-
-再然后用和硬间隔一样的方法求出 $w$ 和 $b$，从而求出超平面就行。
-
-
-### Hinge Loss
-
-SVM 的优化目标还有另外一种理解，即最小化 **Hingle Loss**：
-
-$$
-L = \sum_{i=1}^n \max(1 - y_i(w^T x_i + b), 0) + \lambda \| w \|^2
-$$
-
-其中第一项是经验风险，第二项是正则项。它的意思是 $y_i(w^T x_i + b) > 1$ 时损失为 0，否则损失为 $1 - y_i(w^T x_i + b)$。相比感知机的损失函数 $\max(y_i(w^T x_i + b), 0)$ 来说，hinge loss 不仅要分类正确，而且置信度还要足够高（间隔最大化），损失才为 0，更加严格。
-
-Hingle Loss 的函数图像为：
-
-<img src="/img/in-post/2021-06-12/hinge-loss.png" width="450px" alt="hinge loss" />
-
-因为长得像本打开的书，所以中文名叫合页损失。它的零区域对应的是不是支持向量的普通样本，从而所有的普通样本都不参与最终超平面的决定。
-
-
-
-## 核函数
-
-前面讨论的硬间隔和软间隔都是假设训练样本的线性可分或至少大部分线性可分，但很多时候样本不是线性可分的（左图）：
-
-<img src="/img/in-post/2021-06-12/kernel.png" width="600px" alt="hinge loss" />
-
-这是就需要用到**核函数**（kernel function）将原空间的样本映射到一个更高维甚至无穷维（比如高斯核）的空间（右图），让样本点在高维空间线性可分，然后再学习出一个最大间隔超平面。
-
-一个定理是：
-
-::: info
-当 $d$ 有限时，一定存在 $\tilde{d}$，使得样本在空间 $\Reals^{\tilde{d}}$ 中线性可分。
-:::
-
-那么设原空间为 $\mathcal{X} \in \Reals^d$，新空间为 $\mathcal{Z} \in \Reals^{\tilde{d}}$，从原空间到新空间的映射为 $\phi: \mathcal{X} \to \mathcal{Z}$。我们把函数 $K(x, z) = \phi(x) \cdot \phi(z)$ 叫做**核函数**。
-
-现在新空间中的超平面可以写为 $w^T \phi(x) + b = 0$，非线性 SVM 的对偶问题变为：
-
-$$
-\begin{aligned}
-  \min_{\lambda_i \geq 0} &\quad \frac{1}{2} \sum_{i=1,j=1}^n \lambda_i \lambda_j y_i y_j K(x_i, x_j) - \sum_{i=1}^n \lambda_i \\
-  \text{s.t.} &\quad \sum_{i=1}^n \lambda_i y_i = 0, \lambda_i < C
-\end{aligned}
-$$
-
-可以看到实际上我们只定义了核函数 $K$，而并没有显示地定义映射函数 $\phi$，因为通常来说直接计算 $K(x, z)$ 比较容易，而通过 $\phi(x)$ 和 $\phi(y)$ 来计算 $K(x, z)$ 则并不容易。也就是说核函数并没有把特征映射到高维空间，而是找到了一种直接在低位空间对高维空间中的向量做点积运算的简便方法。
-
-
-### 常用核函数
-
-常用的核函数 $K(x_i, x_j)$ 有：
-
-|   名称       |   形式      |   优点           |   缺点              |
-| ----------- | ----------- | --------------- | ------------------ |
-| 线性核       | $x_i^T x_j$ | 高效；不容易过拟合 | 无法解决非线性可分问题 |
-| 多项式核      | $(\beta x_i^T x_j + \theta)^p$ | 比线性核更一般，$p$ 直接描述了被映射空间的复杂度  | 参数多，当 $p$ 很大时会导致计算不稳定 |
-| 高斯核（RBF） | $\exp \left (- \frac{\| x_i - x_j \|^2}{2 \sigma^2} \right )$  | 只有一个参数，没有计算不稳定的问题 | 计算慢；$\sigma$ 是超参，所以需要调参；过拟合风险大 |
-
-
-### 正定核
-
-如果要自定义核函数，则需要满足 Mercer 条件：
-
-::: info Mercer 条件
-对于任意训练样本 $\{x_1, x_2, \dots, x_n\}$，核函数 $K$ 对应的矩阵 $[K(x_i, x_j)]_{n \times m}$ 是[半正定](https://zh.wikipedia.org/wiki/正定矩阵)的。
-
-满足这个条件的核函数叫正定核。
-:::
-
-
-## 优缺点
-
-优点：
-
-- 有严格的数学理论支持，可解释性强
-- 能找出对任务至关重要的关键样本（支持向量）
-- 参数只依赖少量的支持向量，无需依赖全体样本
-- 计算的复杂性取决于样本的数量，而不是样本的维数，避免了“维数灾难”，可以有效解决高维特征的分类和回归问题
-- 使用核函数后可以应对线性不可分问题
-- 样本数量中等偏小时，同样有较好的效果
-
-缺点：
-
-- 在特征维度远大于样本个数时表现一般
-- 在样本数量很多时训练时间会很长：SMO 算法每次都需要挑选一对参数，因此时间复杂度为 $O(n^2)$，其中 $n$ 为训练样本的数量
-- 非线性问题的核函数没有选择标准
-- 采用核函数时，如果需要存储核矩阵，则空间复杂度为 $O(n^2)$
-- 因为参数只依赖少量的支持向量，所以对缺失数据敏感
-- 模型的预测时间与支持向量的个数成正比，所以当支持向量的数量较大时，预测时间复杂度较高
-
-
-
-## 参考
-
-- 统计学习方法. 李航.
-- [【机器学习】支持向量机 SVM（非常详细）](https://zhuanlan.zhihu.com/p/77750026)
-- [支持向量机通俗导论（理解SVM的三层境界）](https://blog.csdn.net/v_july_v/article/details/7624837)
-- [拉格朗日对偶性](https://zhuanlan.zhihu.com/p/38182879)
-- [支持向量机（SVM）必备知识(KKT、Slater、对偶）](https://blog.csdn.net/feilong_csdn/article/details/62427148)
-- [Convex Optimization](https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf). Stephen Boyd and Lieven Vandenberghe. 2004.
-- [支持向量机（SVM）—— SMO 算法](https://zhuanlan.zhihu.com/p/32152421)
Index: blog/posts/2020-07-17-transformer.md
===================================================================
diff --git a/blog/posts/2020-07-17-transformer.md b/blog/posts/2020-07-17-transformer.md
deleted file mode 100644
--- a/blog/posts/2020-07-17-transformer.md	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
+++ /dev/null	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
@@ -1,230 +0,0 @@
----
-layout: Post
-title: Transformer
-subtitle: "试图理一理 Transformer"
-author: Renovamen
-date: 2020-07-17
-headerImage: /img/in-post/2020-07-17/header.jpg
-permalinkPattern: /post/:year/:month/:day/:slug/
-tags:
-  - NLP
----
-
-**Attention Is All You Need.** *Ashish Vaswani, et al.* NIPS 2017. [[Paper]](https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf) [[Code]](https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/models/transformer.py)
-
-<!-- more -->
-
-考虑到 RNN 只能单向依次计算，所以存在以下问题：
-
-- $t$ 时刻的计算依赖与 $t-1$ 时刻的计算结果，限制了模型的并行能力
-
-- RNN 的长期依赖问题
-
-于是这篇论文扔掉了 encoder 和 decoder 中的 RNN 结构，完全用 attention 来搞 machine translation：
-
-- 没有 RNN 结构，所以有更好的并行能力
-
-- attention 机制对全局信息的处理更有效
-
-Transformer 整体结构如下：
-
-<img src="/img/in-post/2020-07-17/transformer.png" width="400px" alt="Transformer" />
-
-
-## Position Embedding
-
-Transformer 扔掉了 RNN，对输入句子的所有单词都是同时处理的，所以失去了捕捉单词的排序和位置信息的能力。如果不解决词序的问题，那即使把一句话打乱，attention 出来的结果也是一样的，相当于这就只是一个词袋模型。为了解决这个问题，论文引入 position embedding 来对单词的位置信息进行编码。最终的输入词向量 = word embedding + position embedding：
-
-![Positional Embedding](/img/in-post/2020-07-17/positional-embedding.png)
-
-<p class="desc">图片来源：<a href="http://jalammar.github.io/illustrated-transformer#representing-the-order-of-the-sequence-using-positional-encoding" target="_blank">The Illustrated Transformer</a></p>
-
-
-有两种搞到 position embedding 的思路：
-
-- 学习出一份 position embedding（[**Convolutional Sequence to Sequence Learning**](http://proceedings.mlr.press/v70/gehring17a/gehring17a.pdf). *Jonas Gehring et al.* ICML 2017.）
-
-- 直接用不同频率的 sin 和 cos 函数算出来
-
-经过实验，论文发现这俩方法效果差不多，所以选了第二种方法，因为它有以下好处：
-
-- 不需要加额外的训练参数
-
-- 学习出来的 position embedding 会受到训练集中序列的长度的限制，但三角函数明显不受序列长度的限制，所以能够处理训练集中没见过的序列长度
-
-具体的位置编码公式为：
-
-$$
-PE(pos, 2i) = \sin(\frac{pos}{10000^{\frac{2i}{d_{\text{model}}}}})
-$$
-
-$$
-PE(pos, 2i+1) = \cos(\frac{pos}{10000^{\frac{2i}{d_{\text{model}}}}})
-$$
-
-其中 $d_{\text{model}}$ 为词嵌入维度（论文中为 512），pos 为该单词在序列中的位置，$2i$ 为词向量的偶数维度（用第一个公式），$2i+1$ 指词向量的奇数维度（用第二个公式）。波的频率和偏移对于每个维度是不同的：
-
-![wave](/img/in-post/2020-07-17/wave.png)
-
-<p class="desc">图片来源：<a href="http://nlp.seas.harvard.edu/2018/04/03/attention.html#positional-encoding" target="_blank">The Annotated Transformer</a></p>
-
-因为三角函数还有以下特性：
-
-$$
-\cos(\alpha + \beta) = \cos(\alpha) \cos(\beta) - \sin(\alpha) \sin(\beta)
-$$
-
-$$
-\sin(\alpha + \beta) = \sin(\alpha) \cos(\beta) + \cos(\alpha) \sin(\beta)
-$$
-
-所以任意位置的 $PE(pos+k)$ 都能通过 $PE(pos)$ 线性表达，这为模型捕捉单词之间的相对位置关系提供了非常大的便利。
-
-
-## Encoder
-
-论文中的 encoder 由 N = 6 个相同的 layer 堆叠而成：
-
-<img src="/img/in-post/2020-07-17/encoder.png" width="180px" alt="encoder" />
-
-
-每个 layer 由两个 sub-layer 组成，分别为 multi-head self-attention 和 fully connected feed-forward network。
-
-并且每个 sub-layer 都加了：
-
-- Residual Connection：解决多层神经网络训练困难的问题，通过将前一层的信息无差的传递到下一层，可以有效的仅关注差异部分
-
-- Layer Normalisation：对层的激活值进行归一化，可以加速模型的训练过程，使其更快的收敛
-    
-    [**Layer Normalization**](https://arxiv.org/pdf/1607.06450.pdf). *Jimmy Lei Ba, et al.* arXiv 2016.
-
-也就是输入会先进 LayerNorm，再进 sub-layer，然后加在原始输入上（虽然图上 LayerNorm 似乎在 sub-layer 后面，但[代码](http://nlp.seas.harvard.edu/2018/04/03/attention.html#encoder)里的确是先进 LayerNorm）。最后 6 个 layer 都跑完之后还要再单独 norm 一次（虽然图上没画但[代码](http://nlp.seas.harvard.edu/2018/04/03/attention.html#encoder)里写了）。
-
-
-### Muti-Head Self-Attention
-
-attention 可以表示为以下形式：
-
-$$
-att\_out = \text{Attention}(Q, K, V)
-$$
-
-其中 $V$（value）用来求加权和得到最终的上下文向量，而 $Q$（query）和所有的 $K$（key）会被用来计算注意力权重。如在传统的 seq2seq 结构中，它们分别由以下值经过线性变换得到：
-
-- $Q$：decoder 的当前输入
-
-- $V$：encoder 的输出（$h_1, h_2, \dots, h_n$）
-
-- $K$：同 $V$
-
-而这里是 self-attention，所以 $Q, V, K$ 由同一个值 $x$ 经过线性变换得到，$x$ 在第一个 layer 为输入的词向量序列，在之后的 layer 则为上一个 layer 的输出。
-
-而 multi-head attention 就是通过 $h=8$ 个不同的线性变换得到不同的 $Q, V, K$，最后将这 $h$ 个 attention 结果拼接起来：
-
-![multi-head sekf-attention](/img/in-post/2020-07-17/multi-head-self-attention.png)
-
-<p class="desc">图片来源：<a href="http://jalammar.github.io/illustrated-transformer#the-beast-with-many-heads" target="_blank">The Illustrated Transformer</a></p>
-
-
-这里的 attention 计算公式为（scaled dot-product）：
-
-$$
-\text{Attention}(Q, K, V) = \text{softmax}(\frac{QK^T}{\sqrt{d_k}}) V
-$$
-
-注意：这里跟 $V$ 是**矩阵相乘**，不是 element-wise 相乘。
-
-![attention](/img/in-post/2020-07-17/attention.png)
-
-其中 $d_k = d_{\text{model}} / h = 512 / 8 = 64$。除以 $\sqrt{d_k}$ 是因为，$d_k$ 越大 $QK^T$ 就会越大，可能就会将 softmax 函数推入梯度极小的区域，所以要用 $\sqrt{d_k}$ 对 $QK^T$ 进行缩放。
-
-图中的 mask 只会在 [decoder](#masked-multi-head-self-attention) 中被用到。
-
-
-### Feed-Forward Network
-
-第二个 sub-layer 是一个前馈网络：
-
-$$
-\text{FFN} = \max(0, xW_1 + b_1) W_2 + b_2
-$$
-
-
-## Decoder
-
-encoder-decoder 结构：
-
-![encoder-decoder](/img/in-post/2020-07-17/encoder-decoder.png)
-
-<p class="desc">图片来源：<a href="http://jalammar.github.io/illustrated-transformer#the-residuals" target="_blank">The Illustrated Transformer</a></p>
-
-[这里](http://jalammar.github.io/illustrated-transformer#the-decoder-side)还有两个清楚的解释了 encoder 和 decoder 的工作方式的动画。
-
-decoder 也由 N = 6 个相同的 layer 堆叠而成，每个 layer 由三个 sub-layer 组成：
-
-<img src="/img/in-post/2020-07-17/decoder.png" width="180px" alt="decoder" />
-
-
-### Masked Multi-Head Self-Attention
-
-在训练时，decoder 在预测第 $i$ 个位置时不应该看到未来的信息，但 self-attention 机制能让它看到全局信息（标签泄露）。所以会对在 self-attention 的 softmax 层前加 mask，将未来信息屏蔽掉。
-
-mask 是一个下三角矩阵，对角线以及对角线左下都是1，其余都是0：
-
-<img src="/img/in-post/2020-07-17/mask.png" width="300px" alt="mask" />
-
-<p class="desc">mask 矩阵，蓝色部分是 1，白色部分是 0（图片来源：<a href="https://spaces.ac.cn/archives/6933#单向语言模型" target="_blank">从语言模型到 Seq2Seq：Transformer 如戏，全靠 Mask</a>）</p>
-
-矩阵的行为当前预测到第几个单词，列为当前允许看到前几个位置的信息。然后 mask=0 的位置上的元素会都被替换为 `-inf`。
-
-### Multi-head Attention
-
-即论文 3.2.3 节中的 encoder-decoder attention。它的 $Q$ 来自于上一位置的 decoder 的输出（第一个 layer）或上一个 decoder layer 的输出（之后的 layer），而 $K$ 和 $V$ 来自于 encoder 的输出。这让 decoder 的每一个位置都可以看到到输入序列的全局信息。
-
-编码可以并行计算，但解码时，因为需要上一时刻的输出当作 $Q$，所以无法并行计算。
-
-
-### Feed-Forward Network
-
-同 encoder。
-
-
-## Summary
-
-优点：
-
-- 相比其他方法，当序列长度 $n$ 小于词向量维度 $d$ 时，每层的计算复杂度（complexity per layer）更低：
-
-    ![complexity](/img/in-post/2020-07-17/complexity.png)
-
-- 更好的并行性，符合目前的硬件（GPU）环境
-
-- 更好地处理长时依赖问题：如果要处理一个长度为 n 的序列，CNN 需要增加卷积层数来扩大视野，RNN 需要从 1 到 n 逐个进行计算，而 self-attention 只需要一步矩阵运算就可以
-
-
-缺点：
-
-- 但同时从上面那张复杂度表里也能看出来，当句子太长时，Transformer $O(n^2)$ 的时间复杂度是非常爆炸的。Transformer 能更好地处理长时依赖问题，但这种复杂度又让它没法处理太长的文本，即使是 Bert 的最大长度也只有 512。
-
-    于是出现了一堆致力于解决这个问题的后续工作，等我摸两天鱼再看看有没有空写这个...
-
-- 扔掉了 RNN 和 CNN，导致失去了捕捉局部特征的能力
-
-    不过论文也提到了一个 restricted self-attention（上面那张复杂度表里有），它假设当前词只与前后 $r$ 个词有关，因此只在这 $2r+1$ 个词上做 attention，复杂度是 $O(nr)$，相当于是在捕捉局部特征。听上去很像卷积窗口？
-
-- 失去的位置信息非常重要，在词向量中加入 position embedding 这个解决方案依然不够好
-
-- 非图灵完备（computationally universal）
-
-    [**Universal Transformer**](https://openreview.net/pdf?id=HyzdRiR9Y7). *Mostafa Dehghani, et al.* ICLR 2019.
-
-
-## Reference
-
-- 图解 Transformer：[The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/)
-
-- 连着代码一起讲：[The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html)
-
-- [【NLP】Transformer 详解](https://zhuanlan.zhihu.com/p/44121378)
-
-- [详解 Transformer（Attention Is All You Need）](https://zhuanlan.zhihu.com/p/48508221)
Index: blog/posts/2018-11-11-zelda-horizon.md
===================================================================
diff --git a/blog/posts/2018-11-11-zelda-horizon.md b/blog/posts/2018-11-11-zelda-horizon.md
deleted file mode 100644
--- a/blog/posts/2018-11-11-zelda-horizon.md	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
+++ /dev/null	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
@@ -1,23 +0,0 @@
----
-layout: Post
-title: "《塞尔达传说：荒野之息》&《地平线：黎明时分》联动"
-subtitle: "The Legend of Zelda: Breath of the Wild & Horizon: Zero Dawn"
-author: Renovamen
-date: 2018-11-11
-useHeaderImage: true
-headerImage: /img/in-post/2018-11-11/header.jpg
-headerMask: rgb(71, 108, 152, .2)
-permalinkPattern: /post/:year/:month/:day/:slug/
-tags:
-  - 摸鱼
----
-
-摸鱼。（等等你代码写完了吗......
-
-<!-- more -->
-
-![img-1](/img/in-post/2018-11-11/1.jpg)
-![img-2](/img/in-post/2018-11-11/2.jpg)
-![img-3](/img/in-post/2018-11-11/3.jpg)
-![img-4](/img/in-post/2018-11-11/4.jpg)
-<img src="/img/in-post/2018-11-11/5.jpg" width="400px" />
Index: blog/posts/2017-06-09-my-high-school-life.md
===================================================================
diff --git a/blog/posts/2017-06-09-my-high-school-life.md b/blog/posts/2017-06-09-my-high-school-life.md
deleted file mode 100644
--- a/blog/posts/2017-06-09-my-high-school-life.md	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
+++ /dev/null	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
@@ -1,69 +0,0 @@
----
-layout: Post
-title: 高中生活回忆录
-subtitle: My High School Life
-author: Renovamen
-date: 2017-06-09
-useHeaderImage: true
-headerImage: /img/in-post/2017-06-09/header.jpeg
-headerMask: rgb(14, 21, 5, .2)
-permalinkPattern: /post/:year/:month/:day/:slug/
-tags:
-  - 摸鱼
----
-
-总得有地方来存我当年写的小作文。
-
-<!-- more -->
-
----
-
-高考之前，我想“等我考完后我要写一篇高中生活回忆录”。本来是准备去自主招生的时候在等飞机/等车/等考试开始/等别的什么东西/除了发呆没什么可干时码一篇出来，不过这些时间都被我用来码另一篇“非常阴暗版本的高中生活回忆录”（虽然我最开始给它起的名字是“光辉人生回忆录”）了，这个版本阴暗得我现在都不想再看一遍...
-
-然后我决定在我 18 岁生日的时候写一篇出来，可是我懒，所以...
-
-如今又一年的高考都已经考完了，我就要期末考试，许多 ddl 没赶完，许多东西想学没学会，可我居然在写这个一年前就该完成的东西，orz...
-
----
-
-我大概从来就不是学习得进去的人，我高中三年学习最努力的时候，是高一上学期换座位换到一个数竞大大大大大大大神的后面，然后包括我在内的坐在大神周围的人就目睹了他两天做完了本来该一个学期做完的练习册...然后我们就像打了鸡血一样拼命的预习和刷题（我当时把这称之为“军备竞赛”），当然这鸡血的效果并没有持续太久...
-
-既然学不进去，那能不学的时候就不学吧。于是我下课后要是困就睡觉，不困就在教室外面晃来晃去，反正不想学习。到了高二高三已经到了要是哪节课下了不出去晃就浑身不舒服的地步，所以当时特别喜欢做靠走廊或最后一排的位置，因为这样就不会面临下了课想出去逛而两边同桌都在睡觉不想叫醒他们的尴尬...
-
-高一高二的时候教室还在至善楼一楼，至善楼前是一块还算巨大的平地，种了很多树，教室门口就是那颗巴蜀引以为傲的菩提，虽然长得似乎不太好。总之那就是我晃了两年的地方，我相信有很多人虽然不认识我，但看到我后也会知道“就是这个傻子天天在楼下晃”。有一次一个隔壁班的、初三时教室在五楼的女生跟我说：“一年前我走出教室，看到的是树顶，而现在我走出教室后却站在树底”。然后我想了想，初三时我在四楼，下课后会趴在走廊的栏杆上，有时会有一个很有哲思的同学跟我出来聊一些可能我也不知道是什么的问题，反正我从来没有关注过那棵菩提，那时候巴蜀还在翻修，菩提刚被移植过来，长得...呃...挺凄凉的...
-
-高三时我们就被关进了那个天井式的教学楼，于是下课后我就只能趴在教室门口围城一圈的栏杆上发呆，我经常趴的位置正对我们班和隔壁班的教室，于是我发着呆看着同学们从教室门出来又进去，一年下来对隔壁班很多同学了解了不少...虽然这并没有什么用...我一边无所事事一边期待有人会从某个教室里走出来随便用什么方式告诉我我所想的所做的她都能理解。我想那个时候我大概真的很孤独，既然孤独那不如滚去学习，可我不想学习，于是把大把的时间都耗在神游与发呆上，耗在仰头透过楼顶的玻璃看光影变幻上，耗在和隔壁班的室友站在办公室前的走廊上看树的叶子由绿变黄最后掉光上，耗在思考“我为什么是一个人呢”“说不定我不是一个人呢”“是个神也不一定呢”这种终极哲学问题上...
-
-可能支撑我过完高三的就是这样的无所事事吧。高二高三过得挺憋屈的，发生了很多事，惹到了很多人。这些事和人在心里乱成一团很难受，可我也不敢去理清楚，我怕我理着理着就崩溃，毕竟高二的时候就有人对我说过「我觉得你高三会去跳楼」。我大概不算是一个讨人喜欢的人，可我也不想去跳楼，于是就这样无所事事什么也不想反而成了一种幸福。然而想不清楚那些乱成一团的事就会让人变得偏执和自我，这种偏执和自我在高考前夕爆发，于是我伤害到了一个当时挺喜欢的人并搞僵了关系，嗷看起来我真是禽兽...
-
-除了在外面发呆我还是干了很多事，比如用那个配置很低屏幕很小的安卓机强行玩了很多游戏并把它们推荐给了室友；比如画了许多火柴人；比如不知为何让同学觉得我要做一个“炸掉巴蜀大帝国”的游戏，虽然这游戏直到现在都还没开始做...好吧看起来这三年我过得浑浑噩噩，这样的浑浑噩噩只能让我不断想起进高中之前的自己，那时候我觉得自己刀枪不入百毒不侵天下无敌，希望扛着八十二斤的大刀走南闯北，吼着我们的火要把世界都点燃...
-
-高中干的另外一件目前看来还不算那么浑浑噩噩的事就是去学竞赛，然而一直以来学竞赛的最重要的目的“把课外时间都花去学竞赛就有理由不学习了，也有理由考试考差了”也挺浑浑噩噩的。那时总有同学觉得我是热爱计算机的大佬，可我真的学得很烂也没那么热爱计算机...在竞赛机房的时候我其实也很颓废，我知道自己该刷题该背模板该学新算法，可就是克制不住的坐在电脑前发呆。可就算是这样，NOIP 成绩出来前的那个晚上，我以为我没拿到省一，居然还哭了，哭得莫名其妙。我明明不该在意这个，我宁愿发呆都不愿意写代码，又有什么资格在意成绩。简直不可理喻，没有投入什么努力却要有那种“我天下无敌没有什么做不到”的所谓骄傲。省选前的那几天也知道自己该把各种常考的板都背一篇，毕竟之前可持久化线段树莫比乌斯反演什么的就基本没在不看板的情况下写出来过，可我依然没去背。省选前一天去考场踩点试机子，隔壁八中的人在机子上敲了一遍 Splay，而我在机子上打开了扫雷。于是省选的时候看着五道题里面一道可持久化线段树一道莫比乌斯反演当场心态就崩了，崩得连网络流都一分没得，理所当然的没进省队，滚回去全职准备高考。
-
-刚退竞赛的时候是高二下学期，成绩爆炸，排名几百名开外，一轮复习都快开始了，而我还缺了很多知识点。尤其是化学，基本就跟没学过一样，高中唯一一次不及格就是刚退竞赛的时候化学考了个 53。然后我学竞赛的目的就达成了，连我爸妈都觉得我是因为学了竞赛才这样的。事实上我知道以我那两年的状态就算不学竞赛大概也好不到哪里去。一轮二轮三轮复习跟完后看起来学得差不多了，但肯定还有很多很多我知道或不知道的漏洞，鬼知道高考会考到哪个漏洞上面，然后我就挂了。值得欣慰的是那年重庆第一年考全国卷，题目居然出奇的简单，以至于我物理压轴算了三遍，每一遍都觉得“怎么会那么简单，一定是我哪里搞错了”，于是漏洞并没有暴露多少。
-
-然后我的真实分数还是很难看，跟我的预估分差了二十多分，这分数让我一脸懵逼。
-
-看到成绩的时候基本就确定了得在两个自招过了的学校里选一个。以我当时的成绩，同济是我能去的最好的学校，也不知道我是怎么拿到降分的。同济自招先考实验再面试，实验是测不明液体的密度，大概做得不怎么样。实验环节提供了计算器，但我当时不会用科学计算器，敲完除法后计算器上会出现一个分数，我不知道该怎么调成小数，于是我最后还是扔掉了计算器全程手算。我的上海室友（上海高考允许用计算器）在知道了这件事以后，嘲笑了我一顿，并在考高数前教会了我科学计算器的基本用法（感谢她）。面试的时候，靠着“说话完全不过脑”和“一面试就胡说八道”综合症，我基本上对每个问题都给出了死亡回答。比如老师问：“你为什么要选择软件工程专业呢”，我：“因为按照同济的政策，信息学竞赛选手只有软件工程、工科试验班计算机大类和飞行器制造工程三个选择，而我不想造飞行器，也不太明白工科试验班是什么”。总之我现在想到我面试的时候说的那些莫名其妙的话依然会觉得尴尬，老师们愿意给降分完全是大恩大德。
-
-现在在同济我也不知说不说得上后悔，但让我再选一次我肯定会去另外一个学校。但另外一个学校在任何人看来都不会是主流选择，于是我爸妈不同意，我跟他们吵，跟他们找来劝我的人吵，填志愿截止的那个晚上我都想找机会改志愿。可最后还是觉得算了吧，我高中三年几乎没有哪一次考试排名能够得上同济的录取线，再怎么也轮不到我去嫌弃同济。于是就这样尘埃落定。
-
-我记得高中时我不止一次做在机房的电脑前信誓旦旦的说“我大学肯定不学计算机相关专业”，成绩还没出来的时候我也按照我的预估分看了很多学校和专业。而成绩出来以后，我看的那些学校和专业都没有了意义，最后依然没逃过当码农的命运。我也不知道我现在进了同济后现在是个什么状态，反正不是什么能让我征服宇宙的状态，但还是比高中好多了。
-
-高考完以后考英语口语，开放性题目抽到了“未来想做的职业”，我一开口就跑火车：“theoretical physicist, because theoretical physics is difficult, 而我就喜欢难的ヽ(ˋ▽ˊ)ノ”，然后俩考官就肉眼可见的开始笑。口语考完后去寝室收东西，把书都堆在了寝室门口跟宿管阿姨拿去卖废纸。我把还算看得过去的几本笔记带走了，每本上面都有我画的火柴人。我对着高三时写的那本日记思考了一会儿，上面是我即使不做作业也要固执的用潦草的字迹和混沌的草图记下的记忆、幻想、痛苦与梦魇一般的信仰。最后我还是把它带走了，压在了家里柜子深处一堆杂物下面，我至今没有勇气再翻开它，可能以后也不会再有。走的时候和以前任何一起期末考完收东西回家没什么区别，就好像跟我们寝室的隔壁寝室的对面寝室的人以后还会经常见面。
-
-然而很多人其实就再也没有见过了。
-
-就算发生了很多事，就算有的人你已经决定不再去关注，已经在心里对她默念了很多遍“我不会再来打扰你了”，离开的时候你依然会忍不住回头去再看一眼——然后发现她已经走了。
-
-然后你们的关系稳定在每年三次对话，分别是双方的生日和新年。
-
-再然后是毕业典礼，这次毕业典礼居然是在录取结果出来前办的。13、14 级的毕业典礼我都去看过，13 级毕业典礼是初三毕业参加夏令营的时候学校组织去的，那一年巴蜀考上清北的人数多年以来第一次掉下了重庆第一，毕业典礼上宣传高考成绩的 PPT 上的用词被迫从“全市第一”改成了“全市领先”，在喜庆的毕业氛围里我总觉得我还是感受到了校领导的咬牙切齿。14 级毕业典礼是暑假在学校学竞赛时被强行拉去的，一个环节是先让高三毕业生站起来，再让初三毕业来参加夏令营的学生站起来，而我们不管哪一次都不符合需要站起来的标准，看上去长得也不像家长，因此坐在我们周围的高三前辈们投来了困惑的目光。15 级毕业典礼没有门票不让进所以没去成，那时我们高二，看着学长学姐穿着礼服浓妆艳抹欢乐的走红毯，觉得离毕业还很遥远。我们这届的毕业典礼干了什么我基本都忘了，只记得我帮一堆没来的人拿了毕业证和毕业照，班主任在知道我这个吊车尾能去同济之后露出了欣慰的表情，巴蜀在录取结果没出的情况下依然能完美的大吹特吹。
-
-大概就是这样吧。
-
----
-
-这一版读起来，其实还是很悲催啊 (╯‵□′)╯︵╘═╛
-
-P.S. 这个掀桌的表情真的好萌
Index: blog/posts/2021-08-31-attention-conv.md
===================================================================
diff --git a/blog/posts/2021-08-31-attention-conv.md b/blog/posts/2021-08-31-attention-conv.md
deleted file mode 100644
--- a/blog/posts/2021-08-31-attention-conv.md	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
+++ /dev/null	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
@@ -1,264 +0,0 @@
----
-layout: Post
-title: Attention / Conv 大锅烩
-subtitle: Self-Attentions and Convolutions
-author: Renovamen
-date: 2021-08-31
-headerImage: /img/in-post/2021-08-31/header.jpg
-permalinkPattern: /post/:year/:month/:day/:slug/
-tags:
-  - Deep Learning
----
-
-长期记录和实现看过的各种论文里的自注意力和卷积机制，咕咕咕，实现地址在：[<v-icon name="ri-link-m" scale="0.9"/> Github](https://github.com/Renovamen/torchop)
-
-<!-- more -->
-
-
-提前定义，$F \in \Reals^{N \times d}$ 是一个特征，在文本任务里，$N$ 是文本长度，$d$ 是词向量维度；在视觉任务里，$N$ 是特征图的 $W \times H$，$d$ 是通道数量。
-
-
-## Attention
-
-### Self-Attenion
-
-**Attention Is All You Need.** *Ashish Vaswani, et al.* NIPS 2017. [[Paper]](https://arxiv.org/abs/1706.03762) [[Code]](https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/models/transformer.py)
-
-<img src="/img/in-post/2021-08-31/self-attention.png" width="300px" alt="self-attention" />
-
-<p class="desc">图片来源：论文 <a href="https://arxiv.org/pdf/2105.02358.pdf" target="_blank">Beyond Self-attention: External Attention using Two Linear Layers for Visual Tasks</a></p>
-
-$Q, V, K$ 由同一个值 $F \in \Reals^{N \times d}$ 经过线性变换得到，然后 attention map 和 context 的计算公式为：
-
-$$
-\begin{gathered}
-  A = \text{softmax}(\frac{QK^T}{\sqrt{d_k}}) \\
-  F_{\text{out}} = A V
-\end{gathered}
-$$
-
-其中 $d_k = d / h$ 是一个注意力头的维度，$h$ 是注意力头的数量。除以 $\sqrt{d_k}$ 是因为，$d_k$ 越大 $QK^T$ 就会越大，可能就会将 softmax 函数推入梯度极小的区域，导致更新缓慢，所以要用 $\sqrt{d_k}$ 对 $QK^T$ 进行缩放。
-
-最后 $F_{\text{out}}$ 会经过线性层、残差连接和 Layer Normalization。
-
-一个简化版本是，把线性变换扔掉，直接用 $F$ 计算 attention，即 $Q = K = V = F$，从而省掉那三个线性层的计算量：
-
-<img src="/img/in-post/2021-08-31/simplified-self-attention.png" width="300px" alt="simplified-self-attention" />
-
-<p class="desc">图片来源：论文 <a href="https://arxiv.org/pdf/2105.02358.pdf" target="_blank">Beyond Self-attention: External Attention using Two Linear Layers for Visual Tasks</a></p>
-
-$$
-\begin{gathered}
-  A = \text{softmax}(\frac{FF^T}{\sqrt{d_k}}) \\
-  F_{\text{out}} = A F
-\end{gathered}
-$$
-
-Self Attention 是在计算任意两个位置之间的相关性，得到一个 $N \times N$ 的 attention map，所以计算复杂度是 $O(d N^2)$（“简化版本”也是这样），这是一个很高的计算开销。所以 Bert 的最大长度只有 $N = 512$。而对于视觉任务来说，$N = W \times H$，所以特征图也不能太大，一般 $W$ 和 $H$ 都需要先被降到 10+ 的数量级。
-
-
-### SAGAN
-
-**Self-Attention Generative Adversarial Networks.** *Han Zhang, et al.* ICML 2019. [[Paper]](https://arxiv.org/abs/1805.08318) [[Code]](https://github.com/brain-research/self-attention-gan)
-
-SAGAN 是一个用 self-attention 来替代了卷积层的 GAN，它的 self-attention 跟原始 transformer 的 self-attention 的不同在于：
-
-- 在将 $F$ 通过线性变换得到 $Q$ 和 $K$ 时，进行了降维（$d \to d / 8$）
-- 在残差连接之前，对 $F_{\text{out}}$ 进行了缩放：$\gamma F_{\text{out}}$，其中 $\gamma$ 是一个可学习的参数
-
-
-### External Attention
-
-**Beyond Self-attention: External Attention using Two Linear Layers for Visual Tasks.** *Han Zhang, et al.* arXiv 2021. [[Paper]](https://arxiv.org/abs/2105.02358) [[Code]](https://github.com/MenghaoGuo/EANet)
-
-![external-attention](/img/in-post/2021-08-31/external-attention.png)
-
-<p class="desc">图片来源：论文 <a href="https://arxiv.org/pdf/2105.02358.pdf" target="_blank">Beyond Self-attention: External Attention using Two Linear Layers for Visual Tasks</a></p>
-
-
-External Attention 主要考虑了以下问题：
-
-- 原始 self attention 会计算任意两个位置（pixel）之间的相关性，计算量太大。但实际上，attention map 是很稀疏的，只有很少量的 pixel 之间有关联，所以没有必要用 $N \times N$ 的 attention map
-- 原始 self attention 只考虑了同一个样本中不同 pixel 之间的关系，但没有考虑不同样本间的关联
-
-因此 External Attention 提出用 external memory unit $M_k$ 和 $M_v$（都是可学习的参数）来代替 $K$ 和 $V$：
-
-$$
-\begin{gathered}
-  A = \text{Norm}(Q M_k^T) \\
-  F_{\text{out}} = A M_v
-\end{gathered}
-$$
-
-其中 $M \in \Reals^{S \times d}$，$S$ 是一个超参。
-
-对于第一个问题，$O(d N^2)$ 的复杂度来源于 $Q, K, V$ 的矩阵相乘，而这里 $K, V$ 的维度从 $N \times d$ 变成了 $S \times d$，因此复杂度变为了 $O(d S N)$，与 $N$ 线性相关。因为 $S$ 可以取得远远小于 $N$（在论文的实验中，$S = 64$ 的时候效果就已经很好了），所以计算复杂度可以降低很多。
-
-对于第二个问题，可以认为 external memory unit 学习到了整个数据集的信息，因此考虑了不同样本间的关联。
-
-式 $(1)$ 中的 $\text{Norm}(\cdot)$ 是 double-normalization 操作。Softmax 只会对一个维度进行归一化，但 attention map 对于输入特征的 scale 比较敏感，所以 double-normalization 在 softmax 之后对另一个维度也进行了归一化：
-
-$$
-\begin{gathered}
-  \tilde{a} = Q M_k^T \\
-  \hat{a}_{ij} = \underbrace{\frac{\text{exp} (\tilde{a}_{ij})}{\sum_k \text{exp} (\tilde{a}_{\textcolor{red}{k}j})}}_{\text{Softmax}} \\
-  a_{ij} = \frac{\hat{a}_{ij}}{\sum_k \hat{a}_{i\textcolor{red}{k}}}
-\end{gathered}
-$$
-
-### Fastformer
-
-**Fastformer: Additive Attention Can Be All You Need.** *Chuhan Wu, et al.* arXiv 2021. [[Paper]](https://arxiv.org/abs/2108.09084) [[Code]](https://github.com/wuch15/Fastformer)
-
-又是『XXX is all you need』系列的题目，让人审美疲劳。虽然这个题目包含了它应该包含的信息：“比原始 Transformer 快，因为我们用了 additive attention”，但还是让人审美疲劳。
-
-<img src="/img/in-post/2021-08-31/fastformer.png" width="500px" alt="fastformer" />
-
-<p class="desc">图片来源：论文 <a href="https://arxiv.org/pdf/2108.09084.pdf" target="_blank">Fastformer: Additive Attention Can Be All You Need</a></p>
-
-同样是想解决 $N \times N$ 的稀疏 attention map 带来的高计算量的问题。它的处理方式是先用 additive attention 把 $Q$ 融合成了一个 global query vector $Q_\text{global} \in \Reals^d$：
-
-$$
-\begin{gathered}
-  A_q = \text{softmax}(\frac{Q W_q^T}{\sqrt{d_k}}) \\
-  Q_\text{global} = A_q Q
-\end{gathered}
-$$
-
-其中 $W_q^T \in \Reals^d$（这里直接把 $N$ 维降到了 1 维）。然后用 $K$ 和 $Q_\text{global}$ 矩阵 **element-wise 相乘**，乘完之后再用和上面一样的 additive attention 得到一个向量 $K_\text{global} \in \Reals^d$：
-
-$$
-\begin{gathered}
-  \overline{K} = K \odot Q_\text{global} \\
-  A_k = \text{softmax}(\frac{(\overline{K} W_k^T}{\sqrt{d_k}}) \\
-  K_\text{global} = A_q \overline{K}
-\end{gathered}
-$$
-
-最后用 $K_\text{global}$ 和 $V$ 矩阵相乘，得到最终的输出：
-
-$$
-F_{\text{out}} = K_\text{global} V
-$$
-
-因为有 additive attention 这个降维操作，所以上面每一个矩阵乘法的复杂度都是 $Q(Nd)$，element-wise 乘法的复杂度也是 $Q(Nd)$，所以总的时间复杂度是线性的 $O(Nd)$。
-
-
-### HaloNets
-
-**Scaling Local Self-Attention for Parameter Efficient Visual Backbones.** *Ashish Vaswani, et al.* CVPR 2019. [[Paper]](https://arxiv.org/abs/2103.12731)
-
-![halo](/img/in-post/2021-08-31/halo.png)
-
-<p class="desc">图片来源：论文 <a href="https://arxiv.org/pdf/2103.12731.pdf" target="_blank">Scaling Local Self-Attention for Parameter Efficient Visual Backbones</a></p>
-
-用 self-attention 来做类似于卷积的操作，心路历程是：
-
-- 如果用全局 self-attention，计算量太大；如果用卷积中的滑动窗口，在每个窗口里做 local self-attention，由于每个窗口的结果都要一直存在显存里没法释放，容易造成显存溢出
-- 但卷积中，两个相邻的滑动窗口中的大部分元素都是一样的，为了减少这部分重复的计算量，论文直接将输入的特征图分成了不重复的一些 block（上图中的 blocked image），然后在每个 block 里做 local self-attention，所以论文管这个操作叫 blocked local self-attention
-- 但只在 block 里做 self-attention 也是不合适的，周边共享的元素多少也要考虑一些，因此论文在每个窗口边上都 pad 了一圈（上图中的 neighborhood windows 周边那圈五颜六色的东西），以增加感受野。因为 pad 的这一圈看上去很像光环，所以论文管这个操作叫 haloing
-
-
-### Linformer
-
-**Linformer: Self-Attention with Linear Complexity.** *Sinong Wang, et al.* arXiv 2020. [[Paper]](https://arxiv.org/abs/2006.04768)
-
-<img src="/img/in-post/2021-08-31/linformer.png" width="250px" alt="linformer" />
-
-<p class="desc">图片来源：论文 <a href="https://arxiv.org/pdf/2006.04768.pdf" target="_blank">Linformer: Self-Attention with Linear Complexity</a></p>
-
-从实现上来看，和原始 Transformer 的区别就是，对 $K, V$ 用 $E, F \in \Reals^{N \times k}$ 进行了降维（上图中的 Projection），即：
-
-$$
-F_{\text{out}} = \underbrace{\text{softmax} \left ( \frac{Q (E K)^T}{\sqrt{d_k}} \right)}_{\overline{P}: N \times k} \cdot \underbrace{F V}_{k \times d}
-$$
-
-$k$ 是一个超参常数，所以时间复杂度降到 $Q(Nkd)$。同时它还使用了一些参数共享的 trick 来进一步降低计算量。
-
-但论文还证明了为什么可以用 $\overline{P}$ 来近似原始的 attention map $P$（虽然我觉得略显强行）。原文的 Theorem 2 先证明了当 $k = 5 \log(nd) / (\epsilon^2 - \epsilon^3)$ 时，一定存在 $E, F$ 使得 $\overline{P}$ 可以近似 $P$。这里 $k$ 的取值与 $n$ 有关，复杂度还不是线性。但如果考虑到 $\text{rank}(A) = d$ 这一点（我还没搞明白这一点是怎么来的），$k$ 的选择就可以独立于 $n$，从而变为线性复杂度。
-
-
-
-## Convolution
-
-### Selective Kernel
-
-**Selective Kernel Networks.** *Xiang Li, et al.* CVPR 2019. [[Paper]](https://arxiv.org/abs/1903.06586) [[Code]](https://github.com/implus/SKNet)
-
-希望能够自适应地调整感受野的大小，为了做到这一点，论文采取的方式是用多个大小不同的卷积核生成特征图，然后把这些特征图融合在一起。
-
-![selective kernel](/img/in-post/2021-08-31/sk.png)
-
-<p class="desc">图片来源：论文 <a href="https://arxiv.org/pdf/1903.06586.pdf" target="_blank">Selective Kernel Networks</a></p>
-
-- Split：用 $M$ 个大小不同的卷积核生成特征图，上图中举的是 $3 \times 3$ 和 $5 \times 5$ 两个卷积核的例子
-- Fuse：把不同卷积核生成的特征图相加，然后经过平均池化 $\to$ 全连接 $\to$ Batch Norm $\to$ ReLU，得到一个特征向量 $z \in \Reals^d$，其中 $d = \max (C / r, L)$，$r, L$ 都是超参，用于控制通道维度
-- Select：用 $z$ 来计算一个 attention map，然后把 $M$ 个特征图加权求和，得到最终的输出
-
-
-
-
-### Squeeze-and-Excitation
-
-**Squeeze-and-Excitation Networks.** *Jie Hu, et al.* CVPR 2018. [[Paper]](https://arxiv.org/abs/1709.01507) [[Code]](https://github.com/hujie-frank/SENet)
-
-赋予不同通道不同的权重，这样就可以加强重要的通道特征。
-
-![squeeze and excitation](/img/in-post/2021-08-31/se.png)
-
-<p class="desc">图片来源：论文 <a href="https://arxiv.org/pdf/1709.01507.pdf" target="_blank">Squeeze-and-Excitation Networks</a></p>
-
-通道权重的计算方式是：
-
-- Squeeze：先把卷积出的特征图 $u \in \Reals^{H \times W \times C}$ 平均池化成一个向量 $z \in \Reals^C$，这一步抽离了空间上的信息，这样后面就可以只关注通道之间的关系
-- Excitation：$z$ 只能体现在当前 batch 上计算出来的通道关系，所以论文加了两个全连接层来利用整个数据集的信息：
-
-  $$
-  s = \sigma (W_2 \delta(W_1 z))
-  $$
-
-  其中 $\delta$ 是 ReLU 激活函数，$W_2$ 和 $W_1$ 是两个全连接层，$s \in \Reals^C$ 是最终各个通道的权重
-  
-最后把特征图 $u$ 跟权重 $s$ 相乘就行。
-
-
-### Involution
-
-**Involution: Inverting the Inherence of Convolution for Visual Recognition.** *Duo Li, et al.* CVPR 2021. [[Paper]](https://arxiv.org/abs/2103.06255) [[Code]](https://github.com/d-li14/involution)
-
-普通的卷积有两个特点：空间不变（spatial-agnostic）（不同空间位置共享同一个卷积核）和通道特异（channel-specific）（不同通道对应不同的卷积核）。参数数量为 $C_i \times C_o \times K \times K$，其中 $C_i, C_o , K$ 分别为输入和输出通道数量，以及卷积核大小。
-
-而这篇论文认为：
-
-- 由于通道数量 $C_i, C_o$ 往往成百上千，所以为了限制参数量和计算量，$K$ 的取值往往较小，从而限制了感受野大小
-- 空间不变的特征可能会剥夺卷积核适应不同空间位置的能力
-- 卷积核在通道维度往往存在冗余，即很多卷积核是近似线性相关的。也就是说，如果把每个输出通道对应的卷积核铺成一个 $C_i \times K^2$ 大小的矩阵，那么矩阵的秩不会超过 $K^2$。所以缩减卷积核的通道维度可能并不会明显影响效果
-
-因此论文提出了一种跟卷积相反的 involution 操作：空间特异（不同空间位置对应不同的卷积核）和通道不变（不同通道共享同一个卷积核），参数数量为 $H \times W \times K \times K \times G$，$G$ 表示 $C_i$ 个输入通道分成 $G$ 组（每组 $C_i / G$ 个通道），每组通道共享同一个卷积核。
-
-<img src="/img/in-post/2021-08-31/involution.png" width="500px" alt="involution" />
-
-<p class="desc">图片来源：论文 <a href="https://arxiv.org/pdf/2103.06255.pdf" target="_blank">Involution: Inverting the Inherence of Convolution for Visual Recognition</a></p>
-
-和卷积不一样的是，involution 的核是根据输入的特征图自动生成的，一个通用的形式是：
-
-$$
-\mathcal{H}_{ij} = \phi(X_{\Psi_{ij}})
-$$
-
-其中 $\Psi_{ij}$ 表示坐标 $(i, j)$ 的某个邻域上的坐标集合，$X_{\Psi_{ij}}$ 表示 $\Psi_{ij}$ 对应的特征。在实例化这个形式时，论文用了比较简单的方式，即令 $\Psi_{ij} = \{(i, j)\}$ 这个单点，然后：
-
-$$
-\mathcal{H}_{ij} = \phi(X_{\{(i, j)\}}) = W_1 \sigma (W_0 X_{\{(i, j)\}})
-$$
-
-论文另一个挺有意思的地方是，它指出 self-attention 公式也可以用这个式子来表示，即：
-
-$$
-\begin{gathered}
-  \Psi_{ij} = \Omega \\
-  \mathcal{H}_{ij} = \phi(X_\Omega) = (X W^Q)(X W^K)^T
-\end{gathered}
-$$
-
-其中 $\Omega$ 是 query 对应的 key 的范围。
Index: blog/posts/2018-12-22-note-of-linear-algebra.md
===================================================================
diff --git a/blog/posts/2018-12-22-note-of-linear-algebra.md b/blog/posts/2018-12-22-note-of-linear-algebra.md
deleted file mode 100644
--- a/blog/posts/2018-12-22-note-of-linear-algebra.md	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
+++ /dev/null	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
@@ -1,827 +0,0 @@
----
-layout: Post
-title: "线性代数笔记"
-subtitle: 'Note of Linear Algebra'
-author: Renovamen
-date: 2018-12-22
-headerImage: /img/in-post/2018-12-22/header.jpg
-permalinkPattern: /post/:year/:month/:day/:slug/
-tags:
-  - Math
----
-
-MIT 18.06 / Stanford CS229 (Linear Algebra 部分)
-
-<!-- more -->
-
-## 1.矩阵乘法
-
-### 1.1 向量 x 向量
-
-1. 有向量 $x,y \in R^n$，$x^Ty$ 被称为**向量内积（Inner Product）**或**点积（Dot Product）**，结果为一个实数。 
-
-    $$
-    x^Ty \in R^n = 
-
-    \left[
-      \begin{matrix}
-        x_1 & x_2 & ... & x_n
-      \end{matrix}
-    \right]
-
-    \left[
-      \begin{matrix}
-        y_1  \\
-        y_2  \\
-        \vdots  \\
-        y_n
-      \end{matrix}
-    \right]
-
-    = \sum_{i=1}^n x_i y_i
-    $$
-
-    注：$x^Ty = y^Tx$ 始终成立。
-
-2. 有向量 $x \in R^n, y \in R^m$，$xy^T \in R^{m \times n}$ 被称为**向量外积（Outer Product）**，结果为一个矩阵，其中 $(xy^T)_{ij} = x_i y_i$。
-
-    $$
-    xy^T \in R^{m \times n} = 
-
-    \left[
-      \begin{matrix}
-        x_1  \\
-        x_2  \\
-        ...  \\
-        x_m
-      \end{matrix}
-    \right]
-
-    \left[
-      \begin{matrix}
-        y_1 & y_2 & ... & y_n
-      \end{matrix}
-    \right]
-
-    = 
-    
-    \left[
-      \begin{matrix}
-        x_1y_1 & x_1y_2 & \cdots & x_1y_n \\
-        x_2y_1 & x_2y_2 & \cdots & x_2y_n \\
-        \vdots & \vdots & \ddots & \vdots \\
-        x_my_1 & x_my_2 & \cdots & x_my_n
-      \end{matrix}
-    \right]
-    $$
-
-### 1.2 矩阵 x 向量
-
-有矩阵 $A \in R^{m \times n}$，向量 $x \in R^n$，它们的积是一个向量 $Ax \in R^m$。有两种理解矩阵与向量的乘法的方式：
-
-1. 行列内积
-
-    如果按行写 $A$，可以把 $Ax$ 表示为：
-
-    $$
-    y = Ax = 
-
-    \left[
-      \begin{matrix}
-        - & a_1^T  & - \\
-        - & a_2^T  & - \\
-          & \vdots & \\
-        - & a_m^T  & -
-      \end{matrix}
-    \right]x = 
-
-    \left[
-      \begin{matrix}
-        a_1^Tx \\
-        a_2^Tx \\
-        \vdots \\
-        a_m^Tx
-      \end{matrix}
-    \right]
-    $$
-
-    可以看出 $y$ 的第 $i$ 行是 $A$ 的第 $i$ 行和 $x$ 的内积，即 $y_i = a_i^T x$。
-
-2. 整列相乘
-
-    把 $A$ 按列表示：
-
-    $$
-    y = Ax = 
-
-    \left[
-      \begin{matrix}
-          | &   | &        &   | \\
-        a_1 & a_2 & \cdots & a_n \\
-          | &   | &        &   |
-      \end{matrix}
-    \right]
-
-    \left[
-      \begin{matrix}
-        x_1 \\
-        x_2 \\
-        \vdots \\
-        x_n
-      \end{matrix}
-    \right] = 
-
-    [ a^1 ] x_1 + [ a^2 ] x_2 + \cdots + [ a^n ] x_n
-    $$
-
-    可以看到，$y$ 是 $A$ 的列的线性组合，其中线性组合的系数由 $x$ 的元素给出。
-  
-也可以在左侧乘以行向量，写为 $y^T = x^T A$，其中 $A \in R^{m \times n}, x \in R^m, y \in R^n$。也有两种理解方式：
-
-1. 把 $A$ 按列表示：
-
-    $$
-    y^T = x^T A = 
-
-    x^T
-
-    \left[
-      \begin{matrix}
-          | &   | &        &   | \\
-        a_1 & a_2 & \cdots & a_n \\
-          | &   | &        &   |
-      \end{matrix}
-    \right]
-    
-    =
-
-    \left[
-      \begin{matrix}
-        x^T a^1 & x^T a^2 & \cdots & x^T a^n
-      \end{matrix}
-    \right]
-    $$
-
-    可以看出 $y^T$ 的第 $i$ 个元素为 $x$ 和 $A$ 的第 $i$ 列的内积。
-
-2. 整行相乘
-
-    把 $A$ 按行表示：
-
-    $$
-    y^T = x^T A = 
-
-    \left[
-      \begin{matrix}
-        x_1 & x_2 & \cdots & x_n
-      \end{matrix}
-    \right]
-
-    \left[
-      \begin{matrix}
-        - a_1^T - \\
-        - a_2^T - \\
-          \vdots \\
-        - a_m^T -
-      \end{matrix}
-    \right]
-    
-    = x_1 [- a_1^T -] + x_2 [- a_2^T -] + \cdots + x_n [- a_n^T -]
-    $$
-
-    可以看出 $y^T$ 是 $A$ 的行的线性组合，其中线性组合的系数由 $x$ 的元素给出。
-
-### 1.3 矩阵 x 矩阵
-
-两个矩阵相乘，其中 $A \in R^{m \times n}, B \in R^{n \times p}$（$A$ 的总列数必须与 $B$ 的总行数相等），则：
-
-$$ 
-C = AB \in R^{m \times p}
-$$
-
-其中 $C_{ij} = \text{row}_i \times \text{column}_j = \sum_{k=1}^n A_{ik}B_{kj}$。
-
-1. 行列内积
-
-    显然，$C_{ij}$ 等于 $A$ 的第 $i$ 行和 $B$ 的第 $j$ 列的内积：
-
-    $$
-    C = AB = 
-
-    \left[
-      \begin{matrix}
-        - & a_1^T  & - \\
-        - & a_2^T  & - \\
-          & \vdots & \\
-        - & a_m^T  & -
-      \end{matrix}
-    \right]
-    
-    \left[
-      \begin{matrix}
-          | &   | &        &   | \\
-        b_1 & b_2 & \cdots & b_p \\
-          | &   | &        &   |
-      \end{matrix}
-    \right]
-    
-    = 
-
-    \left[
-      \begin{matrix}
-        a_1^Tb_1 & a_1^Tb_2 & \cdots & a_1^Tb_p \\
-        a_2^Tb_1 & a_2^Tb_2 & \cdots & a_2^Tb_p \\
-          \vdots &   \vdots & \ddots &   \vdots \\
-        a_m^Tb_1 & a_m^Tb_2 & \cdots & a_m^Tb_p
-      \end{matrix}
-    \right]
-
-    $$
-
-
-2. 列乘以行
-
-    用列表示 $A$，用行表示 $B$，这时 $C_{ij}$ 等于 $A$ 的第 $i$ 列和 $B$ 的第 $j$ 行的外积的和：
-
-    $$
-    C = AB = 
-
-    \left[
-      \begin{matrix}
-          | &   | &        &   | \\
-        a_1 & a_2 & \cdots & a_n \\
-          | &   | &        &   |
-      \end{matrix}
-    \right]
-
-    \left[
-      \begin{matrix}
-        - & b_1^T  & - \\
-        - & b_2^T  & - \\
-          & \vdots & \\
-        - & b_n^T  & -
-      \end{matrix}
-    \right]
-    
-    = 
-
-    \sum_{i=1}^n a_ib_i^T
-    $$
-
-    这种情况下，$a_i \in R^m$，$b_i \in R^p$，外积 $a_ib_i^T$ 的维度是 $m \times p$，与 $C$ 的维度一致。
-
-    如：
-
-    $$
-    \left[
-      \begin{matrix}
-        2 & 7 \\
-        3 & 8 \\
-        4 & 9
-      \end{matrix}
-    \right]
-
-    \left[
-      \begin{matrix}
-        1 & 6 \\
-        0 & 0
-      \end{matrix}
-    \right]
-
-    =
-
-    \left[
-      \begin{matrix}
-        2 \\
-        3 \\
-        4
-      \end{matrix}
-    \right]
-
-    \left[
-      \begin{matrix}
-        1 & 6
-      \end{matrix}
-    \right]
-
-    +
-
-    \left[
-      \begin{matrix}
-        7 \\
-        8 \\
-        9
-      \end{matrix}
-    \right]
-
-    \left[
-      \begin{matrix}
-        0 & 0
-      \end{matrix}
-    \right]
-
-    = 
-
-    \left[
-      \begin{matrix}
-        2 & 12 \\
-        3 & 18 \\
-        4 & 24
-      \end{matrix}
-    \right]
-    $$
-
-    每一次都是用列向量与行向量相乘得到一个矩阵，每次得到的矩阵都有特点。如：
-
-    $$
-    \begin{bmatrix}
-      2 \\
-      3 \\
-      4
-    \end{bmatrix}
-
-    \begin{bmatrix}
-      1 & 6
-    \end{bmatrix}
-    =
-    \begin{bmatrix}
-      2 & 12 \\
-      3 & 18 \\
-      4 & 24
-    \end{bmatrix}
-    $$
-    
-    矩阵
-    $\begin{bmatrix} 
-      2 & 12 \\ 
-      3 & 18 \\ 
-      4 & 24 
-    \end{bmatrix}$
-    每一列都和向量
-    $\begin{bmatrix} 
-      2 \\ 
-      3 \\ 
-      4 
-    \end{bmatrix}$
-    同向，即列向量都在
-    $\begin{bmatrix}
-      2 \\ 
-      3 \\ 
-      4 
-    \end{bmatrix}$
-    这条直线上，列空间是一条直线。同理，行向量都在
-    $\begin{bmatrix}
-      1 & 6
-    \end{bmatrix}$
-    这条直线上，行空间（矩阵行所有可能的线性组合）是一条直线。
-
-
-3. 整列相乘
-
-    把 $B$ 用列表示，则可以将 $C$ 的列视为 $A$ 与 $B$ 的列的矩阵向量积（1.2 节）：
-
-    $$
-    C = AB = A
-
-    \left[
-      \begin{matrix}
-          | &   | &        &   | \\
-        b_1 & b_2 & \cdots & b_p \\
-          | &   | &        &   |
-      \end{matrix}
-    \right]
-
-    =
-
-    \left[
-      \begin{matrix}
-          | &   | &        &   | \\
-        Ab_1 & Ab_2 & \cdots & Ab_p \\
-          | &   | &        &   |
-      \end{matrix}
-    \right]
-    $$
-
-    $c_j = Ab_j$，可以看做 $C$ 的第 $j$ 列是 $A$ 的列向量以 $B$ 的第 $j$ 列作为系数所求得的线性组合。
-
-
-4. 整行相乘
-
-    把 $A$ 用行表示，则可以将 $C$ 的行视为 $A$ 与 $B$ 的列的矩阵向量积（1.2 节）：
-
-    $$
-    C = AB =
-
-    \left[
-      \begin{matrix}
-        - & a_1^T  & - \\
-        - & a_2^T  & - \\
-          & \vdots &   \\
-        - & a_m^T  & -
-      \end{matrix}
-    \right] B = 
-
-    \left[
-      \begin{matrix}
-        - & a_1^TB & - \\
-        - & a_2^TB & - \\
-          & \vdots &   \\
-        - & a_m^TB & -
-      \end{matrix}
-    \right]
-    $$
-
-    $c_i^T = a_i^Tb$，可以看做 $C$ 的第 $i$ 行是 $B$ 的行向量以 $A$ 的第 $i$ 行作为系数所求得的线性组合。
-
-5. 分块乘法
-
-    $$
-    \left[
-      \begin{array}{c|c}
-               A_1 & A_2 \\
-        \hline A_3 & A_4
-      \end{array}
-    \right]
-    
-    \left[
-      \begin{array}{c|c}
-               B_1 & B_2 \\
-        \hline B_3 & B_4
-      \end{array}
-    \right]
-    
-    =
-    
-    \left[
-      \begin{array}{c|c}
-               A_1B_1+A_2B_3 & A_1B_2+A_2B_4 \\
-        \hline A_3B_1+A_4B_3 & A_3B_2+A_4B_4
-      \end{array}
-    \right]
-    $$
-
-    在分块合适的情况下，可以简化运算。
-
-
-## 2.矩阵消元
-
-### 2.1 消元法
-
-三元方程组 
-$\begin{cases}
-  x& + 2y& + z& = 2 \\
-  3x& + 8y& + z& = 12 \\
-  &4y& + z& = 2
-\end{cases}$
-对应的矩阵形式 $Ax=b$ 为：
-
-$$
-\begin{bmatrix}
-  1 & 2 & 1 \\
-  3 & 8 & 1 \\
-  0 & 4 & 1
-\end{bmatrix}
-\begin{bmatrix}
-  x \\
-  y \\
-  z
-\end{bmatrix}
-=
-\begin{bmatrix}
-  2 \\
-  12 \\
-  2
-\end{bmatrix}
-$$
-
-
-**消元**（$[A \| b]$ 为方程组的**增广矩阵**形式）：
-
-$$
-[A \mid b] = 
-
-\left[
-  \begin{array}{c c c |c}
-    \underline{1} & 2 & 1 & 2 \\
-    3             & 8 & 1 & 12 \\
-    0             & 4 & 1 & 2
-  \end{array}
-\right]
-\underrightarrow{r_2 - 3r_1}
-
-\left[
-  \begin{array}{c c c |c}
-    \underline{1} & 2             & 1  & 2 \\
-    0             & \underline{2} & -2 & 6 \\
-    0             & 4             & 1  & 2
-  \end{array}
-\right]
-
-\underrightarrow{r_3 - 2r_2}
-\left[
-  \begin{array}{c c c |c}
-    \underline{1} & 2             & 1             & 2 \\
-    0             & \underline{2} & -2            & 6 \\
-    0             & 0             & \underline{5} & -10
-  \end{array}
-\right]
-$$
-
-下划线的元素为**主元**，主元不能为零。如果在消元时遇到主元位置为零，则需要看它的后面的行对应位置是否为 0，如果不为 0，就交换这两行，将非零数视为主元。
-
-消元失效：如果它后面所有行的对应位置都为 0，则该矩阵**不可逆**，消元法求出的解不唯一。（如：把第三个方程 $z$ 前的系数成 -4，会导致第二步消元时最后一行全部为零，则第三个主元就不存在了，消元就不能继续进行了。）
-
-消元后方程组变为 
-$\begin{cases}
-   x  & +2y & +z  & = 2 \\
-      &  2y & -2z & = 6 \\
-      &     &  5z & = -10
-\end{cases}$
-
-从第三个方程求出 $z=-2$，代入第二个方程求出 $y=1$，再代入第一个方程求出 $x=2$。
-
-### 2.1 消元矩阵
-
-
-
-
-## 8.求解 Ax = b：可解性和解的结构
-
-### 8.1 Ax = b 的解
-
-举例，同上一讲：有 $3 \times 4$ 矩阵 $A$： 
-
-$$
-A=
-\left[
-  \begin{matrix}
-    1 & 2 & 2 & 2\\
-    2 & 4 & 6 & 8\\
-    3 & 6 & 8 & 10
-  \end{matrix}
-\right]
-$$
-
-求 $Ax=b$ 的特解：
-
-写出其增广矩阵（augmented matrix）$[A \mid b]$：
-
-$$
-\left[
-\begin{array}{c c c c|c}
-1 & 2 & 2 & 2 & b_1 \\
-2 & 4 & 6 & 8 & b_2 \\
-3 & 6 & 8 & 10 & b_3
-\end{array}
-\right]
-\underrightarrow{\text{消元}}
-\left[
-\begin{array}{c c c c|c}
-1 & 2 & 2 & 2 & b_1 \\
-0 & 0 & 2 & 4 & b_2-2b_1 \\
-0 & 0 & 0 & 0 & b_3-b_2-b_1
-\end{array}
-\right]
-$$
-
-显然，有解的必要条件为 $b_3-b_2-b_1=0$。
-
-#### 8.1.1 Ax = b 可解性
-
-讨论 $b$ 满足什么条件才能让方程 $Ax=b$ 有解（solvability condition on $b$）：
-
-1. 从列空间看：当且仅当 $b$ 属于 $A$ 的列空间时；
-2. 如果 $A$ 的各行线性组合得到 0 行，则 $b$ 端分量做同样的线性组合，结果也为 0 时，方程才有解。
-
-#### 8.1.2 Ax = b 的解结构
-
-1. 特解
-
-    解法：令所有自由变量取 0，则有
-    $\Big\lbrace
-    \begin{aligned}
-      x_1 + 2x_3 & = 1 \\
-      2x_3 & = 3
-    \end{aligned}$
-    ，解得
-    $\Big\lbrace
-    \begin{aligned}
-      x_1 & = -2 \\
-      x_3 & = \frac{3}{2}
-    \end{aligned}$
-   
-    代入 $Ax=b$ 求得特解： 
-    $x_p=
-    \begin{bmatrix}-2 \\ 
-      0 \\ 
-      \frac{3}{2} \\ 
-      0
-    \end{bmatrix}$
-
-2. 通解
-
-    令 $Ax=b$ 成立的所有解：
-    $\Big\lbrace
-    \begin{aligned}
-      A x_p & = b \\
-      A x_n & = 0
-    \end{aligned}
-    \quad
-      \rightarrow{}
-    \quad
-    A(x_p+x_n)=b$
-
-    即 $Ax=b$ 的解集为其特解加上零空间。对本例有：
-
-    $$
-    x_{\text{complete}}=
-    \begin{bmatrix}-2 \\ 
-      0 \\ 
-      \frac{3}{2} \\ 
-      0
-    \end{bmatrix}
-    +c_1
-    \begin{bmatrix}
-      -2\\
-      1\\
-      0\\
-      0
-    \end{bmatrix}
-    +c_2
-    \begin{bmatrix}
-      2\\
-      0\\
-      -2\\
-      1
-    \end{bmatrix}
-    $$
-
-### 8.2 秩 r 与 Ax = b 的解关系
-
-对于 $m \times n$ 矩阵 $A$，有矩阵 $A$ 的秩 $r \leq \min(m, n)$。
-
-#### 8.2.1 列满秩
-
-主元变量为 $n$，没有自由变量。因为没有自由变量可以赋值，所以列的线性组合得不到 0（因为如果存在非零 $x$ 使 $Ax=0$ 成立，那么 $A$ 中有一列是没有贡献的，既然没有贡献，那么也就不存在列满秩的情况了）。
-
-所以列满秩的解的情况：0 或 1 个特解。
-
-举例：
-
-列满秩 $r=n$ 情况：
-
-$$
-A=
-\begin{bmatrix}
-  1 & 3 \\
-  2 & 1 \\
-  6 & 1 \\
-  5 & 1
-\end{bmatrix}
-,
-R=
-\begin{bmatrix}
-  1 & 0 \\
-  0 & 1 \\
-  0 & 0 \\
-  0 & 0
-\end{bmatrix}
-$$
-
-$\text{rank}(A)=2$，要使 $Ax=b, b \neq 0$ 有非零解，$b$ 必须取 $A$ 中各列的线性组合，此时 $A$ 的零空间中只有 $0$ 向量。
-
-**P.S.** 因为行向量是 2 维的，且前两行线性无关，2 维平面中有两个向量线性无关，那该平面的所有向量都可以由这两个向量线性组合得到，所以后面两行一定会是 0 行。
-
-#### 8.2.2 行满秩
-
-每行都有主元，不存在 0 行，那么 $b$ 就没有要求，而且有 $n-r$ 个自由变量，所以解有无穷多个。
-
-举例：
-
-行满秩 $r=m$ 情况：
-
-$$
-A=
-\begin{bmatrix}
-  1 & 2 & 6 & 5 \\
-  3 & 1 & 1 & 1
-\end{bmatrix},
-
-R=
-\begin{bmatrix}
-  1 & 0 & - & - \\
-  0 & 1 & - & -
-\end{bmatrix}
-$$
-
-$\text{rank}(A)=2$，$\forall b \in R^m$ 都有 $x \neq 0$ 的解，因为此时 $A$ 的列空间为 $R^m$，$b \in R^m$ 恒成立，组成 $A$ 的零空间的自由变量有 $n-r$ 个。
-
-
-#### 8.2.3 行列满秩
-
-代表的是满秩方阵，消元到最简形式是单位矩阵，是一个可逆矩阵，结合 $r=m$ 和 $r=n$ 的解的情况得出此时一定有一个解 $b$，$b$ 满足是 $A$ 向量的线性组合。
-
-举例：
-
-行列满秩情况：$r=m=n$，如：
-
-$$
-A=
-\begin{bmatrix}
-  1 & 2 \\
-  3 & 4
-\end{bmatrix}
-$$
-
-则 $A$ 最终可以化简为 $R=I$，其零空间只包含 $0$ 向量。
-
-
-#### 8.2.4 总结
-
-$$
-\begin{array}{c|c|c|c}
-  r=m=n & r=n<m & r=m<n & r<m,r<n \\
-
-  R=I & R=\begin{bmatrix}I\\0\end{bmatrix} & R=\begin{bmatrix}I&F\end{bmatrix} & R=\begin{bmatrix}I&F\\0&0\end{bmatrix} \\
-  
-  \text{1 solution} & \text{0 or 1 solution} & \infty \text{ solution} & \text{0 or } \infty \text{ solution}
-\end{array}
-$$
-
-
-
-## 9. 线性相关性、基、维数
-
-### 9.1 线性相关性
-
-$v_1,\ v_2,\ \cdots,\ v_n$ 是 $m \times n$ 矩阵 $A$ 的列向量：
-
-- 如果 $A$ 零空间中有且仅有 $0$ 向量，则各向量线性无关，$\text{rank}(A)=n$。
-
-- 如果存在非零向量 $c$ 使得 $Ac=0$，则存在线性相关向量，$\text{rank}(A)\lt n$。
-
-
-### 9.2 基
-
-向量空间 $S$ 中的一组基（basis），具有两个性质：
-
-1. 他们线性无关；
-2. 他们可以生成 $S$。
-
-对于向量空间 $R^n$，如果 $n$ 个向量组成的矩阵为可逆矩阵，则这 $n$ 个向量为该空间的一组基，而数字 $n$ 就是该空间的维数（dimension）。
-
-
-### 9.3 维数
-
-举例：
-
-$$
-A=
-\begin{bmatrix}
-  1 & 2 & 3 & 1 \\
-  1 & 1 & 2 & 1 \\
-  1 & 2 & 3 & 1
-\end{bmatrix}
-$$
-
-$A$ 的列向量线性相关，其零空间中有非零向量，所以：
-
-$$
-\text{rank}(A)=2=\text{主元存在的列数}=\text{列空间维数}
-$$
-
-可以很容易的求得 $Ax=0$ 的两个解，如：
-
-$$
-x_1=
-\begin{bmatrix}-1 \\
-  -1 \\
-  1 \\
-  0
-\end{bmatrix},
-x_2=
-\begin{bmatrix}
-  -1 \\
-  0 \\
-  0 \\
-  1
-\end{bmatrix}
-$$
-
-根据前几讲，我们知道特解的个数就是自由变量的个数，所以：
-
-$$
-n-\text{rank}(A) = 2 = \text{自由变量存在的列数} = \text{零空间维数}
-$$
-
-可以得到：列空间维数 $\dim C(A)=\text{rank}(A)$，零空间维数 $\dim N(A)=n-\text{rank}(A)$。
-
-## 参考
-
-1. [MIT - 18.06 Linear Algebra](http://open.163.com/special/opencourse/daishu.html)
-
-2. [Stanford - CS229 Machine Learning (Linear Algebra)](http://cs229.stanford.edu/summer2019/cs229-linalg.pdf)
-
-3. [Github - zlotus/notes-linear-algebra](https://github.com/zlotus/notes-linear-algebra)
-
-4. [Github - apachecn/18.06-linalg-notes](https://github.com/apachecn/18.06-linalg-notes)
Index: blog/posts/2021-07-28-natural-gradient.md
===================================================================
diff --git a/blog/posts/2021-07-28-natural-gradient.md b/blog/posts/2021-07-28-natural-gradient.md
deleted file mode 100644
--- a/blog/posts/2021-07-28-natural-gradient.md	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
+++ /dev/null	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
@@ -1,248 +0,0 @@
----
-layout: Post
-title: 自然梯度下降
-subtitle: Natural Gradient Decent
-author: Renovamen
-date: 2021-07-28
-headerImage: /img/in-post/2021-07-28/header.jpeg
-permalinkPattern: /post/:year/:month/:day/:slug/
-tags:
-  - Machine Learning
----
-
-自然梯度下降（Natural Gradient Decent）把参数看成一种概率分布，然后使用 KL 散度而不是欧氏距离来作为距离的度量，从而更好地描述更新后的分布和原分布有多大的不同。
-
-<!-- more -->
-
-
-## 基础
-
-### 梯度下降
-
-假设有 $\theta \in R^n$，$f(\theta)$ 是具有一阶连续偏导数的函数，现在要求解无约束最优化问题：
-
-$$
-\min_\theta f(\theta)
-$$
-
-**梯度下降法**（Gradient Decent）是一种迭代算法。它先取一个适当的初值，然后不断迭代，更新 $\theta$ 的值，极小化目标函数，直到收敛。第 $k+1$ 次迭代的公式为：
-
-$$
-\theta^{(k+1)} = \theta^{(k)} + \eta \vec{v}
-$$
-
-其中 $\eta$ 表示步长，$\vec{v}$ 表示更新方向。将损失函数 $L(\theta^{(k+1)})$ 在 $\theta^{(k)}$ 处[泰勒展开](/post/2020/08/24/regularization-based-continual-learning/#泰勒展开)：
-
-$$
-\begin{aligned}
-  L(\theta^{(k+1)}) &= L(\theta^{(k)}) + \nabla L(\theta^{(k)}) \cdot (\theta^{(k+1)} - \theta^{(k)}) \textcolor{blue}{+ o(\theta^{(k)})} \quad \text{(泰勒展开)}\\
-    &= L(\theta^{(k)}) + \eta \vec{v} \cdot \nabla L(\theta^{(k)}) \textcolor{blue}{+ o(\theta^{(k)})}\\
-    &\approx L(\theta^{(k)}) + \eta \vec{v} \cdot \nabla L(\theta^{(k)}) \quad (\text{忽略掉二阶及以上高阶项} \: \textcolor{blue}{o(\theta^{(k)})})
-\end{aligned}
-$$
-
-因为我们的目标是让损失函数的值不断变小，即：
-
-$$
-L(\theta^{(k+1)}) - L(\theta^{(k)}) = \eta \vec{v} \cdot \nabla L(\theta^{(k)}) < 0
-$$
-
-而 $\eta$ 是一个大于 0 的常量，所以要使上式成立，$\vec{v}$ 需要与 $\nabla L(\theta^{(k)})$ 的夹角 $\alpha$ 大于 $90^{\circ}$。又因为：
-
-$$
-\vec{v} \cdot \nabla L(\theta^{(k)}) = \| \vec{v} \| \cdot \| \nabla L(\theta^{(k)}) \| \cdot \cos(\alpha)
-$$
-
-显然当夹角 $\alpha = - \pi$，即 $\vec{v}$ 与 $\nabla L(\theta^{(k)})$ 的方向完全相反时，$\cos(\alpha) = -1$，两者乘积最小，损失值下降最快。所以梯度下降法会取**负梯度方向**为更新方向，所以它又叫**最速下降法**（Steepest Descent）。
-
-所以方向向量 $\vec{v}$ 为：
-
-$$
-\vec{v} = - \frac{\nabla L(\theta^{(k)})}{\| \nabla L(\theta^{(k)}) \|}
-$$
-
-则更新公式为：
-
-$$
-\theta^{(k+1)} = \theta^{(k)} - \eta \cdot \frac{\nabla L(\theta^{(k)})}{\| \nabla L(\theta^{(k)}) \|}
-$$
-
-为了方便，直接把 $\frac{\eta}{\| \nabla L(\theta^{(k)}) \|}$ 整体表示为 $\eta$，最终有：
-
-$$
-\theta^{(k+1)} = \theta^{(k)} - \eta \cdot \nabla L(\theta^{(k)})
-$$
-
-
-### KL 散度
-
-**KL 散度**（Kullback-Leibler Divergence）又叫**相对熵**，描述的是概率分布 p 与目标分布 q 之间的差异，计算公式为：
-
-$$
-KL (p \| q) = \int p(x) \log \frac{p(x)}{q(x)} dx
-$$
-
-两个分布越接近，KL 散度越小，当 $p=q$ 时，$KL (p \| q) = 0$。
-
-
-### Fisher 信息矩阵
-
-具体的细节可以看我的[这篇博客](/post/2021/07/27/fisher-information-matrix/)。简单来说，**Fisher 信息矩阵**（Fisher Information Matrix）是：
-
-- 对数似然函数的一阶导的二阶矩（基本定义）：
-
-  $$
-  F = \mathbb{E}_{p(x \mid \theta)} \Big [ \nabla \log p(x \mid \theta) \nabla \log p(x \mid \theta)^T \Big ]
-  $$
-
-- 对数似然函数的二阶导（海森矩阵）的期望取负（[证明过程](https://wiseodd.github.io/techblog/2018/03/11/fisher-information/)）
-
-  $$
-  F = - \mathbb{E}_{p(x \mid \theta)} \left [ \frac{\partial^2}{\partial_{\theta} \partial_{\theta^T}} \log p(x \mid \theta) \right ]
-  $$
-
-
-
-### KL 散度和 Fisher 信息
-
-一个结论是：令 $d \to 0$，有：
-
-$$
-KL \Big ( p(x \mid \theta) \| p(x \mid \theta + d) \Big ) \approx \frac{1}{2} d^T F d
-$$
-
-::: details 证明过程
-为了方便，用 $p(\theta)$ 来表示 $p(x \mid \theta)$，用 $p(\theta + d)$ 来表示 $p(x \mid \theta + d)$。
-
-$$
-\begin{aligned}
-  KL \Big ( p(\theta) \| p(\theta + d) \Big ) &= \int p(\theta) \log \frac{p(\theta)}{p(\theta + d)} dx = \mathbb{E}_{p(\theta)} \left [ \log \frac{p(\theta)}{p(\theta + d)} \right ] \\
-    &= \mathbb{E}_{p(\theta)} [ \log p(\theta) ] - \textcolor{blue}{\mathbb{E}_{p(\theta)} [ \log p(\theta + d) ]}  \\
-    &\approx \mathbb{E}_{p(\theta)} [ \log p(\theta) ] - \textcolor{blue}{\underbrace{\mathbb{E}_{p(\theta)} \left [ \log p(\theta) + \nabla \log p(\theta) d + \frac{1}{2} d^T \nabla^2 \log p(\theta) d \right ]}_{\text{二阶泰勒展开}}}  \\
-    & = - \mathbb{E}_{p(\theta)} [ \nabla \log p(\theta) d ] - \mathbb{E}_{p(\theta)} \left [ \frac{1}{2} d^T \nabla^2 \log p(\theta) d \right ] \\
-    &= - \left [ \int_{\theta} p(\theta) \frac{1}{p(\theta)} \nabla p(\theta) d \theta \right ] d - \frac{1}{2} d^T \mathbb{E}_{p(\theta)} [ \nabla^2 \log p(\theta) ] d \\
-    &= - \underbrace{\left [ \nabla \int_{\theta}  p(\theta) d \theta \right ]}_{\text{积分求导互换}} d - \frac{1}{2} d^T \mathbb{E}_{p(\theta)} [ \nabla^2 \log p(\theta) ] d \\
-    & = - \frac{1}{2} d^T \underbrace{\mathbb{E}_{p(\theta)} [ \nabla^2 \log p(\theta) ]}_{= - F} d \\
-    & = \frac{1}{2} d^T F d
-\end{aligned}
-$$
-:::
-
-即 Fisher 信息矩阵 $F$ 是 KL 散度的局部二阶近似。KL 散度定义了两个概率分布之间的差异，而 Fisher 信息矩阵定义了用 KL 散度做度量时，概率分布空间上局部曲率。
-
-
-
-### 黎曼流形
-
-#### 流形
-
-**流形**（Manifold）是局部具有欧氏空间（Euclidean space）性质的拓扑空间。可以把流形看做一个平滑的面，在流形上的每一个点上都可以做一个切面，也就是说每个点的周围都有一个可以看做平面的非常小的邻域，因此这个邻域是遵循欧氏度量的。举个栗子，人在地球上会感觉周围的平面都是平坦的，而感受不到地球的曲率。所以流形中的每一个点周围都有一个曲率为 0 的小型邻域和欧氏度量。
-
-更数学一点的表述是：假设 $M$ 是一个拓扑空间，如果 $M$ 上的任意一点 $p$，都有一个和欧氏空间 $\Reals^n$ 上的某个开集同胚的邻域，则称 $M$ 是一个 $n$ 维流形。这个欧氏空间上的开集被称为**切空间**（tangent space），记为 $T_p \mathcal{X}$。
-
-
-#### 黎曼度量
-
-欧氏空间上两点之间的距离可以直接用向量的模长来算。但流形不是线性空间，因此要用别的方法来算流形上的长度。假设 $\gamma: [a, b] \to M$ 是流形上一段连续可微分的弧线，那么一个可以想到的方法是算弧线 $\gamma$ 中所有点上的距离微分的积分：
-
-$$
-L(\gamma) = \int_a^b \| \gamma'(x) \| dx
-$$
-
-相当于对每个点 $\gamma(x)$，给出在它的切空间中计算距离的方法，通过这个方法算出 $x$ 的切向量（tangent vector）$\gamma'(x) = \frac{\partial}{\partial x} \gamma(x)$ 的模长 $\| \gamma'(x) \|$。最后把所有的 $\| \gamma'(x) \|$ 加起来，就是弧线的长度。
-
-那么计算 $\| \gamma'(x) \|$ 的公式是：
-
-$$
-\| \gamma'(x) \|^2 = ⟨ \gamma'(x), \gamma'(x) ⟩ = g_{\gamma(x)} (\gamma'(x), \gamma'(x))
-$$
-
-模长的平方就是 $\ell_2$ 范数，而 $\ell_2$ 范数就是向量自己跟自己的内积（inner product）。因此，$g_p: T_p \mathcal{X} \times T_p \mathcal{X} \to \Reals$ 就是一个定义了切空间上的内积的度量（metrics）。如果这个度量的值随点 $p$ **平滑**地改变，那么这个度量就叫**黎曼度量**（Riemannian Metrics），具有黎曼度量的流形就叫**黎曼流形**（Riemannian Manifold）。
-
-引用[这里](https://www.math.fsu.edu/~whuang2/pdf/ECNU_slides.pdf)的解释：
-
-::: info 黎曼流形
-Roughly, a Riemannian manifold $M$ is a smooth set with a smoothly-varying inner product on the tangent spaces.
-:::
-
-更数学一点，对于任意 $p \in M$，黎曼度量 $g = g_p$ 需要满足：
-
-- 对于任意 $u, v \in T_p \mathcal{X}$，有 $g(u, v) = g(v, u)$
-- 对于任意 $u \in T_p \mathcal{X}$，有 $g(u, u) > 0$
-- 当且仅当 $u = 0$ 时，$g(u, u) = 0$
-
-
-## 自然梯度下降
-
-### 约束优化角度
-
-在梯度下降中，我们要优化的问题是：
-
-$$
-\begin{gathered}
-  \min_{d} L(\theta + d) \\
-  \text{s.t.} \enspace \| d \| \leq \epsilon
-\end{gathered}
-$$
-
-其中 $\epsilon$ 相当于最大步长，参数更新的距离可以用欧氏距离来计算。
-
-如[之前](#梯度下降)所述，损失值 $L$ 下降最快的方向是负梯度方向：
-
-$$
-- \frac{\nabla L(\theta)}{\| \nabla L(\theta) \|} = \lim_{\epsilon \to 0} \frac{1}{\epsilon} \arg \min_{d \text{ s.t.} \| d \| \leq \epsilon} L(\theta + d)
-$$
-
-但是如果直接用梯度下降，参数发生改变后，参数的分布也会发生改变。所以分布的改变量也需要约束，而且这个改变量无法用欧氏距离来度量。因此自然梯度优化的是参数的概率分布 $p(x \mid \theta)$，而分布之间的距离一般可以用 [KL 散度](kl-散度)来衡量，所以现在优化问题变成了：
-
-$$
-\begin{gathered}
-  \min_{d} L(\theta + d) \\
-  \text{s.t.} \enspace KL \Big ( p(x \mid \theta) \| p(x \mid \theta + d) \Big ) \leq \epsilon
-\end{gathered}
-$$
-
-用拉格朗日乘子法把约束条件写进优化问题里：
-
-$$
-\begin{aligned}
-  d^* &= \arg \min_{d} L(\theta + d) + \lambda \Big ( KL \big ( p(x \mid \theta) \| p(x \mid \theta + d) \big ) - \epsilon \Big )  \\
-    &\approx \arg \min_{d} \underbrace{L(\theta) + \nabla L(\theta)^T d}_{\text{一阶泰勒展开近似}} + \underbrace{\frac{1}{2} \lambda d^T F d}_{\text{二阶泰勒展开近似}} - \lambda \epsilon
-\end{aligned}
-$$
-
-因为目标是函数取极小值，所以其导数应该为 0：
-
-$$
-\begin{aligned}
-  0 &= \frac{\partial}{\partial d} \left [ L(\theta) + \nabla L(\theta)^T d + \frac{1}{2} \lambda d^T F d  - \lambda \epsilon \right ] \\
-    &= \nabla L(\theta) + \lambda F d \\
-  \lambda F d &= -\nabla L(\theta) \\
-  d &= - \frac{1}{\lambda} F^{-1} \nabla L(\theta)
-\end{aligned}
-$$
-
-也就是说最后的梯度为 $\tilde{\nabla} L(\theta) = F^{-1} \nabla L(\theta)$（常数项可以和学习率合并），称为**自然梯度**。
-
-
-### 流形角度
-
-可以看到，梯度下降的方向取决于范数 $\|d\|$ 该怎么求。如果把这个优化问题看成流形上的优化，“$\|d\|$ 怎么求”就相当于“流形上的度量是什么”。
-
-原始梯度下降是在欧氏空间上的优化，所以度量就是欧氏范数。而自然梯度下降中是在概率分布空间上的优化，黎曼流形上的点 $p(x \mid \theta)$ 是一个参数化的概率分布。当参数从 $\theta$ 变成 $\theta + d$ 时，$p(x \mid \theta)$ 和 $p(x \mid \theta + d)$ 之间的距离就是 $\frac{1}{2} d^T F d$。可以看到 Fisher 信息矩阵 $F$ 正好就是这个黎曼流形上的黎曼度量。
-
-因为 Fisher 信息反映了似然概率分布空间上的局部曲率，因此用 $F$ 作为度量求出来的梯度下降方向考虑了似然概率分布空间上的曲率信息。曲率越大，说明为了维持这个似然，参数能够变化的量就越小。
-
-
-
-## 参考
-
-- [[知乎] 如何理解 Natural Gradient Descent？](https://www.zhihu.com/question/266846405)
-- [[知乎] 多角度理解自然梯度](https://zhuanlan.zhihu.com/p/82934100)
-- [[知乎] 什么是一般梯度、相对梯度、自然梯度和随机梯度？](https://www.zhihu.com/question/21923317/answer/205008255)
-- [[博客] Natural Gradient Descent](https://wiseodd.github.io/techblog/2018/03/14/natural-gradient/)
-- [[博客] 从勾股定理到黎曼度量](https://kexue.fm/archives/3969)
-- [[课件] Differential Geometry.](https://maths-people.anu.edu.au/~andrews/DG/) *Ben Andrews.* Australian National University.
-- [[课件] Differential Geometry.](http://people.maths.ox.ac.uk/~joyce/Nairobi2019/Hitchin-DifferentiableManifolds.pdf) *Nigel Hitchin.* Oxford University.
-- [[课件] Riemannian Metrics.](https://www.ime.usp.br/~gorodski) *Claudio Gorodski.* University of São Paulo.
-- [[论文] Geometric Deep Learning: Going beyond Euclidean Data.](https://maths-people.anu.edu.au/~andrews/DG/) IEEE Signal Processing Magazine 2017. *Michael M. Bronstein, et al.*
Index: blog/posts/2020-08-05-meta-learning.md
===================================================================
diff --git a/blog/posts/2020-08-05-meta-learning.md b/blog/posts/2020-08-05-meta-learning.md
deleted file mode 100644
--- a/blog/posts/2020-08-05-meta-learning.md	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
+++ /dev/null	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
@@ -1,279 +0,0 @@
----
-layout: Post
-title: "元学习：一种套娃算法"
-subtitle: 'Meta Learning: Learning to Learn'
-author: Renovamen
-date: 2020-08-05
-headerImage: /img/in-post/2020-08-05/header.jpg
-permalinkPattern: /post/:year/:month/:day/:slug/
-tags:
-  - Meta Learning
-  - Deep Learning
----
-
-continual learning 方向 19 年之后的[几篇论文](https://note.zxh.io/papers/dl/continual-learning.html#meta-learning)搞出了一个套 meta learning 框架（主要是 MAML 这种 optimization-based 的方法）的新思路。<!-- more -->这个思路~~又可以水不少论文~~还是很自然的，毕竟 meta learning『快速适应新任务』的思想可以看做 continual learning 的两个目标之一（学习新任务）的升级版，那么就只需要解决剩下那个目标（灾难性遗忘）就可以了。
-
-于是这里我决定稍微理一理背后的思想是~~套娃~~ learning to learn 的 meta learning 的基本概念。
-
-这是一篇讲 meta learning 讲得非常清楚的文章，本文很大程度上~~抄~~参考了这篇文章：
-
-**Learning to Learn Fast** (Lilian Weng) [[英文原版]](https://lilianweng.github.io/lil-log/2018/11/30/meta-learning.html) [[中文翻译]](https://wei-tianhao.github.io/blog/2019/09/17/meta-learning.html)
-
-这作者还写过一篇在 reinforcement learning 任务里面用 meta learning 的文章：
-
-[**Meta Reinforcement Learning**](https://lilianweng.github.io/lil-log/2019/06/23/meta-reinforcement-learning.html) (Lilian Weng)
-
-这是自用的对 meta learning 相关文献的记录：[Literatures of Meta Learning](https://note.zxh.io/papers/dl/meta-learning.html)
-
-
-## 动机
-
-传统监督学习的流程是，对于一个训练集 $D = \{ (x_i, y_i) \}$，试图学习出一个模型 $f_{\theta}$（$\theta$ 是从训练数据中估计出的模型参数，决定了 $f$ 的性能 ），使得损失函数 $L(f_{\theta}(x), y)$ 最小。
-
-这个思路在训练集中有大量数据的情况下是行得通的。而在很多情况下，有的数据集的数据量非常少，我们很难在上面直接训练出来一个泛化能力好的机器学习模型。
-
-但不同的相似任务之间是有联系的。比如人类学会分类新的物体并不需要很多的样本作为支撑，人类可以做到只观看一个物体的一张或几张图片，就在之后的照片中准确地识别。这就是利用了不同任务之间的联系，基于过往的经验快速地学习。比如下面这个例子，训练数据中每个类别就三个样本，然后让你判断测试数据是哪个画家的作品：
-
-![which painter](/img/in-post/2020-08-05/paint.png)
-
-<p class="desc">图片来源：<a href="https://drive.google.com/file/d/1DuHyotdwEAEhmuHQWwRosdiVBVGm8uYx/view" target="_blank">Slides for ICML 2019 Meta-Learning Tutorial</a></p>
-
-
-答案是 Braque。由于每个类别的样本很少，人类能答对这个问题很大程度上是依赖过往经验，而不是从头开始学习（虽然作为~~神~~人类我觉得这个问题似乎也不简单？2333）。所以就有了这样的想法：有些不同的任务之间是有一定的联系的，所以虽然我现在要做的这个任务的数据集的数据量很少，但我有很多其它的数据集，如果模型可以先在其他数据集上学到“如何快速学习新知识”的先验知识（即 learn to learn，学习出一个会学习的模型），大概就能仅用少量的数据就学会新的概念。
-
-这就是一个套娃的过程。
-
-事实上我们还可以继续套更多的娃，比如 learn to learn to learn，即学习一个能够学习出会学习的模型的模型（...）。甚至还可以衍生到 learn to ... to learn，最终可以实现机器学习的完全自动化。
-
-
-## 问题定义
-
-meta learning 可以用于解决任意一类定义好的机器学习任务，如监督学习、强化学习等。这里谈的主要是监督学习（如图像分类）。
-
-
-### 概览
-
-假设有一个 task 的分布，我们从这个分布中采样了许多 task 作为训练集。我们希望 meta learning 模型在这个训练集上训练后，能在这个分布中所有的 task 上都有良好的表现，即使是从来没见过的 task。每个 task 可以表示为一个数据集 $D$，数据集中包括输入向量 $x$ 和其对应的标签 $y$，task 分布表示为 $p(D)$ 。那么 meta learning 的优化目标是：
-
-$$
-\theta^* = \arg \min_{\theta} \mathbb{E}_{D \thicksim p(D)} [L_{\theta}(D)]
-$$
-
-可以看到，一般的学习任务中，模型会在一个 task 中通过对样本的学习以对新样本做出决策；而 meta learning 把每个样本换成了**一个 task**，通过对多个 task 的学习以对新的 task 进行快速的学习。
-
-数据集 $D$ 通常还会被划分为训练集 support set $S$ 和测试集 query set $B$，即 $D = \lang S,B \rang$。相当于 meta learning 的训练阶段会**模拟传统训练中的测试过程**。
-
-![datasets for meta-learning](/img/in-post/2020-08-05/meta-dataset.png)
-
-<p class="desc">图片来源：<a href="https://www.dropbox.com/s/sm68skkkbxbob0i/metalearning.pdf?dl=0" target="_blank">Generalizing from Few Examples with Meta-Learning</a></p>
-
-
-一个需要解释一下的术语是 N-way K-shot，指 support set 中有 N 类数据，每类数据有 K 个带有标注的样本。
-
-
-![few shot classification](/img/in-post/2020-08-05/few-shot-classification.png)
-
-<p class="desc">2-way 4-shot 图像分类示例。我们希望模型在知道了如何区分『猫和鸟』以及『花和自行车』后，能快速学会区分『狗和水獭』。图片来源：<a href="https://lilianweng.github.io/lil-log/2018/11/30/meta-learning.html#a-simple-view" target="_blank">Meta-Learning: Learning to Learn Fast</a></p>
-
-
-### 训练过程
-
-meta learning 的训练过程一般为，对于每一个 task $D$：
-
-1. 采样出一个 support set $S \in D$ 和一个 query set $B \in D$；
-
-2. 在 support set $S$ 上进行学习，根据这些样本上的损失进行参数更新，得到更新后的参数 $\theta'$。但通常 $\theta'$ 只是一个临时参数。
-
-    这一步被叫做元学习器（meta-learner），其目的是为整个模型（学习器）该怎么更新参数提供指导；
-
-3. 用临时参数 $\theta'$ 在 query set $B$ 上计算损失，并根据这个损失来更新模型参数。这一步是永久更新，与监督学习一致。
-
-我从直觉上来理解的话，第二步对标传统训练中的训练集上的参数更新，第三步对标测试阶段，然后用测试集上的损失来更新模型参数。通过这种方式，模型被训练出了在其他数据集上扩展的能力。
-
-
-### 常见方法
-
-meta learning 主要有三类常见的方法：
-
-- 基于度量（metric-based）
-
-  思想类似于 k-NN 一类的算法。测试时会计算输入样本跟 support set 中所有样本的距离，然后根据这些距离预测标签。这种方法一般只能用于分类问题。
-
-- 基于模型（model-based）
-
-  不对模型做任何定义，直接用另外一个神经网络把它的参数都学习出来，这个用来学习模型参数的网络一般基于 RNN。
-
-- 基于优化（optimization-based）
-
-  相比 model-based 方法，optimization-based 方法只学习初始化参数的规则，而不学习模型架构，模型架构是提前定好的。这类方法的主要流派就是 MAML，本文后面主要会理一下 MAML。
-
-
-## MAML
-
-**Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks.** *Chelsea Finn, et al.* ICML 2017. [[Paper]](https://arxiv.org/pdf/1703.03400.pdf) [[Code]](https://github.com/cbfinn/maml) 
-
-这是 MAML 一作：[Chelsea Finn](https://ai.stanford.edu/~cbfinn/) （现在是 Stanford 的 AP），她们组有不少相关的工作。
-
-MAML（Model-Agnostic Meta-Learning）是一种通用的基于优化的算法，可以被用于任何基于梯度下降学习的模型。它的目标是学习出一组初始化参数 $\theta$，对于任意 task，这个初始化的参数都能在一步或极少步梯度下降中就快速达到最优参数解 $\theta_n^*$：
-
-<img src="/img/in-post/2020-08-05/maml-diagram.png" width="450px" alt="diagram of maml" />
-
-
-### Meta-Train
-
-MAML 的训练过程（一般被称为 meta-train）为：
-
-<img src="/img/in-post/2020-08-05/maml-alg.png" width="600px" alt="maml algorithm" />
-
-可以看到对于采样出每个 task $\mathcal{T}_i$，有两层循环：
-
-- inner loop：在从 task $\mathcal{T}_i$ 中采样出的 support set 上计算梯度并更新参数（只更新一次），得到更新后的参数 $\theta'$。就像之前所说，这里的 $\theta'$ 只是一个临时参数，并不会作为最终的更新（所以实际操作上是要 copy 一份当前参数去计算 $\theta'$）；
-
-- outer loop：用参数 $\theta'$ 在采样出的 query set 上计算损失，然后**对参数 $\theta$ 求梯度**，然后在 $\theta$ 上更新出最终的模型参数。
-
-这个过程如下图所示：
-
-<img src="/img/in-post/2020-08-05/maml-update.png" width="300px" alt="maml update" />
-
-<p class="desc">图片来源：<a href="https://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2019/Lecture/Meta1%20(v6).pdf" target="_blank">Meta Learning，李宏毅</a></p>
-
-
-
-### Meta-Test
-
-在测试（mete-test）时，会把经过 meta-train 训练好的模型拿去测试集（新 task）的 support set 上 fine-tune，然后在 query set 上得到测试结果。fine-tune 的过程跟 meta-train 基本上差不多，不同点主要是：
-
-- 第 1 行：meta-train 时的 $\theta$ 是随机初始化的，而 fine-tune 时直接用了经过 meta-train 后得到的 $\theta$；
-
-- 第 3 行：fine-tune 的时候就不存在 batch 了，只抽取一个 task 来学习；
-
-- 第 8 行：fine-tune 的时候不存在这一步，因为这时的 query set 是用来测试模型的，不可能给你算损失然后梯度回传。所以会直接用第 6 行得到的 $\theta'$ 作为最终参数。
-
-
-### 二阶导
-
-outer loop 对 $\theta$ 求导时是需要进行二阶导计算的。设模型初始参数为 $\theta_0$，第 $i$ 次 innner loop（第 $i$ 个 batch）的参数更新公式可以表示为：
-
-$$
-\theta_i = U_{i-1}(\theta_{i-1}) = \theta_{i-1} - \alpha L_i'(\theta_{i-1})
-$$
-
-那么 outer loop 中：
-
-$$
-\theta_0 \leftarrow \theta_0 - \beta g_{\text{MAML}}
-$$
-
-$$
-\begin{aligned}
-  g_{\text{MAML}} &= \frac{\partial}{\partial \theta_0} L_k(\theta_k) \\[10pt]
-    &= \frac{\partial}{\partial \theta_0} L_k(U_{k-1}(U_{k-2}(\dots (U_0(\theta_0))))) \\[15pt]
-    &= U_0'(\theta_0) \dots U_{k-1}'(\theta_{k-1}) L_k'(\theta_k) \\[5pt]
-    &= L_k'(\theta_k) \prod_{i=0}^{k-1} U_i'(\theta_i) \\
-    &= L_k'(\theta_k) \prod_{i=0}^{k-1} (I - \textcolor{red}{\alpha L_i''(\theta_i)})
-\end{aligned}
-$$
-
-标红部分是二阶导。求二阶导会消耗更多的计算时间，为了节省计算成本，作者还提出了 MAML 的一阶变种 [First-Order MAML（FOMAML）](#fomaml)，即直接舍弃掉二次微分项。
-
-
-### Transfer Learning?
-
-MAML 的思想很像 transfer learning，即在大数据集上预训练一个模型，学习一个初始化参数，然后拿到小数据集任务上去 fine-tune。Chelsea Finn 在[一篇博客](https://bair.berkeley.edu/blog/2017/07/18/learning-to-learn/)中也阐述了 MAML 跟 transfer learning 的区别和联系。当某个任务的数据量过小时，把预训练模型直接拿去 fine-tune 会过拟合。因此 MAML 的核心目标是，学习一个在小数据集上更容易被 fine-tune 的初始化参数。
-
-下图是 MAML 和一般的预训练模型的参数更新方式对比：
-
-<img src="/img/in-post/2020-08-05/maml-pretrain.png" width="600px" alt="maml vs pre-train" />
-
-
-## FOMAML
-
-First-Order MAML（FOMAML），MAML 作者顺便提出的一阶版本，为了节省计算成本，直接扔掉了二次微分项。
-
-MAML 的 outer loop 会对 $\theta$ 而不是 $\theta'$ 求梯度，因此存在[二阶梯度](#二阶导)为：
-
-$$
-g_{\text{MAML}}= L_k'(\theta_k) \prod_{i=0}^{k-1} (I - \alpha L_i''(\theta_i))
-$$
-
-而 FOMAML 直接对 $\theta'$ 求梯度，这样就没有二阶梯度了：
-
-$$
-g_{\text{FOMAML}}= L_k'(\theta_k)
-$$
-
-FOMAML 算法流程为：
-
-![fomaml](/img/in-post/2020-08-05/fomaml.png)
-
-<p class="desc">图片来源：<a href="https://www.andrew.cmu.edu/user/abhijatb/assets/Deep_RL_project.pdf" target="_blank">First-order Meta-Learned Initialization for Faster Adaptation in Deep Reinforcement Learning</a></p>
-
-
-
-从论文中的实验，包括 [Reptile](#reptile) 论文中的实验来看，省掉二阶梯度对于结果的影响并不大。
-
-## Reptile
-
-**On First-Order Meta-Learning Algorithms.** *Alex Nichol, et al.* arXiv 2018. [[Paper]](https://arxiv.org/pdf/1803.02999.pdf) [[Code]](https://github.com/openai/supervised-reptile) [[Slide]](https://www.slideshare.net/YoonhoLee4/on-firstorder-metalearning-algorithms)
-
-Reptile 是另一种一阶的 meta learning 算法，它的流程为：
-
-![reptile](/img/in-post/2020-08-05/reptile.png)
-
-带 batch 的版本就是每次采样多个 task：
-
-![batched reptile](/img/in-post/2020-08-05/reptile-batch.png)
-
-Reptile 与 FOMAML 的区别在于：
-
-- inner loop 中会根据损失 $L_{\tau}$ 进行 $k$ 次 sgd
-
-- outer loop 中不再计算梯度，而是取 inner loop 更新后的参数与原模型参数的改变量的 $\epsilon$（学习率）倍
-
-当 $k = 1$ 时，这个算法就是 multi-task learning 用 sgd 更新一步的公式：在每个 task 上都更新一步，就相当于对所有 task 的总损失的期望求梯度然后更新了。
-
-普通 multi-task 进行 $k$ 次 sgd 求的是 $\text{SGD}(\mathbb{E}_{\tau}[L_{\tau}], \theta, k)$；而 Reptile 的 $k$ 次 sgd 在 inner loop 里，所以它求的是 $\mathbb{E}_{\tau}[\text{SGD}(L_{\tau}, \theta, k)]$，当 $k >1$ 时两者是不一样的。
-
-Reptile 的参数更新过程：
-
-<img src="/img/in-post/2020-08-05/reptile-update.png" width="600px" alt="reptile update" />
-
-与 MAML 和 Pre-train 在一次外循环里的参数更新的对比：
-
-<img src="/img/in-post/2020-08-05/reptile-maml-pretrain.png" width="400px" alt="reptile vs maml vs pre-train" />
-
-
-## Reptile & MAML
-
-Reptile 论文里还对 Reptile 和 MAML 的原理写了一大段分析。推了一堆公式之后，作者认为 Reptile 和 MAML 的优化目标都为（5.1 节）：
-
-- 沿 task 上的损失的平均梯度方向更新模型，使模型在当前任务上的表现更好
-
-- 最大化同一个 task 中多个 batch 的梯度的内积。因为梯度的内积越大说明它们夹角越小，意味着它们的更新方向越相似，因此在一个 batch 上的更新同时还能提升在另外一个 batch 上的性能，从而使模型在当前任务上具有更好的泛化性。
-
-这是一张解释第二点的图：
-
-<img src="/img/in-post/2020-08-05/transfer-interference.jpg" width="550px" alt="transfer & interference" />
-
-<p class="desc">图片来源：<a href="https://arxiv.org/pdf/1810.11910.pdf" target="_blank">Learning to Learn without Forgetting by Maximizing Transfer and Minimizing Interference (ICLR 2019)</a></p>
-
-
-## 参考
-
-- **Learning to Learn Fast.** Lilian Weng. [[英文原版]](https://lilianweng.github.io/lil-log/2018/11/30/meta-learning.html) [[中文翻译]](https://wei-tianhao.github.io/blog/2019/09/17/meta-learning.html)
-
-- **Meta Learning.** Hung-yi Lee (李宏毅). [Slides: [Part 1](https://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2019/Lecture/Meta1%20(v6).pdf), [Part 2](https://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2019/Lecture/Meta2%20(v4).pdf)] [[Video]](https://www.youtube.com/watch?v=EkAqYbpCYAc&list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&index=33&t=0s)
-
-- [ICML 2019 Tutorial - Meta-Learning: from Few-Shot Learning to Rapid Reinforcement Learning](https://sites.google.com/view/icml19metalearning)
-
-- [CVPR 2020 Tutorial - Towards Annotation-Efficient Learning: Few-Shot, Self-Supervised, and Incremental Learning Approaches](https://annotation-efficient-learning.github.io/)
-
-- [元学习（Meta Learning）学习笔记](http://www.gwylab.com/note-meta_learning.html)
-
-- [Generalizing from Few Examples with Meta-Learning.](https://www.dropbox.com/s/sm68skkkbxbob0i/metalearning.pdf?dl=0) Hugo Larochelle.
-
-- [Learning to Learn.](https://bair.berkeley.edu/blog/2017/07/18/learning-to-learn/) Chelsea Finn.
-
-- [First-order Meta-Learned Initialization for Faster Adaptation in Deep Reinforcement Learning.](https://www.andrew.cmu.edu/user/abhijatb/assets/Deep_RL_project.pdf) Abhijat Biswas and Shubham Agrawal.
-
-- [Model-Agnostic Meta-Learning （MAML）模型介绍及算法详解](https://zhuanlan.zhihu.com/p/57864886)
Index: blog/posts/2020-02-24-the-enigmatic-appeal-of-video-games-greatest-bards.md
===================================================================
diff --git a/blog/posts/2020-02-24-the-enigmatic-appeal-of-video-games-greatest-bards.md b/blog/posts/2020-02-24-the-enigmatic-appeal-of-video-games-greatest-bards.md
deleted file mode 100644
--- a/blog/posts/2020-02-24-the-enigmatic-appeal-of-video-games-greatest-bards.md	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
+++ /dev/null	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
@@ -1,79 +0,0 @@
----
-layout: Post
-title: "「译」游戏中的游吟诗人的神秘魅力"
-subtitle: "The world’s second-oldest profession has a long history of nonviolence in video games"
-author: Renovamen
-date: 2020-02-24
-useHeaderImage: true
-headerImage: /img/in-post/2020-02-24/header.jpg
-headerMask: rgb(46, 86, 90, .4)
-permalinkPattern: /post/:year/:month/:day/:slug/
-tags:
-  - 摸鱼
----
-
-翻译自 [EGM](https://egmnow.com/) 上的文章：[<v-icon name="ri-link-m" scale="0.9"/> *Toss a Coin: The Enigmatic Appeal of Gaming’s Greatest Bards*](https://egmnow.com/toss-a-coin-the-enigmatic-appeal-of-video-games-greatest-bards/)。
-
-<!-- more -->
-
----
-
-本文的封面图是《塞尔达传说：荒野之息》中的利特族游吟诗人卡西瓦（Kass）。原文的封面图是这张（《巫师》系列里的游吟诗人丹德里恩）：
-
-![Original Header Image](/img/in-post/2020-02-24/the-witcher-dandelion-header.jpg)
-
----
-
-几十年来，电子游戏中的游吟诗人一直在带给人们无穷的乐趣。无论是陪着巫师寻找怪物，还是只是在当地的小酒馆里搞歌曲串烧，他们给玩家带来的乐趣主要在于为玩家提供了一种与通常由暴力定义和塑造的游戏世界进行非暴力的交互的方式。在各种游戏里他们都可以扮演不同的角色，从鼓舞你的队伍的士气，到引入传奇的支线剧情，再到充当历史学者或社区人物。但游吟诗人的历史可以追溯到比你想象得还要久远的时候。
-
-“游吟诗人（bard）”这个词最初被用来称呼来自爱尔兰、苏格兰和威尔士的凯尔特部落（Celtic tribal）的歌手，这些歌手通过演奏竖琴（harp）或[克鲁斯琴（crwth）](https://en.wikipedia.org/wiki/Crwth)来为富有的顾客进行歌颂或讽刺。他们的歌曲的共同主题通常是富人的冷漠、英雄事迹、宗教民谣以及对恩人的颂歌。但如今这个词的范围已经被扩大，它还可以用来指许多类似的文化习俗，包括南欧（minstrel）和挪威（skald）的游吟诗人。
-
-![Skyrim Sven](/img/in-post/2020-02-24/skyrim-sven.jpg)
-
-<p class="desc">《上古卷轴》中的游吟诗人从挪威的游吟诗人身上汲取了灵感——虽然并没有确切的证据表明历史上挪威的诗人会演奏乐器</p>
-
-《The Strategic Review》[^1][第 2 卷第 1 期](https://annarchive.com/files/Strv201.pdf)首次将游吟诗人引入了《龙与地下城》，它起着“万事通”的作用并借鉴了许多类似的传统。它通常在冒险队中担任辅助角色，允许玩家通过吟唱来施放咒语和鼓舞他人。这种设定意味着玩家可以用暴力以外的方法（如依靠魅力或口才）来进行角色扮演和解决冲突，从而使玩家的游戏体验更独特和更具社交性。
-
-游吟诗人和咒语、魔法的结合很可能起源于他们和[德鲁伊（druids）](https://en.wikipedia.org/wiki/Druid)的接近。例如威尔士编年史家 Elis Gruffydd 曾描写过一个据说拥有预知未来的能力威尔士吟游诗人 Taliesin。然而，随着把游吟诗人描绘成预言家和先知的前浪漫主义和浪漫主义诗人，如 [Thomas Gray](https://en.wikipedia.org/wiki/Thomas_Gray)、[Felicia Hemans](https://en.wikipedia.org/wiki/Felicia_Hemans) 和 [William Blake](https://en.wikipedia.org/wiki/William_Blake)，的到来，公众把游吟诗人当做魔法师的想象很可能被发酵了。你可以在 Thomas Gray 的[《The Bard: A Pindaric Ode》](https://www.poetryfoundation.org/poems/44298/the-bard-a-pindaric-ode)中看到这一点，其中一个威尔士吟游诗人在斯诺登山上诅咒英格兰国王爱德华一世和他对威尔士的征服：“*Ruin seize thee, ruthless King!*”，然后他预言了双方的毁灭：“*The different doom our Fates assign. Be thine Despair, and scept’red Care, / To triumph, and to die, are mine.*”
-
-![The Bard's Tale](/img/in-post/2020-02-24/the-bards-tale.jpg)
-
-<p class="desc">《冰城传奇》重制版截图</p>
-
-随着游戏开发者开始专注于计算机并希望将《龙与地下城》用代码开发出来，游吟诗人迅速成为了基于职业系统的 RPG 游戏的主要内容，他们为传统英雄职业提供了替代选择。例如《冰城传奇》不仅将游吟诗人设定为讲述者，还允许玩家将他们招募进自己的队伍，以让他们在战斗中治疗队友、施放保护咒语和安抚被激怒的怪物——这为战斗增添了多样性。同样，《最终幻想》系列的数款游戏中也有游吟诗人这个职业，玩家可以在战斗中通过吟唱来治疗队友、恐吓敌人和免疫攻击。在这两个例子中，游吟诗人都将“战斗”这个词延伸到了暴力以外的地方，从而颠覆了游戏系统。就像游吟诗人与魔法的结合一样，这种设定也有历史基础，让人想到了爱尔兰的 Ollamhain Re-dan 和 Filidhe[^2]，他们会用音乐激发军队的热情，然后远距离观看战斗。
-
-<img src="/img/in-post/2020-02-24/edward-ffiv.jpg" width="250px" alt="Edward FFIV" />
-
-<p class="desc">《最终幻想IV》中的爱德华</p>
-
-在《最终幻想 IV》中，史克威尔放弃了职业系统，转而将游吟诗人的角色放在了爱德华王子的身上。可能是为了产生戏剧性效果，爱德华在继承了其前辈的许多特征的同时利用了吟游诗人的浪漫的特点。就像结婚后不久妻子[欧律狄刻](https://en.wikipedia.org/wiki/Eurydice)（Eurydice）就被杀死的色雷斯游吟诗人[俄耳甫斯](https://en.wikipedia.org/wiki/Orpheus)（Orpheus）[^3]一样，爱德华的挚爱安娜在游戏初期就在红翼飞艇对大漠烟城的轰炸中死亡。他的悲痛是驱使他踏上征途的动力，因为他被他的挚爱的灵魂所困扰。但与暴怒的安娜的父亲泰拉不同，爱德华只是被对自己的质疑所困扰，并没有一定要报仇，他只是想要通过帮助队友打败邪恶的高贝兹来为他失去的人找回和平。这让他成为了队伍中一个非常吸引人的角色，他不是一个典型的英雄，与队伍中的其他成员形成了鲜明的对比。
-
-Greg Lobanov 在他们 2018 年发售的游戏《Wandersong》中进一步利用了游吟诗人的特点来对游戏设计进行创新。在该游戏中你会扮演一个通过歌唱来解决难题和处理冲突的角色，你需要控制一个由音符组成的转轮来唱出不同的音符或按照屏幕上的提示及时进行对应的操作来做到这些。游戏在开场时就简洁的传达了这种理念，游吟诗人捡起了一把剑，但马上就被解除了武装。这告诉玩家，这不是一个典型的平台动作游戏，这也不是一个传统的英雄[^4]。厌恶暴力的游吟诗人更喜欢采用跟怪物交流、治愈生灵和使迷失的灵魂重新团聚一类的方法。这种形式令人耳目一新，颠覆了我们对于这种需要打 Boss 或进行其他对抗的游戏类型的看法。
-
-<img src="/img/in-post/2020-02-24/gwent-dandelion.jpg" width="300px" alt="Gwent Dandelion" />
-
-<p class="desc">丹德里恩的昆特牌</p>
-
-游戏中最著名的游吟诗人大概是《巫师》中的丹德里恩。（在 Netflix 的《巫师》电视剧中，他的名字用了波兰语原名 Jaskier，这个词在波兰语中也可以指一种叫毛茛的花。）丹德里恩是猎魔人杰洛特的陪同者，他被描绘为一个经常因为肉欲和冲动而使他的朋友们陷入困境的色鬼。这一点可以在《巫师 3：狂猎》的破碎之花任务中看出来，该任务中杰洛特必须拜访在丹德里恩失踪前跟他交往过的女性以找出他的下落。
-
-丹德里恩是游吟诗人的粗野版本，尽管如此，他依然证明了自己是一个可靠的朋友和宝贵的资源，并能够帮助杰洛特和平解决一些复杂的任务。例如在《巫师 1》中，杰洛特用丹德里恩的诗让一个被谋杀的新娘的灵魂安息，或是在《巫师 2：国王刺客》中，他被拉去勾引一个被指控杀害士兵的魅魔以知道她对这件事的说法。他跟杰洛特的关系中有一种微妙的利益交换，他能从与这位巫师的冒险中榨取出一些故事来作为诱饵。
-
-当然，游吟诗人更多的是以遍布城镇的 NPC 的形式出现在 RPG 游戏中。如在《神鬼寓言》的前两部中，玩家可以雇佣游吟诗人来歌颂自己的英雄事迹并向城镇中的人传播自己的声誉。这是一种与该系列对英雄的迷恋相符并将游吟诗人视为一个社区的核心的行为。在第三部中，这个功能被移除了，但取而代之的是一个更加商业化的方法：玩家可以自己拿起鲁特琴（lute）来在一个像《吉他英雄》一样的节奏游戏中赚取金币。
-
-在《上古卷轴 V：天际》中，游吟诗人也是非常常见的，他们会在泰姆瑞尔的潮湿沉闷的小酒馆中演奏，或在独孤城中著名的游吟诗人学院学习。把他们跟游戏中其他 NPC 区别开来的是，你可以要求他们给你演奏歌曲来教你泰姆瑞尔大陆的历史。他们演奏的曲目包括《龙裔归来》、《红衣拉格纳》、《好战年代》、《压迫年代》等。在《上古卷轴 V：天际》中，游吟诗人不仅是一种乐趣的来源，也是当地的历史学家并代表了人民的声音。例如，根据你在游戏中所处地区的不同，你会遇到吟唱偏向于风暴斗篷或是偏向于帝国的歌曲的游吟诗人，他们的音乐详述了附近地区的冲突和情绪。
-
-最近，甚至在很多并不需要游吟诗人的游戏中也出现了游吟诗人。例如在《雷霆一击》中，有玩家用游戏里的鲁特琴来配置了一套自己的打法，他们通过[演奏流行音乐来](https://youtu.be/E_zzJiWJQ08)[^5]来暂时迫使战斗停止。因为通常在这个游戏中，杀死游吟诗人的行为是不被赞同的，双方一般都不会选择对游吟诗人动手，否则可能会被标记为“bard killer”。
-
-![Mordhau Bard](/img/in-post/2020-02-24/mordhau-bard.jpg)
-
-<p class="desc">《雷霆一击》中的游吟诗人</p>
-
-多年以来，游吟诗人一直是流行文化中的常驻角色。它融合了不同的传统，相对于传统的奇幻英雄来说，它更加理想化，也是一种替代的选择。在游戏中，游吟诗人可以作为可玩角色，也可以作为 NPC 出现，他们为玩家提供了一种新奇的与世界进行非暴力交互的方式。尽管他们无疑是相当典型的角色，他们依然有多种多样的刻画方式。在这种被挥剑的英雄和硬汉主角主导的媒介中，拿起乐器放松一下，或是脱离战斗在世界中某个安静的角落欣赏音乐休息一下是非常有趣的。
-
----
-
-[^1]: 《龙与地下城》的开发商 TSR 早期出版的杂志
-[^2]: 大概是爱尔兰的[两种诗人](http://billhaneman.ie/IMM/IMM-I.html)
-[^3]: 古希腊神话中太阳神阿波罗和缪斯女神卡利俄帕的儿子，诗人和歌手
-[^4]: 记笔记：原文用的 *bog-standard* 这个词
-[^5]: 视频中演奏的是《Enter Sandman》
Index: blog/posts/2022-01-29-travel-to-boston.md
===================================================================
diff --git a/blog/posts/2022-01-29-travel-to-boston.md b/blog/posts/2022-01-29-travel-to-boston.md
deleted file mode 100644
--- a/blog/posts/2022-01-29-travel-to-boston.md	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
+++ /dev/null	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
@@ -1,500 +0,0 @@
----
-layout: Post
-title: 波士顿漫游指南
-subtitle: How to Travel to Boston
-author: Renovamen
-date: 2022-01-29
-useHeaderImage: true
-headerImage: /img/in-post/2022-01-29/header.jpeg
-headerMask: rgb(65, 48, 30, .2)
-permalinkPattern: /post/:year/:month/:day/:slug/
-tags:
-  - 摸鱼
----
-
-在 gap 了一年，又上了一学期网课以后，我终于来了波士顿。
-
-<!-- more -->
-
-
-## 申请
-
-没敢直博，想给自己一个硕士毕业直接打工的机会，并且以我当时的菜鸡背景应该也没啥导师愿意要。
-
-虽然现在也是菜鸡背景就是了。
-
-
-### GPA
-
-我的 GPA 并不好看。
-
-对于本科毕业后想去美国读 master 的人来说，GPA 非常重要。像 USC 这种学校甚至直接把除了三维以外的材料（CV、PS、RL）设成了 optional，我估计它们真就只看本科学校和三维。我甚至盲猜 USC 会先用机器把 GPA 低于 3.7 的申请全扔出去，因为我二三月份就收到了拒信，而我认识的 GPA 3.6 左右的人也差不多那时候收到了拒信...
-
-如果一定要考虑一个极端的情况，那么如果本科学校够好，GPA 够高，即使其他背景非常平庸，申到的项目应该也挺好。
-
-但我希望你不要让这个极端情况发生。GPA 只是一个数字，一个很重要学校很看重写在申请上很好看所以必须得高的数字，但它几乎证明不了你的核心能力，它无法保证你就能找到很好的工作或做出很好的研究。尤其是在目前这种国内绝大多数学校的绝大多数课程质量都不高，投入太多时间上课甚至会拖累你提高能力的情况下（美本/海本/国内顶级学校比如清北华五的情况可能会稍微好一点）。上课当然也是很有必要的，但大多数情况下建议直接对标美帝顶级学校的网课。
-
-所以我觉得最好的情况是，在耗费尽可能少的精力的前提下，用你能找到的任何（合法）方法把这个数字拉高，然后剩下的时间用来攒真正有用的东西，包括但不限于个人能力、实习、publication、connection（我现在觉得 connection 最重要）、信息渠道等。
-
-好吧这听上去像句废话，大家都想轻松拿到好看的 GPA。但总之就是，永远都有比 GPA 和在学校上课更重要的东西。
-
-
-### TOEFL
-
-这就不得不提一提我考了 7 次托福的血泪史了。从涨价前考到了涨价后，加起来给 ETS 送了上万的人民币。因此我觉得我应该对考过的几个考场进行一下点评：
-
-- 好耶
-
-  - 重庆教育社会考试服务中心
-
-    考过的条件最好的考场，甚至好于宁波诺丁汉和西交利物浦。设备很新，监考、管理什么的都很好，而且休息时间还有小蛋糕吃，这真的是我见过的唯一一个有小蛋糕吃的考场嘤。
-  
-  - 西交利物浦大学
-
-  - 宁波诺丁汉大学
-
-    这俩学校就没有必要多解释了，尤其是西交利物浦，我当时报班学托福的时候老师强调了好多次“一定要去西交利物浦体验一下啊在那里考贼爽啊”。
-
-- 中规中矩
-
-  - 宁波大学
-
-    在去宁波的时候，刚到虹桥我的背包带就断掉了。然后我那正好在虹桥实习的室友表示了震惊，然后带着我去无印良品买了一个新包，这包一直用到了现在。
-
-  - 上海开放大学
-
-
-- 傻孩子们快跑啊
-
-  - 上海大学
-
-    相邻两个人仅仅用一张纸板隔开。最大的问题是耳机不隔音且漏音非常严重，做听力的时候我甚至能听到隔壁小哥耳机的漏音，于是我被迫调大音量，结果隔壁小哥的漏音更大了。我估计是因为我调大音量后漏音变大，影响到了隔壁小哥，于是他也只能调大音量。只能说冤冤相报何时了...可以想象旁边有人在说口语而我在听录音的时候我有多崩溃...
-
-    但我托福最高分和听力最高分就是在这里考出来的...这是什么置之死地而后生吗...
-
-啊我好像只写了六个，那要么是我忘了一个，要么是我在某个考场考了两次。
-
-我是考完 GRE 以后托福才过的线。跟 GRE 拉扯完以后，至少托福阅读部分就不该有任何压力了，我当时稳定 15 分钟一篇文章，基本不会丢分。而口语我一直处于放弃状态，因为我认真练几个月去考，23 分；完全不练，考前一周才开始做题找感觉，也 23 分，那我还练啥练。
-
-因此最后阶段让我痛苦的是听力和作文。我也不知道我这两项是怎么把分考上去的，我只记得我最后基本上是每一两周考一次托福的频率，然后不知道哪一次分就能看了。所以我一直觉得，托福是一定能过线的，只要你付得起足够多次数的托福考试费 😂。
-
-
-
-### GRE
-
-我开始准备 GRE 的时候已经是大三暑假了。那时我托福还只有 80+，但我短期内实在不想再碰托福了，于是想着不如先去 GRE 那里碰碰运气。因为离申请季已经不远了，并且还得给托福留时间，于是我直接报了一个月后的考试，打算逼自己速成。
-
-GRE = Verbal + Quantitative + Analytical Writing。其中 Q 只要看得懂题就应该能拿满，考虑失误也应该在 168 以上（虽然我只有 167）。而对于理工科学生来说 AW 上了 3.5 就完事儿。因为我得速成，所以这两样我基本没有花太多时间（但 OG 上的 Q 题目和 AW 的题库多少得花时间去研究一下）。
-
-难搞的是 Verbal。如果有更长的准备时间，那我相信肯定会有更可靠的方案。但因为我只有一个月，我只能靠单词量（再要你命 3000）和长难句语感把 Verbal 分数硬怼上去。我很多时候会出现题目里那段话基本没看懂但就是把选项选对了的情况。
-
-实际上单词量也并没有多大，因为背单词的时间太少了。我用了十天把再要你命 3000 背了三遍，但只背三遍显然不够，很多单词背了就忘了。网上有种说法是 GRE 单词背五遍以下上考场算裸考，那我应该就是皮肤都没绑定直接拿骨架上去考了。在这种时间不够的情况下，我觉得应该优先把六选二等价词给背了（网上可以找到各路机构出的等价词列表）。一方面六选二在填空题里面占比挺高，并且如果在选项里只看到了一对等价词，甚至可以不看题直接选；另一方面从我做机经和考试的情况来看，等价词在别的题型里面也经常出现，我觉得就算只背等价词应该也能应付大部分情况。
-
-除了单词以外，就是长难句看不懂。这时理论上应该怼长难句的语法，但我也没这个时间了，我只能靠多做机经攒语感。网上可以找到各路机构出的机经，但内容应该基本是一样的。我觉得 GRE 就是为了考难而故意把句子写复杂，说是考学术阅读能力，但我就没见过哪篇论文像 GRE 题目那样说话的。写论文应该简单易懂，更严苛一点的人甚至会限制自己每一句话的单词数量。如果真像 GRE 题目那样写论文，审稿人估计会审得鬼火冒。
-
-
-### 结果
-
-简单来说：
-
-- Fall 2020 申了一堆学校，全是 CS master 项目，除了 BU 以外全拒
-  
-  因为 BU 不给 defer，签证开放遥遥无期，我又不想上网课，于是决定 GAP。遂拒了这唯一个录取，把申请推到了 Fall 2021。
-
-- 结果 BU 又给我录了 Spring 2021，签证开放依然遥遥无期，我依然不想上网课，于是又给推了
-
-- Fall 2021 又申了一堆学校，这次除了 CS 还申了 ECE、DS 之类的项目，除了 BU 以外依然全拒
-
-所以如果不是我校连续捞我，我真的每年都没书读...
-
-
-## CPT 和 OPT
-
-5 月拿到了唯一一个录取（...），然后从当时的实习公司离职，开始琢磨出去玩顺便把签证签了的事儿。
-
-关于我为什么 Fall 2021 要上网课的官方说法一直是“签证被 check 没来得及办下来”。这的确是事实，但很大程度上也是因为我 7 月才去签证，如果我 5、6 月就去签证，时间也是来得及的。而不早点去签证是因为我本来就不太想 fall 就去美国 in-person，那时对美国的形势还摸不着头脑所以打算再观望一学期，反正学校允许 Fall 2021 上网课，我就打算 Spring 2022 的时候再去。因此我其实在去签证之前就已经在找未来半年的实习了...
-
-然后我研究了一下 remote 一学期对 CPT 和 OPT 的影响。虽然当时嚷嚷着要读博所以最后 CPT 和 OPT 可能都用不上，但想着有总比没有好。BU MSCS 毕业要求是 32 个学分，大多数课是 4 个学分，也就是说要修 8 门课。主流修法是 332，前两学期每学期 3 门（full-time），最后一学期 2 门（part-time），三学期（一年半）毕业：
-
-- CPT 要求是 full-time 一学年，同时 ISSO 在邮件里表示不管你 remote 还是 in-person 都无所谓，只要 full-time 一年就能申 CPT，所以 CPT 没啥问题
-- OPT 要求是 in-person 一学年，part-time 还是 full-time 无所谓。而我 remote 一学期以后就会去美国 in-person 上一年课（一学期 full-time 一学期 part-time），所以 OPT 也没啥问题
-
-不过现在看来好像 CPT 和 OPT 可能都能用上...
-
-
-## 签证
-
-天平向网课倾斜以后，签证就变得不是那么的迫切，半年以内签下来就行。于是我在排行程时，签证的优先级甚至放在了旅游的后面。约签证的时候大概已经过了高峰期，非常好约，点进领事馆一堆空位，不用天天去领事馆网站上蹲位置也不用上 [tuixue.online/visa](https://tuixue.online/visa/)。
-
-面签约在了上海梅龙镇广场，毕竟在上海待了四年所以在那里签还是更有安全感一点。不过我还是低估了静安区酒店的价格，而且虽然装修风格我很喜欢，但我从没住过房间如此小的酒店，不愧是寸土寸金的静安。
-
-去之前准备了一下[别人面签的时候被问到的问题](https://docs.qq.com/sheet/DRXRTSmlEeWJtT1RW)。他们说绝对不能让 VO 觉得你有移民倾向和对 AI 感兴趣，因此我决定在被问到毕业了想干啥时一口咬定我要回国写前端（我的确认真考虑过这个可能性所以也不能算瞎扯），结果 VO 啥都没问，收完材料就给我 check 了，并让我去中信银行寄护照。上海当时好像都不现场收护照，得邮寄，不过我几个在北京签的同样被 check 了的朋友都直接现场就把护照收了。
-
-关于 F1 签证要带的材料：
-
-- 必须要带的，不带你可能连 VO 都见不到
-
-  - 护照
-  - I-20
-  - DS-160
-  - 签证预约确认信
-  - SEVIS 缴费收据
-  - 签证照
-
-    就是填 DS-160 的时候要上传的那种格式。我并没有被收签证照，但他们说如果领事馆的人认为你 DS-160 上的照片不符合要求的话，就会要求你补交照片。所以还是带上吧，不然就得去重拍然后重新排队。
-
-- 我面签的时候 VO 收了的材料（除了 I-20 和 DS-160 以外） 
-
-  - CV 
-
-    我尽可能省略了 research 的部分，基本写成了一份前端的简历。但 publication 那里我还是不敢省略，因为签证官网上明确要求得写，而且这玩意儿网上是可以查到的，我被 check 倒是无所谓反正我也不急，但要是因为没写必须写的东西给我拒签了就很麻烦了。
-
-  - Study plan
-
-    写想选什么课和毕业后的职业规划（回国写前端）
-
-  - Academic advisor（即 [cpk](https://www.bu.edu/cs/profiles/cpk/)）的简历
-
-  - Offer
-
-- VO 没收但我带了的材料
-
-  - 本科毕业证和学位证
-  - 本科学生证
-  - 本科成绩单
-  - 财产证明
-  - 父母收入证明
-  - 户口本复印件
-
-    觉得被要求出示户口本的可能性也太小了，没有必要冒着弄丢它的巨大风险带原件去，遂复印了一份
-  - 房产证复印件
-
-    基于和户口本一样的理由，复印了一份带走
-
-  - 本科毕设导师（即[赵姐姐](https://sse.tongji.edu.cn/info/1206/3150.htm)）的简历
-  - “感兴趣的硕士导师”的简历
-
-    为了应对“VO 一定要我交硕士导师简历，而我是授课型硕士根本没有导师”的情况，我去随便找了份本系研究方向不敏感并且看年龄应该快退休了的教授的简历
-
-  - TOEFL / GRE 成绩单
-  - 发过的论文
-
-总的来说，把你能想到的材料都带上，谁知道 VO 想看什么。
-
-进领事馆不能带除了纸质材料以外的任何东西，包括手机和包。用来装材料的文件袋得是透明的，我当时带了一个不透明的文件袋，他们也让我扔了。这催生了领事馆旁边的水果店的副业：存包、卖透明文件袋等等，并且你完全不用担心找不到这个店，因为店里的人随时都在领事馆门前吆喝并准备把你带去店里。
-
-面签完出来以后在地图上搜中信银行，发现领事馆马路对面就有一个...就隔条马路还搁这儿邮寄。并且那个中信银行专门有给领事馆寄材料的柜台。我最开始脑子短路还想着回重庆之后再找中信银行寄护照，直到我妈问我：“你为什么不就在上海寄呢？”，我：“你说得对”。
-
-大概 7、8 周之后网上显示 issued 了，一天以后我收到了护照和签证，给的一年签。
-
-
-## 网课
-
-他们说 BU 的课 workload 大，因此我最开始对第一学期一边全职实习一边上三门课有一些担忧，于是我基本是按“听说不难”和“有老本可以啃”的原则来选的课：
-
-- 听说不难：CS 630 Graduate Algorithms、CS 611 Object-oriented Software Principles and Design
-- 有老本可以啃：CS 542 Machine Learning
-
-上完以后的感觉是基本对得起这两个评价，有种白瞎了那么贵的学费的愧疚感。
-
-BU 5xx 和 6xx 的课都是 graduate level 的课程，但 6xx 只要研究生能选，5xx 本科生也能选。我的感受是 5xx 的课学生质量高于 6xx，所以本科生是真的能打。
-
-网课的体验是感觉自己留了个假学。
-
-开始的时候我还会看 recording，后来各种事儿越来越多，工作日下班回到家摸一会鱼就该睡了，周末做做作业处理一下历史遗留问题 commit 一下奇怪的项目就不剩什么时间了。再加上 recording 的质量实在堪忧，尤其是 630，据说老师说的话他们在现场都听不清楚，视频和音频质量也差，老师还不用 PPT 全程黑板上龙飞凤舞的板书，现场的人看黑板都要连猜带蒙。索性后面连 recording 也不看了，作业和考试就靠啃老本和看讲义和教材自学，就这样一学期下来 GPA 倒还行。
-
-这样连上课的感觉都没有了，我感觉我就是在公司打工，然后定期需要去 piazza 上领题目或者项目需求，然后做完它们并传到 Gradescope 上去。
-
-原来以为半期和期末考试的时候需要倒时差，结果老师和 ta 还是很关照在其他时区 remote 的学生的。in-person 和 remote 的人分开考试，remote 的考试时间尽量定在了美东和其他时区的人都能接受的时间。所谓“其他时区”其实基本上也就是北京时间，我记得 remote 的人里，除了 611 有一个用莫斯科时间的俄罗斯人以外，其他全是中国人。所以不会有什么特别离谱的考试时间，但晚上十一二点或者早上六七点考试也还是有点难受的。
-
-半期考试的时间正好在国庆左右，而我国庆的时候跑去深圳玩了。去之前我瞄了一看考试安排，最早的一场是 611，换算成国内时间是在 10.8 凌晨 2 点，于是我心想我完全可以玩完回来再开始复习。于是我开心的跑去深圳了，在深圳那几天我完全没有看过邮箱和 piazza。等我 10.5 回到北京，收了东西洗了澡摸了会儿鱼到了 10.6 凌晨 1 点准备睡了，突然决定看一眼 piazza，然后就发现 611 半期要考两场，一场 theory 一场 practice，10.8 那场是 practice，而 theory 的时间时 10.6 凌晨 2 点。我吓得瞬间清醒，我但凡晚一天回北京就凉了。
-
-其实几天前 cpk 给 remote 的人发了封邮件，说你们可以选择凌晨 2 点考，也可以选择早上 8 点考。过了两三天后 cpk 又给我补了封邮件，说你还没回我你 prefer 的考试时间呢，再不回我就默认你 2 点考了哦。结果我在外面玩没看邮箱，两封都没回。等我看到的时候就是考试前一个小时，我赶紧给 cpk 补了邮件问我现在还能不能把时间调到 8 点。直到 2 点考试开始，cpk 都没有回我，于是完全没复习的我被迫开始体验凌晨 2 点困得不行的时候裸考。后来想想就算调到 8 点，我也得立马睡觉没法复习，那会儿我困得应该根本复习不进去。
-
-10.7 号十一点左右我上床睡觉，定了 10.8 凌晨一点半的闹钟，打算睡两个多小时再起来考试。睡前我让一个那天打算通宵干活的朋友凌晨一点半打个电话给我，以免我没被闹钟吵醒。
-
-结果我还真没被闹钟吵醒，是被她的电话叫醒的。
-
-这又是一个改变命运的决定。
-
-但睡得好好的突然被打断，醒来以后真的太难受了，感觉全身都不对劲，状态还不如直接熬到两点。
-
-
-### CS 630 Algorithms
-
-如前所述，糟糕的录像质量和龙飞凤舞的板书让我几乎没怎么听这门课，我基本靠自己看算法导论（教材）跟完了所有作业和考试。
-
-我选这门课的时候甚至没看 syllabus，因此我对他的期望是“讲一些 Leetcode 或 ACM 会用到的数据结构和算法”，结果这课的内容完全超出了我的老本的范围，所以其实还是学到了一些东西。虽然如此，老师讲课的节奏其实很慢，前半学期就讲了 fft 以及一些 np 问题的近似算法，后半学期讲 np 问题的定义什么的以及概率算法，没了，所以跟起来还是很轻松的。
-
-
-### CS 542 Machine Learning
-
-体验最好的一门课，兼顾了“有足够的收获”和“花不了我多少时间”。
-
-老师第一节课致力于劝退你，比如如果你数学不行就赶紧 drop 吧，比如如果你只是“interested in machine learning”而不是想要“develop new machine learning algorithms”就赶紧 drop 并出门左转 CS 506 吧，吓得我犹豫了两天，但其实上下来完全没有那么离谱。
-
-主要讲 ML 算法，侧重于公式推导角度的理解。DL 只是简单涉及了一点，基本上你会链式法则求导和知道计算图是啥就行了。作业一般分为两部分，一部分是推公式，涉及到的数学也只是求导积分以及基础的线性代数和概率论；另一部分是 coding，题目里已经给你写好了很多代码，你只需要像填空一样填入核心的部分。总的来说感觉 workload 不大。最后一次作业我没有做，用了 drop lowest pset 政策。
-
-快期末了有个 challenge，一个回归问题，让预测房租价格。给了你训练集和验证集，让你在不用任何 ML 或 DL 框架的前提下训个算法出来，然后交上去在没公开的测试集上跑，最后搞个拿 MSE 当指标的 leaderboard 出来。我用了半天速战速决。因为我之前用纯 Numpy 撸过一个 [toy DL 框架](https://github.com/Renovamen/flint)，于是我想也没想就写了个简陋的 autograd 然后直接上 MLP，后来想想老师应该是希望你撸个传统 ML 算法出来而不是用神经网络...我没有对特征做任何预处理，我试了 PCA、normalization、feature selection，得出的结论是效果都没有不作处理好。这个结论有点离谱，因为我肉眼都能看出数据集 7000+ 维的特征里有大量的冗余。但我也没太在意这个，因为指标已经够用了，训练和推理时间也在规定范围内，而我那时候有点忙没想在 challenge 上换太多时间，所以赶紧交上去交差，没再研究特征的事儿。后来听一个用随机森林的同学说，他只用了 30+ 维特征就有了挺好看的效果，我要是只用 30+ 维特征的话效果应该非常难看。不知道是因为我的模型是 MLP，还是因为我没认真调参。
-
-考试也侧重于推公式，难度也不大，感觉期末难度略高于半期难度。考试前老师会发一些练习题，我觉得半期的话，把考前练习做完基本就没问题了。期末跟考前练习倒没有太大关系，但考的东西作业里也都有。期末考试前我算了算分数，发现我考六七十分就能 A，于是考的时候态度很不端正，最后考试成绩不太好看 2333
-
-考试开始的时候监考的 TA 会让你出示 ID，而我显然没有学生卡，并且护照在家里不在北京，因此我两次考试都出示了身份证...不知道如果 TA 不是中国人的话，还认不认身份证...
-
-我不评价老师讲课的水平（考虑到我有好些课都没听，我也没资格评价），但至少我觉得这门课组织得挺好的。即使你有基础，课上提到的 ML 算法你都学过，去这门课上系统的再学一遍也是有收获的。
-
-
-### CS 611 OOD
-
-对我来说最大的收获是把设计模式顺了一遍。虽然我跟人说过“设计模式是同济软院难得值得一听的课”，但其实我本人并没有认真听（其实我本科就没多少课是认真听了的），那门课成绩也挺难看（其实我本科就没多少课的成绩不难看）。因此 611 上下来还是有收获的。
-
-好话到此结束 (╯‵□′)╯︵╘═╛
-
-我 2021 年几乎所有的抱怨和全部的通宵都给了 611，主要是这课的 assignment 非常扯淡。乍一看只是写一个简单的小游戏，实际上要写的细节非常多。虽然只要你以前写过 Java 懂点 OOD 就几乎没有难度，但工作量真的太大了，而且这种没有难度纯堆量的代码对你的能力不会有提升，感觉我就像在被罚抄作业 500 遍。
-
-然后是作业要求，比如虽然作业都得写几十个 class 文件，但要求是你不能分 package，所有 class 文件都要放在同一个文件夹里。当然这个要求的理由是分了 package 以后会加大 grader 运行你的代码的工作量，这我能够理解，但的确会影响写代码的体验。
-
-再来是作业给分，会出现本来能跑的代码，grader 就是给你跑不起来，然后一言不合把 35 分 correctness and usability 扣完的情况，然后你就需要交 re-grade request，甚至去 oh 现场和 TA 对线。使用[生成器](https://patorjk.com/software/taag/)生成的 ASCII art 会被判 cheating，因为“这部分代码不是你自己写的”，我听说这事儿的时候真的非常震惊。
-
-半期考试的 theory 部分，我以为会考更偏向于面向对象~~和设计模式（半期的时候还没讲设计模式）~~ 一点的东西，结果基本在扣 Java 语言本身的细节。而虽然我们一直都知道这课用的是 Java，而且课上也讲了不少关于 Java 的东西，可如你所见 Java 这个词甚至没在课名（Object-oriented Software Principles and Design）里出现过。当然我觉得这一条这也不算这门课的问题，只是我无能狂怒的偷偷吐槽。
-
-2021 年的至暗时刻是，我在写某次作业的时候，due 前的那个晚上通宵通到一半，电脑坏掉了，而我偏偏那一次代码忘了 push 上 Github，也就是没有备份。我当时差点哭出来，字面意义上的差点哭出来。唯一令我欣慰的是虽然那时大半夜，但我依然找到了人哭诉。然后我换了台电脑（还好我又能换的电脑，不然大半夜的我去哪里找电脑），重头开始写。当然不管是 due 前一天才开始极限操作，还是忘了备份代码，都是我而不是这门课的问题，这依然只是我无能狂怒的偷偷吐槽。
-
-一个有意思的事是，美国开始冬令时之后，对国内的我来说就相当于多了一个小时的赶 due 时间，正是多出来的那一个小时让我赶完了上述作业的最后一个功能。本来我都不打算写了，想着扣分就扣分吧，结果一看嘿呀冬令时了还有一个小时时间，又继续赶代码。
-
-总的来说，我认为 BU CS 的研究生都应该远离这门课，会变得不幸。但考虑到为了达到毕业要求，software area 的课必须得选至少一门，而 611 看上去是 software area 里最好过的课，所以好像也避不太开。
-
-
-## 租房
-
-10 月的时候开始琢磨在波士顿租房的事。
-
-我租房就三个要求：
-
-1. 离学校近 
-2. 有 in-unit 的洗衣机烘干机 
-3. 尽量便宜一点
-
-开始找房的时候才发现要满足上述要求太难了。尤其是我 spring 才租房，很多合适的公寓已经没房子了，更加雪上加霜。
-
-首先是位置。我看了地图才意识到“离学校近”是一个非常模棱两可的描述，因为没有说清楚是离学校的哪个位置近。BU 不算一个很有大学氛围的学校，具体来说它没有围墙，教学楼沿着马路排了一排，也就是说它长成一个挺长的长条形（图中红圈）：
-
-![](/img/in-post/2022-01-29/map-1.jpg)
-
-马路上有一条被称为绿线的地铁/电车线（图中绿色的线）穿过，并沿着学校设了几个站。
-
-因此如果想要严格意义上的近，租房的时候就得精确到你经常会去的教学楼。对于使用主流选课策略的 CS 学生来说，你的大多数课会在 GRS（Graduate School of Arts and Sciences）和 CAS（College of Arts and Sciences）上：
-
-![](/img/in-post/2022-01-29/map-2.jpg)
-
-上图同时还标注了我目前知道的几个大型超市以及经常听到的租房地区，原则除了离学校近以外还有离超市近，以保证基本食材不短缺（虽然网购也行）。住 Fenway 那个圈的话离学校基本是最近的，学校大多数地方都是步行距离。甚至离图里最右边的那个 Newburry St（一条商业街）也很近，没事可以去逛逛吃吃。如果住 Allston 那个圈，那我觉得最大的优势是附近有 Super88 这个中国超市，毕竟有的中国特色的东西在美国超市是买不到的。Super88 里还有一个店卖麻辣香锅，但我无法承认那是麻辣香锅，我觉得连麻辣烫都不能算...不过离学校就略远了一些，但做绿线去学校也很方便。
-
-我看到的大多数房子都很古老，应该有几十年了，相比之下我当时在北京租的九几年的“老房子”显得意外的年轻。很多房子都是在古老的外壳里翻新，装入了现代化的东西。我刚来波士顿的时候，感觉这里有种“年代感和现代感并存”的感觉，现在想来也就是上述情景的高情商说法。
-
-查尔斯河对面是 Cambridge，那里有让人闻风丧胆的 Harvard 和 MIT。我同学说那边的房子会新一点，所以如果有一天世界线剧变导致我居然能去河对面读博...算了没必要立不可能发生的 flag。
-
-好了也就是这样了，我才刚来没几天也写不出更多的东西了。
-
-
-## 入境美国
-
-跌宕起伏一波三折命途多舛（我知道这三个词里面起码有一个用法不对），主要是机票。
-
-### 机票
-
-找到了一个跟我一起飞的同学，有人跟你一起命途多舛（我好像用了那个不对的词）多少让人稍微安心一些。我们准备飞美国的时候，奥密克戎开始席卷。于是我们的第一趟航班（国泰，香港-波士顿）因为疫情熔断被取消了。本着“尽量不在第三国中转”的原则，我们买了第二趟航班（国航+美联航，深圳-洛杉矶-波士顿），其中深圳和洛杉矶中转的时候行李都不是直挂，而重新托运。然后起飞前不到一周，它又因为疫情熔断被取消了。那时已经没有不在第三国中转的航班了，于是我们买了第三趟（日航，大连-东京-波士顿）。
-
-再取消我们就得买中转很多次的票了，令人欣慰的是它没有。在买去大连的机票的时候，我才知道重庆居然没有直飞大连的票，要么经停要么要转机，重庆果然还不算大城市。最后买了在大同经停的票。
-
-我爸妈送我去了大连，结果他们刚从大连回重庆，大连就有人确诊并且去过机场，于是他们健康码就黄了 😂
-
-
-### 出境体检
-
-我以为我拿着学校 offer 和签证就可以免体检费，国际旅行卫生保健中心的人一开始也是那么以为的，并让我去复印了签证。结果后面他们发现我拿的一年签，我又上了一学期网课，于是签证就不满一年了。而免体检费需要签证有效期满一年，最终我还是交了钱。
-
-我就应该暑假一拿到签证就去体检。
-
-
-### 核酸
-
-美帝需要出发前一天内的英文核酸证明，上面得写自己的护照号和护照上的英文名。因此需要找到本地的能当天出英文核酸结果的检测机构，并拿着护照（而不是身份证）去挂号。
-
-亲测重庆能当天出英文结果的医院有：
-
-- 重庆北部宽仁医院
-- 重庆医科大学附属第一医院金山医院
-
-出于慎重，我出发前一天去这两个医院都做了核酸，这样就算其中一个掉了链子也还有另一个能补救。医院的官方说法是 6-12 小时出结果，但实际上我做完三个多小时就出结果了。打印机上直接出中英文双语核酸证明，保险起见可以去找前台盖个章。
-
-还问了一些别的医院，重庆市妇幼保健院当天能出结果但不支持英文，重庆国际旅行卫生保健中心支持英文但第二天才能出结果。
-
-
-### 其他
-
-备份并清空了电脑里的文件和手机里的微信 QQ 聊天记录。这时发现了微信相比 QQ 少有的优点之一：微信 Mac 版有备份功能，但 QQ Mac 版没有，因此我还得去 Windows 本上备份 QQ。
-
-这很不好，希望腾讯好自为之。
-
-虽然最后并没有进小黑屋，更没有人来查我的电子设备就是了。
-
-淘宝了一张 T-Mobile 的电话卡，15 天内无限通话和流量。
-
-带了一些感冒发烧消炎腹泻药，以及传说中管用的莲花清瘟。其实这些基本都能在美国随便买到（包括连花清瘟）或有替代品，不过有的消炎药在美国算处方药，不太好买。
-
-
-### 飞机
-
-值机的时候要出示疫苗接种证明（WHO 认证的国产疫苗只有国药和科兴，也就是说打智飞是登不了机的）和核酸证明。接种证明拿着身份证去接种点让他们开一份就行。这两样其实只有国内值机时看，美国入境的时候完全不看。值机柜台的人给了份[美帝 CDC 要求入境的人填的文件](https://www.cdc.gov/quarantine/pdf/Combined-Passenger-Attestation-Amended-Testing-Order-12-02-2021-p.pdf)，告诉你在东京中转的时候填完并上交。
-
-值机排队的时候看到了不少拿着乐器箱的人，盲猜是伯克利音乐学院的富豪学生，~~他们的气质跟我们这种学计算机的有璧~~。
-
-~~日航的空乘好好看啊，我觉得她们的妆发和服装很好。~~
-
-大连-东京那一段，空乘全程日语，我全程只听懂了阿里阿多 cosine mass。她们检查来检查安全带的时候我们都只能连猜带蒙（其实我至今不确定她当时说的话是不是要检查安全带的意思）。飞机餐好吃，鳗鱼饭，里面有虾，我觉得是能放在店里卖的程度。
-
-到了东京以后，入境日本的人先下飞机，然后中转的人再下去。要重新安检（于是我又得翻出我的手机们电脑们充电宝们），然后有工作人员指导你填 CDC 那张表，填完以后排队去一个机器那里刷脸，刷完以后去登机口等着。
-
-~~日本机场的马桶还挺高级的。~~
-
-东京-波士顿那一段，看上去乘客也大多是中国人，而且人挺少的还，好多人甚至能躺在三四个并排的座位上睡觉。这一段的空乘就说英文了。我上飞机前决定全程不摘口罩不吃东西，空乘拿着菜单让我点餐，我：“不我不吃东西（坚定）”。
-
-然后空乘拿着哈根达斯问我冰淇淋也不要吗。
-
-我：“来一个谢谢！”
-
-真香。
-
-~~啊我喜欢日航，如果没有疫情能放开吃的话也太幸福了。~~
-
-
-### 入境
-
-一个比我先到美国的洛杉矶入境的同学被小黑屋了一个半小时，所以我以为我这种学计算机的签证有效期不到一年的以前没入境过美国的中国人铁定小黑屋了。
-
-结果入境意外的顺利，给了对面护照和 I-20，他就问了一句你带了多少现金，然后就盖入境章放我进去了。
-
-我：？
-
-领完行李出去前被一个工作人员拦了下来，被问了“从哪儿来”“带了多少现金”“带熟食生鲜了吗”，回答完就放人了。
-
-彻底入境，顺利得有些恍惚。
-
-然后我们去打 Uber，可能是第一次在洛干打 Uber 没有经验，司机到了以后我们一直没有找到他...然后订单就被取消了还扣了我们 5 美金。~~写到这里的时候我才惊觉我忘了付打车钱给我同学，我起床以后就给嘤。~~
-
-然后停车场一个老哥问我们上不上车，即使是在国内这也显得很可疑，但那天是波士顿入冬以来最冷的一天（在当时是最冷的，现在已经有更冷的了），-11 度，在寒冷的压迫下我们还是上了老哥的车。
-
-老哥热情的尝试和我们聊天，但我们的听力~~不怎么样~~还没有适应美帝环境所以并没有怎么听懂。
-
-
-## 酒店
-
-入境以后已经是晚上了，公寓下班了没法 check-in，而且就算 check-in 了里面也啥也没有，所以我去 [Booking.com](https://booking.com/) 上定了两天酒店，用 [Expedia](https://www.expedia.com/) 或者 [Airbnb](https://www.airbnb.com/) 也行。
-
-美国酒店和国内的一些不同：
-
-- 没有拖鞋
-
-  别说酒店了，美国超市里都没有拖鞋卖，我拖鞋都是网购的
-
-- 没有牙具
-
-  我去超市买了一套
-
-- 没有烧水壶
-
-  但有胶囊咖啡机（咖啡免费），所以一定要喝热水的话可以用咖啡机来烧水，不过一次只能烧一小杯，而且大概会有咖啡味...
-
-- 会收押金
-
-
-## 购物
-
-我不知道美国其他地方是什么行情，但反正在波士顿，从公寓 leasing office 直接租到房子几乎都是不带软装的，包括床架、床垫、桌子，都没有。想租到有这些家具的房子估计只能找个人房东或者转租。
-
-所以这些全得自己买。为了减少你因为没有床而住酒店或睡地板的时间，最好提前卡着送货时间网购（如果打算买二手或者去家具店现场拉货的话就当我没说）。而菜鸡如我，虽然提前网购了，但我把 ship 理解成了收货而不是发货（收货是 deliver），因此依然买晚了。
-
-我就说美帝物流怎么会那么快。
-
-所以我还是睡了几天地板。我去超市买了一块最便宜的像毯子的东西，还挺厚的，很适合铺地上睡觉。在被子到之前只能调高暖气盖着衣服睡。这样睡了几天我觉得睡地板还不错，~~好像没有床也行~~。
-
-然后去超市买了一些生活必需品。一些中国特色的东西如酱醋老干妈饺子包子等需要去 Super88 买，Super88 离我住的地方还挺远的得坐绿线。去了两趟后发现可以网购，遂没再去过。
-
-
-## 吃
-
-吃过几次普通美国餐厅（即卖的是汉堡三明治披萨沙拉炒面等普通美国食物，算了我也不知道该怎么表达），觉得特点有：
-
-- 贵
-
-  当然是按国内物价来看，虽然这样并没有意义
-
-- 量大管撑
-
-  我从没吃过那么大的三明治，可以顶两顿
-
-- 咸
-
-  美国人买盐是不要钱吗，咸导致吃前两口的时候感觉还行，吃到后面就因为太咸而难吃了
-  
-
-而我有如下特点：
-
-- 好吃：无法接受每顿都吃不好吃的食物
-- 懒做：不想在吃饭这件事上花很多时间
-- 贫穷：字面意思
-- 无能：在来美国前不会也没做过饭
-- 不端：不喜欢做饭
-
-好吃和贫穷让我没法每顿都在外面吃，只能考虑自己做，而懒做无能和不端让我决定采用极简做饭法则。
-
-首先，我倒目前为止只有平底锅、锅铲、电饭煲、碗、勺子、叉子、筷子各一个，其中筷子还是我从国内带来的，其他是我到波士顿的第二天去超市随便抓的。反正菜鸡如我也没必要糟蹋更多的厨具。
-
-其次，我采用的主要做饭方式是：
-
-- 路线一
-
-  1. 把葱姜蒜洋葱切了扔进锅里炒
-  2. 随机抓一些素菜扔进锅里炒
-  3. 随机抓一些肉扔进锅里炒，没那么懒的时候会先用随机的调料把肉腌一下
-  4. 随机往放入调料和水，继续炒
-  5. 放入煮好的饭，继续炒
-
-- 路线二
-
-  1. 往电饭煲里放入米、水、和随机的调料
-  2. 往电饭煲里放入随机的素菜、肉和葱姜蒜
-  3. 按煮饭键
-  4. 搅拌电饭煲里的物品
-
-该方式是随机游走而不是马尔可夫过程。
-
-这样搞下来还挺好吃的，不过我觉得我总有一天会吃腻，所以在吃腻之前我得学会别的方法。
-
-
-## 行
-
-目前除了走路和打过两次 Uber 以外就是地铁（绿线），肥宅也没去过太远的地方。
-
-波士顿地铁上车刷票，只要上车就是 2. 几美金，坐一站是那么多钱，坐 n 站也是那么多钱。可以在地铁站买单程票，也可以搞张地铁卡并往里面充钱。地铁卡有两种：
-
-- Charlie Ticket：纸质的，买的时候往里面存钱，钱用完就不能继续往里充钱了，这张卡就没用了得扔掉。因此如果你最后剩了一点不够一张单程票的钱，应该就相当于浪费掉了。可以在超市比如 Star Market 里买到，我搞了一张这个将就用。
-- Charlie Card：塑料的，可以重复充钱并一直用。好像得去某些地铁站找工作人员要，我还没试过。
-
-绿线看上去真的古老，就像（实际上应该也的确是）几十年前的东西。站台没有护栏，我随时可以冲到或被人推到轨道上去躺着，这让我觉得以后还是抱紧广告牌等地铁比较好。并且它跑得贼慢，我觉得我骑车都比它快。
-
-
-## 天气
-
-我只看过波士顿的冬天，觉得可以对标大连的气候。当然这句话很不负责，因为我只去过一次大连（飞美国那次），待了不到一天。但我的确觉得它们有很多相似的地方，比如纬度都很高（波士顿更高一点）、都在一个国家的东北、冬天都冷且干、都沿海因此气候也会受海洋影响（就是沿海这一点让我觉得国内好像只有大连能对标）。
-
-温度一般在零下几度，极端一点的时候会变成零下十几度。不知是不是我的错觉，这边零下几度的时候我并没有觉得比重庆冷多少，我在重庆怎么穿在这边还是怎么穿。而零下十几度的时候，我会选择不出门。
-
-
-## 其他
-
-社交量还是太低了。虽然还是比我本科的时候好太多了，但量还是不够，而且大多数社交都是在网上。
-
-我知道 connection 大概是跟能力同等重要甚至比能力更重要的东西，但我对社交的抗拒惰性和不喜欢大概已经根深蒂固很难克服。
-
-希望以后会好一点吧。
Index: blog/posts/2019-04-03-racf-experiment.md
===================================================================
diff --git a/blog/posts/2019-04-03-racf-experiment.md b/blog/posts/2019-04-03-racf-experiment.md
deleted file mode 100644
--- a/blog/posts/2019-04-03-racf-experiment.md	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
+++ /dev/null	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
@@ -1,833 +0,0 @@
----
-layout: Post
-title: "RACF 实验"
-subtitle: 'RACF Experiments'
-author: Renovamen
-date: 2019-04-03
-headerImage: /img/in-post/2019-04-03/header.png
-permalinkPattern: /post/:year/:month/:day/:slug/
-tags:
-  - 主机
----
-
-对我认为的本科最难的课（2333）第一次实验的流水账式记录。
-
-希望早日脱离大型机的苦海，阿门。
-
-<!-- more -->
-
-## 1. 创建组
-
-### 1.1 组的结构
-
-![](/img/in-post/2019-04-03/racf-2.1.png)
-
-
-
-### 1.2 登陆 TSO
-
-以 RACFLAB 组管理员身份登陆TSO：
-
-1. 以 ST016 用户身份登录 TSO，进 ISPF；
-
-2. "P" $\rightarrow$ "6"（或直接"P.6"）
-
-3. 使用 `LU` RACF 命令查看 ST016 的属性
-
-   ```
-   LU ST016
-   ```
-
-   
-
-### 1.3 在 RACFLAB 下定义子组
-
-利用 RACF 命令定义以下子组：
-
-- 定义 DIV16ADM 用户管理组（相当于公司人事部门），RACF 命令：
-
-  ```
-  ADDGROUP DIV16ADM OWNER(RACFLAB) SUPGROUP(RACFLAB)
-  ```
-
-- 定义 DIV16FUN 功能组（相当于公司各职能部门），后继实验将在该组下定义各个子功能组，RACF 命令：
-
-  ```
-  ADDGROUP DIV16FUN OWNER(RACFLAB) SUPGROUP(RACFLAB)
-  ```
-
-- 定义 DIV16RES 资源组（为有机组织和保护系统资源—包括数据集 / CICS 交易 / 系统和用户程序等资源—而设立的组），后继实验将在该组下定义各个子资源组，RACF 命令：
-
-  ```
-  ADDGROUP DIV16RES OWNER(RACFLAB) SUPGROUP(RACFLAB)
-  ```
-
-
-
-利用 RACF 命令查看新建的组进行验证：
-
-```
-LG DIV16ADM
-LG DIV16FUN
-LG DIV16RES
-```
-
-
-
-### 1.4 在 DIV16FUN 下定义子组（功能组）
-
-利用 RACF 命令定义以下子组：
-
-- 定义 FUN16PRD 功能组，该组将用于对生产系统数据集（Production Data Sets）的访问进行集中授权（即如果该组对生产系统数据集有访问权限，该组的成员将自动继承这一权限），RACF 命令：
-
-  ```
-  ADDGROUP FUN16PRD OWNER(DIV16FUN) SUPGROUP(DIV16FUN)
-  ```
-
-- 定义 FUN16TST 功能组，该组将用于对测试系统数据集（Test Data Sets）的访问进行集中授权（即如果该组对测试系统数据集有访问权限，该组的成员将自动继承这一权限），RACF 命令：
-
-  ```
-  ADDGROUP FUN16TST OWNER(DIV16FUN) SUPGROUP(DIV16FUN)
-  ```
-
-
-
-### 1.5 在 DIV16RES 下定义子组（资源组）
-利用 RACF 命令定义以下子组（RACF 中数据集 Profile 的 HLQ 必须是 RACF 系统中的一个用户或者组，这里为即将要保护的数据集 RES16PRD.* 和 RES16TST 定义 2 个子组）：
-
-- 定义 RES16PRD 资源组，该组将用于保护生产系统的数据集。RACF 命令：
-
-  ```
-  ADDGROUP RES16PRD OWNER(DIV16RES) SUPGROUP(DIV16RES)
-  ```
-
-- 定义 RES16TST 资源组，该组将用于保护测试系统的数据集。RACF 命令：
-
-  ```
-  ADDGROUP RES16TST OWNER(DIV16RES) SUPGROUP(DIV16RES)
-  ```
-
-
-
-### 1.6 查找组 Profile 
-
-```
-SEARCH CLASS(GROUP) MASK(DIV16)
-```
-
- 
-
-
-&nbsp;
-## 2. 用户管理
-
-![](/img/in-post/2019-04-03/racf-3.1.png)
-
-### 2.1 新建用户
-
-1. 在不太了解用户需要什么权限的情况下，一般只给出最低权限，利用 RACF 命令完成以下设置：
-   1. 指定用户的默认组为 DIV16ADM 
-   2. 为用户指定初始密码 
-   3. 考虑为用户指定 OWNER 
-   4. 新增以下用户: 
-      1. TSO1601  for user Janet Smith 
-      2. TSO1602  for user Robert Anderson 
-      3. TSO1603  for user Leslie Brown 
-      4. TSO1604  for user Arthur Fielding 
-      5. TSO1605  for user Susan Johnson
-
-   ```
-   ADDUSER TSO1601 OWNER(DIV16ADM) DFLTGRP(DIV16ADM) PASSWORD(PASS)
-   # 以此类推
-   ```
-
-2. 查看用户是否建立成功
-
-   ```
-   LU TSO1601
-   ```
-
-   查看用户的 TSO 段是否有内容
-
-   ```
-   LU TSO1601 TSO
-   ```
-
-3. 如果用户 Profile 没有指定 TSO 段的内容，用户将无法顺利登陆 TSO 系统，需要为用户指定 TSO 段信息
-
-   ```
-   ALU TSO1601 TSO(PROC(IKJDB2) ACCTNUM(#ACCT) SIZE(4096))
-   ```
-
-4. 用户登陆 TSO 之后，如果要进入 ISPF 面板系统，首次进入 ISPF 系统时系统会自动为用户建立几个编目的数据集，通常普通用户的文件无法在主机系统主目录（Master Catalog）中进行编目，所以，要实现为新用户创建好用户目录（User Catalog）和别名（Alias）。
-
-   ```
-   DEFINE ALIAS(NAME(TSO1601) RELATE('CATALOG.UCAT.STGRP'))
-   ```
-
-   在 OPTION3.4 中 DSN Level 输入 TSO1601 回车，看是否显示其 "ALIAS"，如果出现类似下面的结果则表明 ALIAS 创建成功：
-
-   ```bash
-   DSLIST - Data Sets Matching TSO1601                       Row 1 of 3
-   
-   Command - Enter "/" to select action           Message        Volume
-   ---------------------------------------------------------------------
-   TSO1601                                                 *ALIAS
-   ************************ End of Data Set list ***********************
-   ```
-
-   
-
-
-### 2.2 重置用户密码
-
-当用户忘记密码的时后需要管理员 ST016 为该用户重新指定一个初始密码。
-
-场景：Janet Smith（TSO1601）遗忘了密码：
-
-```
-ALU TSO1601 PASSWORD(PASS)
-```
-
-
-
-### 2.3 Revoke 用户
-
-当用户帐号暂时不用的时候，安全起见应该将该帐号挂起（Revoke）。
-场景：Arthur Fielding（TSO1604）将会出差一段时间，在这段时间应将该用户的帐号挂起：
-
-```
-ALU TSO1601 REVOKE
-```
-
-
-
-### 2.4 Resume 用户
-
-当挂起的用户帐号需要重新启用的时候，应该及时地将帐号 Resume。
-场景：Arthur Fielding（TSO1604）出差回来，希望能够继续使用以前的帐号：
-
-```
-ALU TSO1601 RESUME
-```
-
-
-
-### 2.5 Search 查找
-
-使用 Search 命令查找以上新建的用户 Profile
-
-```
-SEARCH CLASS(USER) MASK(TSO1601)
-```
-
-
-
-### 2.6 将用户关联到组
-
-RACF 中给用户访问资源权限的最佳方法是将用户关联到可以访问这些资源的组中，这些组称为功能组（Functional Group）。
-
-- 将用户 Arthur Fielding（TSO1604）连接到组 FUN16PRD，实现其对生产数据集的访问：
-
-  ```
-  CONNECT TSO1604 GROUP(FUN16PRD)
-  ```
-
-- 将用户 Susan Johnson（TSOxx05）连接到组 FUN16TST，实现其对测试数据集的访问：
-
-  ```
-  CONNECT TSO1605 GROUP(FUN16TST)
-  ```
-
-
-
-### 2.7 验证用户是否关联到组
-
-```
-LU TSO1604
-LU TSO1605
-LG FUN16PRD
-LG FUN16TST
-```
-
-
-
-
-&nbsp;
-## 3. 分散式 RACF 安全管理
-
-**目的**：实现 RACF 中的管理权限下放（Delegation）
-
-**内容**：新建几个管理员用户，其中一个管理员负责用户安全的管理，一个管理员负 责将用户连接到功能组，另外一个管理员管控制对数据集资源的访问：
-
-|USER|AUTHORITY|
-|-------|----------------|
-|TSO1601|group special for DIV16ADM|
-|TSO1602|connect authority for FUN16PRD & FUN16TST|
-|TSO1603|create authority for RES16PRD & RES16TST|
-
-
-
-![](/img/in-post/2019-04-03/racf-4.1.png)
-
-
-
-### 3.1 用户身份定位
-
-- TSO1601（Janet Smith）：该管理员将对 DIV16ADM 组用户的安全进行管理，包括为用户重置密码，挂起和启用用户：
-
-  ```
-  CONNECT TSO1601 GROUP(DIV16ADM) SPECIAL
-  ```
-
-- TSO1602（Robert Anderson）：该管理员可以将用户关联到 DIV16FUN 组下的子功能组中，以实现用户对特定数据的访问权限：
-
-  ```
-  CONNECT TSO1602 GROUP(FUN16PRD) AUTHORITY(CONNECT)
-  CONNECT TSO1602 GROUP(FUN16TST) AUTHORITY(CONNECT)
-  ```
-
-- TSO1603（Leslie Brown）：该管理员可以为 RES16PRD 和 RES16TST 组数据集创建数据集 PROFILE，以控制用户对组数据集的访问：
-
-  ```
-  CONNECT TSO1603 GROUP(RES16PRD) AUTHORITY(CREATE)
-  CONNECT TSO1603 GROUP(RES16TST) AUTHORITY(CREATE)
-  ```
-
-
-
-### 3.2 测试
-
-测试步骤1的功能是否实现：
-
-1. 以 TSO1601 身份登陆 TSO，尝试修改用户密码等
-
-   ```
-   ALU TSO1602 PASSWORD(PASS)
-   ```
-
-2. 以 TSO1602 身份登陆 TSO，将 TSO1601 用户关联到 FUN16PRD 和 FUN16TST：
-
-   ```
-   CONNECT TSO1601 GROUP(FUN16PRD) 
-   CONNECT TSO1601 GROUP(FUN16TST)
-   ```
-
-3. 以 TSOxx02 身份登陆 TSO，将 TSO1601 从 FUN16PRD 和 FUN16TST 组中移走： 
-
-   ```
-   REMOVE TSO1601 GROUP(FUN16PRD)
-   REMOVE TSO1601 GROUP(FUN16TST)
-   ```
-
-
-
-
-&nbsp;
-## 4. 数据集保护 I
-
-**目的**：实现对用户数据集和组数据集的保护。
-
-**内容**：首先保护用户数据集，然后对生产数据集和测试数据集进行保护，然后进行授权后的验证。
-
-为了简化实验，RES16PRD 和 RES16TST 组既是 Data Control Group，也是 Resource Onwership Group。 
-
-
-
-### 4.1 保护数据集
-
-保护以下用户的数据集，保护准则：只有用户本身可以访问自己的数据集，其他人都不能访问。（用户的数据集是指以用户名为 HLQ 的所有数据集）
-
-- TSO1601  for user Janet Smith 
-
-- TSO1602  for user Robert Anderson 
-
-- TSO1603  for user Leslie Brown 
-
-- TSO1604  for user Arthur Fielding 
-
-- TSO1605  for user Susan Johnson 
-
-以 TSO1601 身份登陆 TSO 然后执行 RACF 命令：
-
-```
-ADDSD 'TSO1601.**' UACC(NONE) 
-ADDSD 'TSO1602.**' UACC(NONE) 
-ADDSD 'TSO1603.**' UACC(NONE) 
-ADDSD 'TSO1604.**' UACC(NONE) 
-ADDSD 'TSO1605.**' UACC(NONE) 
-```
-
-
-
-### 4.2 查看 PROFILE
-
-查看步骤1创建的用户数据集PROFILE：
-
-```
-LISTDSD DA('TSO1601.**') ALL
-LISTDSD DA('TSO1602.**') ALL
-LISTDSD DA('TSO1603.**') ALL
-LISTDSD DA('TSO1604.**') ALL
-LISTDSD DA('TSO1605.**') ALL
-```
-
-
-
-### 4.3  定义 RPOFILE + 赋 ALTER 权
-
-定义RES16TST组数据集的RPOFILE。在前面的实验中，TSO1603 被指定为 RES16PRD 和 RES16TST 的 Create 用户，以拥有对这 2 个组的数据集的保护权限。
-
-1. 以 TSO1603 登陆 TSO，对 RES16TST 数据集进行以下保护：
-
-   - Audit all unsuccessful accesses (Hint: AUDIT)
-
-   - Make the owner TSO1603 (Hint: OWNER)
-
-   - No other users or groups should have access (Hint: UACC) 
-
-   ```
-   ADDSD 'RES16TST.**' AUDIT(FAILURES) OWNER(TSO1603) UACC(NONE)
-   ```
-
-   
-
-   修改上面定义的 `RES16TST.**` PORFILE的访问列表，给FUN16TST组赋予ALTER访问权限：
-
-   ```
-   PERMIT 'RES16TST.**' ID(FUN16TST) ACCESS(ALTER)
-   ```
-
-   
-
-2. 对 RES16PRD 数据集进行以下保护：
-
-   - Audit all unsuccessful accesses (AUDIT)
-
-   - Audit successful accesses at UPDATE and higher (AUDIT) 
-
-   - Make the owner TSO1603 (OWNER)
-
-   - No other users or groups should have access (UACC) 
-
-   ```
-   ADDSD 'RES16PRD.**' AUDIT(FAILURES SUCCESS(UPDATE)) OWNER(TSO1603) UACC(NONE)
-   ```
-
-   
-
-   修改上面定义的 `RESxxPRD.**` PORFILE的访问列表，给FUN16PRD组赋予ALTER访问权限：
-
-   ```
-   PERMIT 'RES16PRD.**' ID(FUN16PRD) ACCESS(ALTER)
-   ```
-
-
-
-### 4.4 验证
-
-确定组数据集 PROFIEL 是否创建并按照预定的要求保护成功
-
-```
-LISTDSD DATASET('RES16TST.**') ALL
-LISTDSD DATASET('RES16PRD.**') ALL
-```
-
-
-
-### 4.5 创建组数据集
-
-以 ST016 用户登陆 TSO，创建 RES16TST 和 RES16PRD 组数据集：
-
-1. 创建 ALIAS：RES16TST 和 RES16PRD
-
-   ```
-   DEFINE ALIAS(NAME(RES16TST) RELATE(CATALOG.UCAT.STGRP))
-   DEFINE ALIAS(NAME(RES16PRD) RELATE(CATALOG.UCAT.STGRP))
-   ```
-
-2. 测试是否成功
-
-   在 OPTION 3.4 中 DSN Level 分别输入 RES16TST**、**RES16PRD，回车，看是否显示其 Alias。
-
-
-
-以 TSO1603 登陆 TSO 并创建组数据集：
-
-创建一个顺序数据集 RES16PRD.DATA (RECFM=FB, LRECL=80) 和 RES16TST.DATA (RECFM=FB, LRECL=80) 
-
-```
-                        Allocate New Data Set
-Data Set Name  . . . : RESxxPRD.DATA
-Management class . . .       (Blank for default management class)
-Storage class  . . . .       (Blank for default storage class)
- Volume serial . . . .       (Blank for system default volume) **
- Device type . . . . .       (Generic unit or device address) **
-Data class . . . . . .       (Blank for default data class)
- Space units . . . . . TRKS  (BLKS, TRKS, CYLS, KB, MB, BYTES or RECORDS)
- Average record unit         (M, K, or U)
- Primary quantity  . . 1     (In above units)
- Secondary quantity    1     (In above units)
- Directory blocks  . .       (Zero for sequential data set) *
- Record format . . . . FB
- Record length . . . . 80 
- Blocksize   . . . . . 
- Data set name type :        (LIBRARY, HFS, PDS, or blank)  *
-                             (YY/MM/DD, YYYY/MM/DD
- Expiration date . . .        YY.DDD, YYYY.DDD in Julian form
-Enter "/" to select option    DDDD for retention period in days
-   Allocate Multiple Volumes  or blank)
-
-( * Specifying LIBRARY may override zero directory block)
-
-( ** Only one of these fields may be specified)
-```
-
-
-
-### 4.6 验证
-
-- 验证 TSO1604 访问 RES16PRD 组数据集：成功访问；
-
-- 验证 TSO1604 访问 RES16TST 组数据集：拒绝访问；
-- 验证 TSO1605 访问 RES16TST 组数据集的保护：成功访问。
-
-- 以 TSO1601 登陆，删除 RES16PRD 打头的数据集（如 `RES16PRD.DATA`）
-
-  保留 TSO1601 登陆的 Session，再打开一个新的 Session，以 TSO1603 登陆 TSO，修改 `RESxxPRD.**` Profile，给 TSO1601 赋 ALTER 权：
-
-  ```
-  PERMIT 'RES16PRD.**' ID(TSO1601) ACCESS(ALTER) 
-  ```
-
-  测试：
-  - 再尝试用 TSO1601 用户删除 `RES16PRD.DATA`
-  - TSO1601 重新登陆后再尝试删除 `RES16PRD.DATA`
-
-
-
-
-&nbsp;
-## 5. 数据集保护 II
-
-目的：实现对用户数据集和组数据集的保护
-
-内容：创建数据集，确定创建数据集需要的权限，然后建立 Generic PROFILE 对数据集进行保护，最后对 PROFILE 的 Warning 状态进行理解和配置，并使用 LISTDSD 命令确定最佳匹配 PROFILE 和确定 Generic PROFILE 所保护的数据集范围。
-
-
-
-### 5.1 创建全匹配 PROFILE
-
-为 RES16PRD.DATA 创建全匹配 PROFILE。以 TSO1603 登陆（RES16PRD 组 CREATE 特权人员，即数据管理人员），为 `RES16PRD.DATA` 创建一个全匹配的 PROFILE 进行保护：
-
-```
-ADDSD 'RES16PRD.DATA' UACC(READ)
-```
-
-
-
-### 5.2 打开 Warning 状态
-
-以 TSO1603 登陆，把 `RES16TST.**` PROFILE 的 Warning 状态打开：
-
-```
-ALTDSD 'RES16TST.**' WARNING
-```
-
-测试：以 TSO1604 登陆，浏览 `RES16TST.DATA` 数据集
-
-
-
-### 5.3 关闭 Warning 状态
-
-以 TSO1603 登陆，把 `RES16TST.**` PROFILE 的 Warning 状态关闭：
-
-```
-ALTDSD 'RES16TST.**' NOWARNING
-```
-
-测试：以 TSO1604 登陆，浏览 `RES16TST.DATA` 数据集
-
-
-
-### 5.4 UPDATE 权限
-
-TSO1603 登陆。假设 `RES16PRD.NEWAPPL.FINANCE.DATA` 和 `RES16PRD.NEWAPPL.HR.DATA` 是一个新应用系统的 2 个数据集，FUN16TST 组需要对这 2 个数据集有 UPDATE 权限，而不能对其他应用系统的数据集有操作权限。注意，FUN16PRD 组仍然需要对所有的 RES16PRD 数据集保留原有的操作权限。
-
-```
-ADDSD 'RES16PRD.NEWAPPL.**' UACC(NONE) FROM('RES16PRD.**')
-PERMIT 'RES16PRD.NEWAPPL.**' ID(FUN16TST) ACC(UPDATE)
-```
-
-
-
-检测哪一个 PROFILE 在保护 `RES16PRD.NEWAPPL.FINANCE.DATA` 和 `RES16PRD.NEWAPPL.HR.DATA`：
-
-```
-LISTDSD DATASET('RES16PRD.NEWAPPL.FINANCE.DATA') GEN
-LISTDSD DATASET('RES16PRD.NEWAPPL.HR.DATA') GEN
-```
-
-
-
-检测一个 Generic PROFILE `RES16PRD.**` 保护了那些数据集：
-
-```
-LISTDSD DATASET('RES16PRD.**') DSNS
-```
-
-
-
-
-&nbsp;
-## 6. 保护 TSO 资源
-
-目的：授权用户登录 TSO
-
-内容：该实验将首先为 AP（Application Programmer）和 SP（System Programmer）用户建立组结构，然后为 TSO 的登陆过程（TSOPROC）和用户帐号（ACCTNUM建立一些通用资源 PROFILE 进行保护，接着新增 AP/SP 用户 PROFILE，对 TSO 段进行赋值，并对他们授权访问 TSO。
-
-组结构：
-
-![](/img/in-post/2019-04-03/racf-7.1.png)
-
-
-
-### 6.1 创建组结构
-
-1. 在 DIV16FUN 下创建子组 FUN16AP
-
-   ```
-   ADDGROUP FUN16AP OWNER(DIV16FUN) SUPGROUP(DIV16FUN)
-   ```
-
-2. 在 DIV16FUN 下创建子组 FUN16SP
-
-   ```
-   ADDGROUP FUN16SP OWNER(DIV16FUN) SUPGROUP(DIV16FUN)
-   ```
-
-3. 在 DIV16RES 下创建子组 RES16TSO，用以管理 TSO 资源授权
-
-   ```
-   ADDGROUP RES16TSO OWNER(DIV16RES) SUPGROUP(DIV16RES)
-   ```
-
-
-
-### 6.2 新增用户
-
-新增 AP 和 SP 用户，这些用户需要访问TSO
-
-1. 新增 SP 用户 TSO1607，要求如下: 
-
-   - OWNER和默认组应该是DIV16ADM
-
-   - 可以登陆TSO 
-
-     1. 账户使用 ACCT#Sxx
-     2. 登陆过程使用 PROC#Sxx 
-     3. Region 大小为 4096 
-
-   ```
-   ADDUSER TSO1607 OWNER(DIV16ADM) NAME('SYSTEM PROGRAMMER') DFLTGRP(DIV16ADM) PASSWORD(123456)
-   
-   ALU TSO1607 TSO(PROC(IKJDB2) ACCTNUM(#ACCT) SIZE(4096) COMMAN(ISPF))
-   
-   CONNECT TSO1607 GROUP(FUN16SP)
-   ```
-
-
-
-2. 新增 AP 用户 TSO1608，要求如下: 
-
-   - OWNER和默认组应该是DIV16ADM
-
-   - 可以登陆TSO 
-
-     1. 账户使用 ACCT#Axx 
-     2. 登陆过程使用 PROC#Axx 
-     3. Region 大小为 4096 
-
-   ```
-   ADDUSER TSO1608 OWNER(DIV16ADM) NAME('SYSTEM PROGRAMMER') DFLTGRP(DIV16ADM) PASSWORD(123456)
-   
-   ALU TSO1608 TSO(PROC(IKJDB2) ACCTNUM(#ACCT) SIZE(4096) COMMAN(ISPF))
-   
-   CONNECT TSO1608 GROUP(FUN16AP)
-   ```
-
-
-
-
-
-### 6.3 创建登陆过程
-
-为 TSO 用户创建一个新的登陆过程 PROC#Sxx 和 PROC#Axx。打开文件 VENDOR.PROCLIB ，在 Command 中输入：
-
-```
-S PROC#S16;COPY IKJDB2
-S PROC#A16;COPY IKJDB2
-```
-
-
-
-
-
-### 6.4 保护登录过程
-
-保护 PROC#Sxx 登陆过程（TSOPROC类）。
-
-1. 创建通用资源 TSOPROC 的 RPOFILE，保护 AP 和 SP 的 TSO 登陆过程。
-
-   授权规则：PROC#Sxx 只有 SP 才能使用（READ 权限），其他人不可以使用；PROC#Axx 只有 AP 才能使用（READ 权限），其他人不可以使用。
-
-   ```
-   RDEFINE TSOPROC PROC#S16 OWNER(DIV16FUN) UACC(NONE)
-   PE PROC#S16 CLASS(TSOPROC) ID(FUN16SP) AC(READ)
-   
-   RDEFINE TSOPROC PROC#A16 OWNER(DIV16FUN) UACC(NONE)
-   PE PROC#A16 CLASS(TSOPROC) ID(FUN16AP) AC(READ)
-   ```
-
-
-
-2. 浏览 PROC#Sxx 和 PROC#Axx PROFILE，它们用于保护不同的 TSO 登陆服务：
-
-   ```
-   RLIST TSOPROC PROC#S16 AUTHUSER
-   RLIST TSOPROC PROC#A16 AUTHUSER
-   ```
-
-
-
-3. 刷新 TSOPROC 类在内存中的 PROFILE
-
-   ```
-   SETROPTS RACLIST(TSOPROC) REFRESH
-   ```
-
-   可能会提示不需要刷新。
-
-
-
-### 6.5 保护 ACCTNUM
-
-创建两个 TSO 账户（ACCTNUM），并创建一个通用资源 RPOFILE 保护该 ACCTNUM。
-
-1. 创建 RPOFILE：ACCT#Sxx 该 ACCTNUM 为 SP 提供 TSO 登陆服务。
-
-   授权规则：ACCT#Sxx 只有 SP 才能使用(READ 权限)，其他人不可以使用。
-
-   ```
-   RDEFINE ACCTNUM ACCT#S16 OWNER(DIV16FUN) UACC(NONE)
-   PE ACCT#S16 CLASS(ACCTNUM) ID(FUN16SP) AC(READ)
-   ```
-
-   
-
-2. 创建 PROFILE：ACCT#Axx 该 ACCTNUM 为 AP 提供 TSO 登陆服务。
-
-   授权规则：ACCT#Axx 只有 AP 才能使用(READ 权限)，其他人不可以使用。
-
-   ```
-   RDEFINE ACCTNUM ACCT#A16 OWNER(DIV16FUN) UACC(NONE)
-   PE ACCT#A16 CLASS(ACCTNUM) ID(FUN16AP) AC(READ)
-   ```
-
-
-
-3. 浏览 PROFILE：ACCT#Sxx 和 ACCT#Axx
-
-   ```
-   RLIST ACCTNUM ACCT#S16 AUTHUSER
-   RLIST ACCTNUM ACCT#A16 AUTHUSER
-   ```
-
-
-
-### 6.6 保护 TSOAUTH
-TSOAUTH 通用资源类提供保护 TSO 权限的功能，TSO 权限主要包括：ACCT，JCL，MOUNT， OPER，RECOVER 等。系统已经定义了一个 JCL PROFILE 用于保护 TSO 的 JCL 权限，该权限允许通过 TSO 向 JES 提交 JCL 批量作业。
-
-1. （不做）为 SP 和 AP 用户赋权访问 JCL 权限：
-
-   ```
-   PE JCL CLASS(TSOAUTH) ID(FUN16AP FUN16SP) ACCESS(READ)
-   ```
-
-   
-
-2. 查看 SP 和 AP 用户是否拥有提交 JCL 作业的权利：
-
-   ```
-   RLIST TSOAUTH JCL
-   ```
-
-
-
-### 6.7 保护用户数据集 
-
-1. 保护 TSO1607 的用户数据集 
-
-   ```
-   ADDSD 'TSO1607.**' UACC(NONE)
-   ```
-
-   
-
-2. 保护 TSO1608 的用户数据集 
-
-   ```
-   ADDSD 'TSO1608.**' UACC(NONE)
-   ```
-
-
-
-### 6.8 创建 ALIAS
-
-为 TSOxx07 和 TSOxx08 创建 ALIAS（普通用户不能修改 Master Catalog，所以为了让用户可以创建自己的编目数据集，必须为用户创建 ALIAS，ALIAS 指向 User Catalog）。
-
-1. 为 TSOxx07 创建别名
-
-   ```
-   DEFINE ALIAS(NAME(TSO1607) RELATE('CATALOG.UCAT.STGRP'))
-   ```
-
-   
-
-2. 为 TSOxx08 创建别名
-
-   ```
-   DEFINE ALIAS(NAME(TSO1608) RELATE('CATALOG.UCAT.STGRP'))
-   ```
-
-
-&nbsp;
-## 7. 使用 JCL 执行 RACF 命令
-
-编写 JCL 作业，然后 SUBMIT：
-
-```
-//ST016R1 JOB CLASS=A,MSGLEVEL=(1,1),MSGCLASS=H,
-// NOTIFY=ST016
-//SEND EXEC PGM=IKJEFT01
-//SYSPRINT DD DUMMY
-//SYSTSPRT DD SYSOUT=*
-//SYSTSIN DD *
-SEARCH CLASS(GROUP) MASK(DIV16)
-SEARCH CLASS(GROUP) MASK(FUN16)
-SEARCH CLASS(GROUP) MASK(RES16)
-SEARCH CLASS(USER) MASK(TSO16)
-LG FUN16PRD
-LG FUN16TST
-LG FUN16SP
-LG FUN16AP
-SEARCH CLASS(DATASET) MASK(TSO16)
-SEARCH CLASS(DATASET) MASK(RES16)
-LISTDSD DA(TSO1601.**) AU
-SEARCH CLASS(TSOPROC) FILTER(PROC#%16)
-RLIST TSOPROC PROC#S16 AU
-RLIST TSOPROC PROC#A16 AU
-SEARCH CLASS(ACCTNUM) FILTER(ACCT#%16)
-RLIST ACCTNUM ACCT#S16 AU
-RLIST ACCTNUM ACCT#A16 AU
-```
Index: blog/posts/2020-09-04-bayesian-meta-learning.md
===================================================================
diff --git a/blog/posts/2020-09-04-bayesian-meta-learning.md b/blog/posts/2020-09-04-bayesian-meta-learning.md
deleted file mode 100644
--- a/blog/posts/2020-09-04-bayesian-meta-learning.md	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
+++ /dev/null	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
@@ -1,52 +0,0 @@
----
-layout: Post
-title: Bayesian MAML
-subtitle: MAML 的贝叶斯解释
-author: Renovamen
-date: 2020-09-04
-headerImage: /img/in-post/2020-09-04/header.jpg
-permalinkPattern: /post/:year/:month/:day/:slug/
-tags:
-  - Deep Learning
-  - Meta Learning
-  - Bayesian
----
-
-
-为了引入不确定性~~和多找一个发论文的话题~~，MAML 还可以用贝叶斯视角来理解。
-
-<!-- more -->
-
-
-## MAML 回顾
-
-在[之前的一篇文章](/post/2020/08/05/meta-learning#maml)中已经介绍了 MAML（Model-Agnostic Meta-Learning），一种 gradient-based 的 meta-learning 方法。其目标是学习出一组初始化参数 $\theta$，对于任意任务 $\mathcal{T}_i$，这个初始化参数都能在一步或极少步梯度下降中就快速达到最优参数解 $\theta_i^*$。
-
-
-大致回顾一下它的算法流程，对于采样出的任务 $\mathcal{T}_i$：
-
-- inner loop（meta-learner）：在 $\mathcal{T}_i$ 的 support set 上计算梯度并更新参数，得到更新后的参数 $\theta_i'$。$\theta_i'$ 只是一个临时参数，并不会作为最终的更新：
-
-    $$
-    \theta_i' = \theta - \alpha \nabla_\theta L_{\mathcal{T}_i}(f_\theta)
-    $$
-
-- outer loop：用 $\theta_i'$ 在 query set 上计算损失，然后**对 $\theta$ 求梯度**，并在 $\theta$ 上更新出最终的参数：
-
-    $$
-    \theta \larr \theta - \beta \nabla_\theta \sum_{\mathcal{T}_i \thicksim p(\mathcal{T})} L_{\mathcal{T}_i}(f_{\theta_i'})
-    $$
-
-所以它的优化目标可以总结为：
-
-$$
-\theta = \arg \min_\theta \sum_{\mathcal{T}_i \thicksim p(\mathcal{T})} L_{\mathcal{T}_i}^{\text{query}}(\theta - \alpha \nabla_\theta L_{\mathcal{T}_i}^{\text{support}}(f_\theta))
-$$
-
-
-
-## 参考
-
-- [Properties of Good Meta-Learning Algorithms (And How to Achieve Them).](https://ai.stanford.edu/~cbfinn/_files/icml2018_automl_35min.pdf) Chelsea Finn. ICML 2018 AutoML Workshop (Talk).
-
-- [Bayesian Model-Agnostic Meta-Learning](https://www.slideshare.net/sangwoomo7/bayesian-modelagnostic-metalearning)
Index: blog/posts/2022-02-21-new-year-2022.md
===================================================================
diff --git a/blog/posts/2022-02-21-new-year-2022.md b/blog/posts/2022-02-21-new-year-2022.md
deleted file mode 100644
--- a/blog/posts/2022-02-21-new-year-2022.md	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
+++ /dev/null	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
@@ -1,554 +0,0 @@
----
-layout: Post
-title: 2022 新年快乐
-subtitle: Gap Year 的结束，摸鱼与快乐
-author: Renovamen
-date: 2022-02-21
-useHeaderImage: true
-headerImage: /img/in-post/2022-02-21/header.jpeg
-headerMask: rgb(67, 65, 47, .2)
-permalinkPattern: /post/:year/:month/:day/:slug/
-tags:
-  - 摸鱼
----
-
-不管是按公历新年，还是按中国新年，在这个点说新年快乐都显得格格不入，~~但反正也没人看也就无所谓了~~。
-
-<!-- more -->
-
----
-
-大四的时候支撑我跟托福拉扯的最大动力是：“申请季前要是考不出分我就得 gap 了，我绝对不能 gap”。那时我对于生命中的一整年莫名掉出计划外这种事相当恐惧，我基本是在被既定的计划裹挟着往前走，所有事情都在 due 前夕完成（虽然现在差不多也是这样），我无法想象 gap 的那一年我会怎么样。
-
-然后我考出了能看的托福分数，然后超现实主义的 COVID-19 和中美互掐从天而降，然后我还是 gap 了。
-
-但这一年是我高中以来过得最开心的一年，而开心的主要原因是我摸了大半年鱼。前半年我表面上是在打两份工，实际上摸鱼摸的飞起，为这一整年奠定了开心的基础。当然这全靠导师和部门老大的包容，没 push 我也没一怒之下把我扔掉。后小半年被学校的课程和公司的活搞得鸡飞狗跳（虽然我觉得鸡飞狗跳很大程度上归功于 CS 611，我这一年的绝大多数抱怨和所有的通宵都贡献给了它），但因为之前过得太开心了所以也没觉得有什么问题。
-
-看来解决我的状态问题的方法是摸鱼，而如果没有疫情我就不会有这样长的一段摸鱼时光，说不定现在已经浑浑噩噩的读完硕士毕业了。
-
-
-## 有书读且活着
-
-去年新年的时候，我说最大的愿望是能在生存率较高的前提下有书读，这个愿望实现了。我终于熬过了无业游民的一年，并且在今年 1 月的时候第一次来了美国，到目前为止还活着，同时每周的核酸结果都很正常。
-
-虽然在那之前我还是上了一学期网课。快手 hr 面的时候，对面问我为啥要 gap，我说我不想上网课，然后对面就开始笑说“结果你这学期还是要上网课哈哈哈哈哈哈哈”。
-
-我：(′▽`)
-
-但其实差点就没书读了。BU 是我去年唯一一个录取，而且 5 月了才发的录取。众所周知美帝很多学校给学生设的决定接不接 offer 的最后期限是 4.15，而 4.15 都过了我还一个录取都没有。那时我觉得自己要没书读了，甚至开始刷题准备找工作了。
-
-那段时间我的知乎简介是“没书读的无业游民”，然后我收到了一条私信：
-
-<img src="/img/in-post/2022-02-21/zhihu-1.png" width="375px" alt="zhihu-1" />
-
-不是你怎么动不动就问别人有没有书读啊我好心痛啊 (╯‵□′)╯
-
-同时我给 BU 发了几封邮件，内容包括“球球你们再收留我一次吧”“you are my dream school”“这次我一定会来的”。BU 在 Fall 2020 和 Spring 2021 录了我两次我都没去（因为它不给 defer 啊不是我不想去啊），结果风水轮流转，Fall 2021 的时候轮到我卑微的去纠缠它了。
-
-当时我跟朋友聊天时，这样评价这件事：
-
-<img src="/img/in-post/2022-02-21/chat-1.jpg" width="375px" alt="chat-1" />
-
-像极了爱情。
-
-但实际上：
-
-<img src="/img/in-post/2022-02-21/chat-2.jpg" width="375px" alt="chat-2" />
-
-欣慰的是 5 月的时候 BU 总算给了录取。我觉得它是被我的诚意打动了，觉得“这只鸽子这次应该不会咕我们了”，于是给发了录取。可能是前一年被咕得太狠了，BU MSCS 历年来都不收 deposit 的，去年要收了。
-
-拿到录取以后我说：
-
-<img src="/img/in-post/2022-02-21/chat-3.jpg" width="375px" alt="chat-3" />
-
-好耶！
-
-
-## 国企
-
-读本科的时候我不会想到我居然会有去国企上班的一天。
-
-在有录取之前我都不是学生身份，不是学生就没法在大多数公司实习，而且我那时想把重心放在写论文上不希望去活太多的公司（最后其实把重心放在了摸鱼上），所以我就去了老家的一个国企实习。
-
-国企待着真的开心，部门老大和同事人非常好，并且标准 955，部门老大在没有急事要干的时候下班比我还积极。技术方面，曾被抓去找模型写 demo、写处理数据的脚本、写三维地图和数据的可视化。非技术方面，跟了一个项目，在里面端茶倒水会议记录做 PPT 写文档，听公司老大一边骂我们“都写的什么玩意儿专家看了会怼死你们的”一边讲解该怎么写体制内的八股文（现在已经忘完了）。
-
-这真是我最奇特的一段实习经历了，比上一段在创业游戏公司又写代码又画画的实习经历还要奇特。
-
-同时我理解了博士毕业进国企带项目的快乐。具体来说作为牵头单位，我们需要给包括高校在内的其他机构发经费以及 push 它们的进度。说不定当年在学校里压榨过你的老师，现在得指望你给他发经费和被你 push。
-
-元旦放假前公司老大还问我还去不去美国，不去的话可以考虑转正。那时我没想到我去年的申请结果会如此的惊心动魄，一口咬定我肯定会去的。
-
-就是这公司离家有点远，坐地铁得一个多小时。我用坐地铁的时间把王树森老师的 [Deep Reinforcement Learning](https://github.com/wangshusen/DRL) 看了一遍，~~并通过找 typos 让自己的名字出现在了这本书的致谢里~~。然后脑子一热去继续学了一下强化学习，当时甚至还燃起了要写一个“极简强化学习库”的热情，因为觉得即使是当时主打轻量的 RL 库，为了兼顾某些方面也必须做出取舍，最终也还是不够简洁。而我只是想要一些最核心的功能来方便我玩耍，只要把这些最核心的功能写得干净高校且方便扩展就好了。结果不了了之，一方面没有精力，另一方面我对 RL 各种算法和现有的库的架构的了解都太少了，感觉很难写出我想写的东西。后来也没再学 RL 了，感觉我现在连贝尔曼方程都看不懂了。
-
-
-## 找实习
-
-5 月拿到录取以后就从之前的实习公司离职了，因为还是想去大点的互联网公司看一看，并且还得赶论文。投完论文以后开始更新简历、投实习和准备面试，全投的算法/研究岗。投的公司也不多，十个左右吧，其中还有一半是我基本没报什么希望就当买彩票的研究岗。其实本来打算边面试边投，但快手给了 offer 以后我就再也没有动力投了。
-
-摸鱼之年贯彻得非常好。
-
-
-### 简历
-
-我第一次实习的公司是个游戏公司，直接要求“不要发那种中规中矩的简历过来”，于是我写了[这个](https://resume.zxh.io/)发过去。第二次实习在国企，感觉对面也没怎么看我简历。因此这可以说是我第一次正经的给公司投简历。
-
-简历我之前就用 LaTeX 自娱自乐性质的写过一份，直接用了 [moderncv](https://ctan.org/pkg/moderncv) 宏包的 classic style，好看是好看，但每节的标题单独占了一列，太不紧凑了，装不下多少内容。尤其是投工业届的简历往往被建议只写一页（虽然也没人明确地告诉过我写两页到底会不会有什么负面影响），那更是寸土寸金。我也懒得调整了，直接换成了[这个](https://github.com/billryan/resume/)更紧凑的模板，然后魔改了一下，主要是扔掉了图标和给标题加了颜色，最后成品长这样：[中文](https://zxh.io/files/cv/cn/brief.pdf) / [英文](https://zxh.io/files/cv/en/brief.pdf)。英文简历除了 MSRA 应该也没公司看，但反正写都写了，我就把它拼在中文简历后面了。
-
-接下来的内容只是我到目前为止的认知（并且只针对互联网公司技术岗），我不为它们负任何责任。
-
-总的来说，不管用 Word 还是 LaTeX 还是别的什么工具，我觉得简历模板应该：
-
-- 紧凑（尽量多写内容）、但不能太紧凑（避免对面看着费力心情不好）
-- 如果要加颜色，首先多找几个人确认一下这些颜色是否花里胡哨奇奇怪怪；同时要保证这些颜色用黑白打印机打出来依然清楚，万一对面就喜欢把简历打印出来看怎么办
-- 背景图案（比如贵校校徽什么的）我觉得就没必要加了，打印出来以后估计你的字就看不清了
-- 如果要出现超链接，那么考虑到对方是拿着纸质简历在看的可能性，应该尽量用文字把核心信息写清楚。比如你要放个人网站链接，就直接把域名打上去：[zxh.io](https://zxh.io)，如果写成这样：[个人网站](https://zxh.io)，打印在纸上就没人知道这是什么了；如果放 Github 一类的主页，起码把平台名和用户名写上去
-- 可以确定的是，至少投互联网公司技术岗，简历不放照片是没有问题的。至于放了照片会加分还是减分，我不确定，有人说长得好看的话可以放，有人说放了会增加各种歧视的可能性。而投别的类型的公司和岗位要不要放照片我就不清楚了，有人说有的公司会觉得你不放照片是不尊重。但至少对于我来说，我的简历已经没空间放照片了，而且往 LaTeX 里加照片听上去就很麻烦，而且加了会让我的模板变丑，于是我没有加
-
-关于内容，我觉得：
-
-- 有人说 GPA 必须写，但我没写（因为真的太低了），好像也没啥影响
-  
-  但要是 GPA 或排名好看的话那肯定得写
-
-- 我觉得获奖情况可以只写专业相关的省奖及以上（ACM / 数学建模 / Kaggle 或其他大型算法赛等）（要是奖还是太多了可以继续缩小范围到国奖甚至国际奖）+ 牛逼一点的奖学金（我没有）+ 优秀毕业生（我没有）
-
-  如果把所有乱七八糟的校奖和专业无关奖都写上去，反而会让人抓不住重点，而且浪费简历篇幅
-
-  当然也会有在上述范围以外的值得写的牛逼的奖项，虽然我一时之间只能想到清华特奖
-
-- 所有教育经历都是计算机科班的话就没必要写相关课程了，但转专业的可以写
-
-- 在读学位不要写 20XX - 至今，把毕业时间写上去
-
-- 写项目/研究/实习经历的时候，一般最后得写一句这个工作实现了怎样的效果。但“发了论文或专利”、“在 Github 上拿了多少 star”、“被公司上线了”之类的虽然肯定应该写并且值得加粗，但我觉得不能算“效果”，“效果”应该得是各类指标比之前的工作优化了多少
-
-- 技能部分大概分为：编程语言 / 框架和工具 / 语言（如果考试成绩好看，就把成绩也写上）
-
-  根据自己的情况进行调整，开发岗可能需要把框架和工具那里再细分一下
-
-- 不用写与专业无关的技能（如 Office 全家桶，虽然 PPT 做得好是个很重要的优势，但写简历上大概没啥用）和经历（如学生会，除非你在学生会里搞了技术）
-
-  跑题：但我道听途说，在申请美国学校的时候，对 minority 做了贡献的经历可能会有作用
-
-
-### 面试
-
-6-7 月在投简历和面试。投的研究部门除了 MSRA 给出了正面回复以外，其他全部石沉大海。可能是因为我太菜了，可能是因为他们当时不缺人，也可能是因为我没找内推直接海投。而 MSRA 的研究员告诉我，虽然我简历看上去还行，但必须得是严格意义上的在校生才能去他们那儿实习，而我当时虽然有 offer，但还没入学，所以依然不算在校生。
-
-我：（⊙ｏ⊙）
-
-他让我 8 月底再去联系他面试。那应该是我离 MSRA 最接近的一次了，大三投了一次，简历拒，大四毕业投了一次星桥计划，简历拒，这次终于简历过了。而且那个研究员和他的方向我都很喜欢。所以当时纠结了很久，最后还是觉得，万一我 8 月底面挂了怎么办，那个时候再重新找实习吗？风险感觉有点大？最终还是没有选择在这一棵树上吊死。
-
-顺便一提，MSRA 的研究员有独立的招实习生的资格，所以如果找不到人内推，可以考虑直接去联系方向跟自己相符的研究员（我就是这样）。但每个研究员只有 1-2 个实习生名额，所以得等之前的实习生离职才有机会。
-
-关于刷题，因为留给我的时间不多了，所以我只考虑了剑指 Offer 和 Leetcode hot 100，而且并没有来得及刷完。欣慰的是面试的时候没被考过很难的算法题，除了快手一面两道算法题全挂以外其他都写出来了。虽然快手一面面试官（也就是我后来的 mentor，是个非常非常非常好的大哥）一直说“没事”“没有关系”，但我还是觉得肯定凉了，于是又投了一些别的公司。结果快手给过了，我直到现在都很意外。
-
-快手和 OPPO 都没有扣机器学习的细节。快手一面全问项目，问完写题。二面问完项目之后开始问场景题，比如现在有个啥啥啥业务需要实现啥啥啥效果，你打算怎么做，要从收集数据到用什么模型到评测指标全部说一遍。我觉得这是最让人头大的，当时一边答一边冒冷汗。OPPO 只有一面，也是全程聊项目，聊完之后写题，面试官甚至直接让我共享屏幕、把 Leetcode 打开、搜题、开始写。如果我入职 OPPO，mentor 应该就是那个面试官，他也是个很好的人，并且他说他带的实习生会做偏研究的工作，写论文打比赛什么的。但因为那个岗位的 base 是在上海，而我在上海待了四年，在有选择的情况下还是想去别的地方，所以最后还是没有去。
-
-我也不知道我一个基本不出去玩的死宅为什么要在乎工作地点。
-
-可能是因为我面的商汤那个组做的东西我不太明白，而我做的东西他们也不太感兴趣，聊项目聊不到一起去，于是商汤一直死扣细节。具体来说，我在聊项目的时候，提到我用了 ResNet，这时面试官大概是觉得终于抓住了能聊的东西，于是开始问 ResNet-18 到 ResNet-152 的结构，甚至精确到了每一层是个几乘几的卷积的程度，中途顺便问了 batch norm 和残差连接。我当时感到压力巨大，脑子全速运转疯狂回忆。当面试官说“来写道算法题吧”的时候，我甚至松了一口气。
-
-这个故事告诉了我们项目/实习经历的重要性。项目经历是面试中你唯一可控的部分，而基础题和算法题是你非常不可控的部分，因为范围太大，准备得再充分也有可能失手。如果项目讲得好，那留给面试官问基础和算法题的时间就不多了，从而尽可能的控制不可控部分的难度。但如果面试官问了两句项目就不知道该聊什么了，那剩下的几十分钟到一个多小时里，他/她就只能把你一直按在基础题和算法题的大海里遨游了，你失手淹死的概率大幅上升。
-
-滴滴的面试官是个很好玩的大哥，我们的对话包括：
-
-- 他：你了解 LDA 吗
-- 我：不了解
-- 他：我也不了解
-- 我：？
-
----
-
-- 他：来讲一下 beam search 吧
-- 我：（空耳听成了毕设）开始讲毕设
-- 他：BEAM！SEARCH！束！搜！索！
-
----
-
-- 他：写二叉树前序遍历的非递归写法
-- 我：（不知为何脑子一抽开始笑）
-- 他：你为什么在笑？你一定是会写才笑，那不写这个了，写个二分吧
-- 我：那还不如写前序遍历...
-- 他：？二分比前序遍历简单吧？就写二分！
-- 我：...
-
-平心而论我觉得我滴滴一面发挥还行，除了 LDA 以外没有没答出来的问题，但然后就再也没人联系我二面了。不知道是因为我太菜了，还是因为滴滴那段时间出了事...
-
-接下来的时间我会用来吐槽字节跳动。我字节前后投了两个岗位，都直接简历拒。当然这我完全能接受，毕竟我菜，同时我同学安慰我那俩岗位可能不缺人。可在同一时间，不断有字节的人来找我问我要不要内推。还有字节的 hr 来找我说“我觉得你很适合去后端”，而我简历上没有任何一条体现出了我会后端（实际上我的确也基本不会后端），可能大家默认算法都能转后端吧。在我实习入职以后，甚至已经去了美国以后，还不断有字节的 hr 来让我去面试，岗位从算法到客户端开发不等。
-
-我可以理解 hr 有凑面试人头的指标，我也可以理解内推成功有奖励，但这也太离谱了，起码拉我去干点我会干的事儿吧。
-
-~~可是所有公司 hr 的声音都好好听啊。~~
-
-
-## 旅游
-
-作为一个死宅，去年我就出去丸了三次。现在想来，那是我出国前最后一次见这些朋友们。
-
-### 成都
-
-6 月去成都找朋友带我吃吃喝喝。我觉得成都是到目前为止，最适合我生存的地方了。足够发达，该有的大公司都有，虽然工资比不上北上深，而且好像基本只有开发岗。离家（重庆）近，坐高铁往返非常方便。食物好吃，除了我这个能吃辣的重庆人在意的火锅串串川菜以外还有各种辣或不辣的极具特色的小吃，我觉得不能吃辣的人也能感到满足。房价友好，至少在看了北上深的房价以后我觉得非常友好。可以说方言，不过成都已经挺全国化了，当地人做生意的时候都会默认说普通话。
-
-其实我上次回家的时候，觉得重庆也挺全国化了，比如我去办事，我说重庆话，柜台的人说普通话，于是我被迫说普通话，同时柜台的人跟她的同事说重庆话...虽然在外地人越来越多的情况下这也是应该的，但这基本意味着最后一个我能随便说重庆话的地方也在渐渐消失。
-
-去蹭了朋友的同事的离职聚餐，吃完饭后去看了那部叫 Hello World 的电影。Hello World 的设定 + 选材 + 画风 + 主题的结合让我在刚开始看的时候就直接很不理智的把印象分拉到非常高的程度。实际上在看完结局以后我印象分依然很高，虽然科幻部分在大量以往作品的簇拥下没法显得很震撼（但这也是没办法的事），剧情节奏在某些时候没把握好，该燃的时候没燃起来该煽情的时候没煽情起来，但印象分可以让我不在乎这些。很多人可能觉得搞一个宏大的世界观设定但内核是在讲中二爱情故事显得太矫情了，上海堡垒电影当时被喷的众多理由里也有矫情这一条（尤其是在流浪地球的衬托下）。但这在我这里的确不算缺点甚至是加分项，这种跨界可以让我忽略掉它在科幻和叙事方面的不足。上海堡垒原著我也看得挺开心的，但电影实在崩得太惨烈了。
-
-我们在高新区吃的饭，成都的各种互联网公司基本都在高新区。吃完饭已经快十点钟了，我们想打车去电影院，然而打不到车。然后朋友的同事说：“因为现在是下班高峰期，所以不好打车”。
-
-我：(。_。)
-
-好家伙现在连成都都这样了吗。
-
-除了吃喝以外去了杜甫草堂锦里青城山都江堰熊猫谷这些外地人都会去的地方。值得一提的是熊猫谷，大熊猫不是在睡觉就是在干饭（可能是因为我将近中午才去吧，他们说得早上去才能看到活动的大熊猫）：
-
-<video controls="controls">
-  <source src="/img/in-post/2022-02-21/panda.mp4" type="video/mp4">
-</video>
-
-因此相比干饭大熊猫，小熊猫更让人心动：
-
-<video controls="controls">
-  <source src="/img/in-post/2022-02-21/red-panda.mp4" type="video/mp4">
-</video>
-
-嗷嗷嗷这玩意儿比干脆面可爱多了好吗！银河护卫队里就应该搞只火箭小熊猫！
-
-
-### 上海
-
-7 月去了上海，如果你要问我上海有啥好玩的你明明大学四年都在上海，那我得说作为一个死宅，我大学四年就没出过几次学校。
-
-何况我还约了上海的签证，必须得去。
-
-见到了另一个朋友和~~缅甸小王子~~，他们带着我：
-
-到外滩去看了建党 100 周年的灯光秀。因为人太多了所以南京东路封站，需要在人民广场下地铁然后走去外滩，而这一段路挤得人山人海水泄不通。那天雾很大，所以我们看到了断掉的东方明珠：
-
-<img src="/img/in-post/2022-02-21/shanghai-1.jpg" width="400px" alt="shanghai-1" />
-
-和像鬼一样飘着的金茂大厦：
-
-![shanghai-2](/img/in-post/2022-02-21/shanghai-2.jpg)
-
-上了大学四年都没上过的东方明珠，在塔底的时候天气还行，等排队排上去时就开始乌云密布电闪雷鸣，甚至能看到闪电在环球金融中心上的倒影，感觉随便拍一张照片就能拉去当上海堡垒的海报：
-
-![shanghai-3](/img/in-post/2022-02-21/shanghai-3.jpg)
-
-去了大学四年都没去过的迪士尼，见到了尼克·王尔德：
-
-![shanghai-4](/img/in-post/2022-02-21/shanghai-4.jpg)
-
-啊他真的太帅了！
-
-最后，我趁着 17 级毕业典礼的时候溜进了同济本部，见到了朋友和老师，吃到了冻酸奶和学苑食堂。
-
-跟老师聊的时候知道了同济现在在搞大类招生，大一新生不细分专业，而是分成几大学堂，大一结束的时候再填专业志愿，然后按绩点和面试成绩分流。虽然我早就知道电院和软院的门槛早已不同当年，但之前在群里看到现在想进软院需要 4.7+ 的大一绩点的时候还是吓傻了。而且因为大家都觉得电院的计算机人工智能什么的肯定很难进，于是大家志愿都填软院，所以软院分数线比电院还高。而同济王牌专业土木工程什么的每年都招不满人...
-
-我要是晚几年读大学，大概是学不上计算机的。
-
-要知道我当年高考的时候，软件工程是同济在重庆录取线最低的专业。刚进大学就知道有不少同学和前辈是第 N 志愿甚至调剂到软院来的。第一次班会课，辅导员甚至说：“我还是希望不要有太多的同学转专业”。那时的大热专业还是金融，上财金融相关专业的录取线直逼复交。高中的时候我们的通用技术课（高二上教焊板子，高二下教锯木头）老师还说过：“为什么所有人都想去学金融呢？这个社会总要有人来写代码的啊！”。
-
-这位老师如今看到计算机如此的卷，大量的人想写代码还写不上，大概会非常欣慰吧。
-
-高中的时候我爸妈非常反对我学信息学竞赛，填志愿的时候如果不是当时几乎没有选择应该也会反对我学计算机，而现在他们觉得我当年非常英明。但我跟英明这个词也扯不上任何关系，计算机后来大爆炸也完全在我的意料之外。我学竞赛是为了给高中成绩不好找借口，志愿填计算机相关是因为别无选择和觉得写代码并不是一个没有热情和天赋就会饿死的行业，仅此而已。
-
-
-
-### 深圳
-
-10 月国庆的时候去了深圳，开心而充实，虽然后果是我的半期考试鸡飞狗跳。
-
-作为一个死宅，即使是在外面旅游，一般来说我也会在酒店里宅到下午，然出去象征性的逛几个小时，最后在天黑前回酒店继续宅着。有的时候甚至会一整天都在酒店待着不想出去。但去深圳的那一次，带我玩的朋友简直是宅的反义词，因此我经历了一次难得的高强度旅行，基本每天回酒店的时候都是凌晨了。
-
-但深圳的确是个值得高强度晃悠的地方，风景好空气好，至少比北京好太多了。广东菜也很好吃，不过如果要我每顿都那么吃那我肯定也扛不住。不适宜生存的点是温度过高，而且小生物们凶猛且个子大。
-
-总之在成都成为发达城市之前，我觉得发达城市都不适合人类生存。
-
-骑车去追逐了落日：
-
-![shenzhen-1](/img/in-post/2022-02-21/shenzhen-1.jpg)
-
-<p class="desc">我已经忘了这是在哪拍的了</p>
-
-朋友指着一个地方跟我说那边就是香港，我说我去香港玩的时候别人也指着一个地方跟我说那边就是深圳。
-
-去了海边，沿着海滨栈道骑车往回走的时候看到了盐田港，那是我第一次看到港口。夕阳将近，残光铺在港口的那些庞然巨物上，我想象它们装载着一艘名叫利维坦的飞艇的零件，有一天那艘飞艇会在火烧般的晚霞中破云而上。
-
-可我的手机拍不出这种感觉。
-
-去逛了西丽大学城，然后在清华见了一个学姐，具体来说是在学姐的工位上打糖豆人。她的工位上有 PC、Mac、Switch、PS4 以及一些手办。
-
-我：(。_。)
-
-我居然在清华见到了我理想中的环境。
-
-学姐：可能是因为我在工位上打游戏被导师发现了，在我后面进来的人都没有好机子用了
-
-我：(。_。)
-
-深藏功与名。
-
-西丽大学城有三个学校，清华北大和哈工，三个连在一起，过了一个的门禁剩下两个就都能去了。因为哈工的门禁最不严格，学姐让我跟着她从哈工的门进去，在这之前她把她的校园卡给我，并告诉我：“如果保安拦你，你就把卡在他眼前晃一下，然后理直气壮的说你是清华的”。
-
-我：(。_。)
-
-学姐：记住要理直气壮
-
-我：我觉得我没法理直气壮的说出这种话...
-
-不过保安并没有拦我。
-
-最后，这是一只看上去很傻的狮子：
-
-<img src="/img/in-post/2022-02-21/shenzhen-2.jpg" width="350px" alt="shenzhen-2" />
-
-<p class="desc">南山博物馆，叙利亚古代文物</p>
-
-
-## 快手
-
-面完试之后 leader 告诉我，组里的实习生搞研究写论文打比赛业务落地都能做，我心说好家伙那么自由的吗我得去看看。实际上的确很自由，入职第一周 mentor 跟我主要聊的就是“你想做什么”。组里别的实习生做的东西也的确五花八门，涵盖了 leader 当时说的几个方向。
-
-我感觉这段实习就像在读研，天天看论文写代码跑实验，然后每周一次组会汇报进度。而组会也很有快手特色，我花了很久才能在看到别人的周报上出现的美女和土味短视频时保持冷静而不是笑出声。~~我不玩快手，我只在周报上看快手短视频。~~
-
-但业务部门的正式员工就得花大量时间在处理业务上了，甚至只有在周末休息的时候才有看论文的时间。有个大哥说他最期待的就是在面试的时候跟应聘者聊论文。但即使是这样，在跟我聊论文的时候，他们依然表现得非常敏锐，这让我非常佩服，很多点真不是我一下（或者很多下）就能想到的。
-
-同时，在听组里的大哥们聊他们捞简历和面试校招生的情况时，我也感受到了国内算法岗的卷。有些我觉得背景挺好的人（清北华五硕+大厂实习）简历都没过，算法题甚至已经考到了（我认为的）ACM 难度。感觉这已经不是在考察应聘者符不符合岗位要求了，而是为了筛人而强行拉高难度，这让我想到了某些大省的高考卷。我感觉我要是校招来面这个组大概率是面不过的。
-
-另一个发现是，即使在业务算法部门里，博士的晋升速度和天花板也高于硕士。以前我一直觉得国内博士毕业以后如果进不了研究岗就有点浪费，现在看来也不算浪费。
-
-下雪后的总部还挺好看的：
-
-<img src="/img/in-post/2022-02-21/kuaishou-1.jpg" width="650px" alt="kuaishou-1" />
-
-<img src="/img/in-post/2022-02-21/kuaishou-2.jpg" width="650px" alt="kuaishou-2" />
-
-最后，我对于这儿的食物很满足，肥宅也就这点追求了。食堂挺不错的，虽然吃到最后有点吃腻的感觉。不想吃食堂的话也可以让公司点外卖，但不知为何公司支持的外卖都不咋好吃，还不如去食堂。咖啡和雪糕不限量，发的下午茶至少我不是每天都能吃完。离开北京前的那几天，为了花光能量券薅掉公司的羊毛，我经常往总部罗森赛百味星巴克跑，感觉像是一个压力巨大的任务。
-
-最后的最后，我有一个非常好的 mentor，感谢他。其他同事也非常好，感谢他们。
-
-
-## 北京
-
-北京是个不适合人类生存的地方。
-
-空气不好，风沙大。夏天随时可能突然下大雨，路上可能几百米都没有能躲雨的地方，等找到躲雨的地方已经成落汤鸡了，遂觉得不如破罐破摔继续往前走。虽然有天气预报，但天气预报没法精确到分钟。冬天妖风大，大到顶着风往前走不动的程度。
-
-房价和房租都太高了，我在软件园附近租的年代很老的房子的价格非常让人心痛，但为了上班方便和蹭房补也没办法了。虽然软件园周边肯定不缺人租房，价格高可以理解，但这都已经五环了啊，五环都那么贵啊。
-
-因为房子老，所以大概存在隔音的问题，这就导致楼下邻居上来怼过我三次。第一次是九月的某一天的中午左右，我感冒了不舒服，摊在椅子上一动不动，然后楼下怒火冲天的上来敲我卧室门（不知道怎么进的公寓门，估计是室友给开的），对我劈头盖脸一顿骂，说我凌晨一两点在房间里拖椅子，吵到他们小孩睡觉了。
-
-我那本就因为生病而宕机的脑子更加宕机了，我凌晨一两点就算还在熬夜，也应该在床上躺着玩手机，为啥会拖椅子。而且那时我为了每天早上早起去公司蹭早餐睡得都挺早。于是我困惑的说了一句：“凌晨一两点？”
-
-楼下的人：“你不要狡辩了！”，然后继续骂。
-
-我心说我压根就没辩啊这明明是个希望得到确认的疑问句，但我觉得可能真的是我搞出了什么动静，比如在床上翻身声音太大，那么作为理亏的一方还是少说点话。而且我当时只想赶紧把她们应付走然后继续回去摊着。同时我还很怂，担心她们突然掏出菜刀来砍我。于是我道了歉并表示我以后我会注意，算是把她们送走了。
-
-后来问室友，她们说从来没听到我房间里的动静。不过地板上的噪音对楼下影响可能会更大一点。总之直到我离开北京，我在房间里干任何事都战战兢兢的。
-
-第二次是十月份，北京突然降温，一步跨过毫无存在感的秋季直奔寒冬。而我刚从短袖短裤依然热得不行的深圳回来，完全无法接受这个温度，于是开了两天热空调。然后某一天早上九点多，楼下又怒气冲冲的上来敲我房间门（为什么这个室友又随便给人开门啊喂）。前一天晚上我在通宵赶 CS 611 的作业（万恶的 CS 611），那时我刚躺下睡着没多久，被强行吵醒起来开门。然后楼下的人表示我空调声音太大了，吵到他们老人小孩睡觉了。
-
-我：“...”
-
-楼下的人：“你去找房东修空调，要是房东不给修的话你就买个小太阳用着。”
-
-道理是这个道理，这的确是最合理的解决方案，但你用这种命令的语气说话就让人头大了。
-
-楼下的人：“你要是还继续开空调吵我们，我们就报警了”
-
-我：“...”
-
-我觉得报警是对方拒绝配合之后才应该搬出来的手段，结果在我啥都还没来得及说的情况下，你上来三句话不到就威胁要报警，感觉就像是斗地主开局就王炸。我吵到你们了我愧疚我会尽量注意，但你这样就搞得好像我的一切决策都是被警察逼的一样。
-
-和上次一样，出于可能的确吵到了她们+想赶紧回去躺着+太怂了担心被砍的理由，我依然是赶紧道歉了事。那时离北京开始供暖已经不远了，于是我就直接不开空调了。
-
-第三次是十二月，我快离开北京的时候。一个室友（给楼下开门的那个）已经退租了，我跟隔壁房间的姐姐都在上班。中介派师傅来清理退租的房间，大概又吵到楼下了，于是楼下又怒气冲冲的跑上来，敲门，师傅懵逼的开了门，楼下在每个房间门上都贴了张写着主题为“注意安静”的纸条，师傅继续懵逼，但啥也没敢说。
-
-隔壁可靠的姐姐先回家，看到了纸条，暴怒。她先去跟中介拉扯，然后按非法入室报了警（虽然最后警察也没管这事）。
-
-太可靠了真的，比我这种菜鸡可靠多了。
-
-最后离开北京得太突然，没来得及跟隔壁姐姐吃约好的饭，算是个遗憾吧，不知道以后还会不会有机会。
-
-在北京找高中同学玩的时候吃了顿火锅，我觉得真的是很正宗的重庆火锅了，而且在底料的细节上做得比很多重庆的火锅店都好。吃完火锅去了丰台的花卉大观园，我也不知道我们为什么要想不开在冬天去花卉大观园，大棚外面就没啥植物还长着。
-
-离开北京前几天去了大学同学的家里丸，让我震惊的是她的妈妈叫我大佬。
-
-第一次听到的时候，我：“好的阿姨！”
-
-经过几秒的思考，我转过头问同学：“等等她刚刚叫我啥？”
-
-
-## Deecamp
-
-跟三个本科同学一起参加了去年的 Deecamp，然后拿了语言赛道的冠军。
-
-虽然语言赛道一共就四个队......用当时队友的话来说：『选择比努力更重要』
-
-2018 年 Deecamp 刚出来的时候我就听说过，在那个没有疫情的年代，参加 Deecamp 的人需要去北大住几个星期，集中听课和写项目，而不是像去年那样在网上听课，并且有着一两个月的写项目的时间。一直以来虽然也没有什么想要参加的冲动，但真的有去参加的机会的时候还是很开心的，感谢队友。
-
-我无端的感觉去年的参赛门槛比前几年低了很多。18、19 年的时候还有笔试，面试也会问一些技术上的细节，录取率还低。去年没有笔试，面试也基本是闲聊项目。
-
-选赛道的时候，我们全组首先达成了对医疗赛道毫无兴趣的共识，直到决赛的时候我们才意识到我们完全低估了医疗+人工智能这种大热门。但从另一个角度来说，我们直接避开了这种组多大佬多竞争激烈的赛道。创意赛道基本都是类似于拼乐高这种乍一看非常有意思但仔细想想不太好做的选题，加上我们觉得这种有意思的题一定很多队选，于是也决定避开。商业赛道我们又觉得过于没意思了一点，于是最后选了剩下的语言赛道。
-
-然后我们发现语言赛道居然就四个队选，那时队友就说：“说不定我们还真能赛道冠军”。
-
-搞完模型后，我们搭了个可以跟模型交互的网站。前端我们用 uni-app 写的，当时想着可以适配小程序，后来发现小程序想上真机的话后端得备案，而显然我们没时间备案了，于是最后在模拟器上录了一个小程序的 demo。
-
-答辩的时候发挥得非常漂亮，而且所有评委的提问都在队友的意料之中，加上的确竞争小，于是就赛道冠军了，并获得了一些奖金。
-
-而决赛的时候我们就发现我们跟医疗和创意赛道的前两名差距也太大了。创意赛道有个队做的是用 AR 辅助拼积木，总之我觉得很有意思，并跟队友说我赌一毛钱那个队会拿总冠军。但在发现评委对医疗赛道的看好和推崇时，我就渐渐觉得我要失去那一毛钱了（最后果然失去了）。
-
-其他收获：
-
-- 根据自己的照片定制的积木（由某届总冠军的已经商业化的项目出品）
-- 导师阵容强大的课（比如在 zoom 上见到了吴恩达老师）
-- 李开复老师签名的书
-- 决赛的时候好像被李开复还是哪个老师提了问
-
-
-## 开源
-
-可能称之为开源并不合适，因为我觉得开源得在维护用户、文档和社区和上下功夫，而不只是把代码挂在 Github 上。总之，去年一个意外的收获是把 GitHub 主页搞得好看了一些。
-
----
-
-因为被导师~~委婉~~直接的评价过深度学习和数学基础不扎实，于是想要把深度学习里面的各种操作手写一遍，遂写了 [Flint](https://github.com/Renovamen/flint)。因为 API 和结构对标 PyTorch，所以我就厚颜无耻的叫它 homemade PyTorch 了，甚至还在 README 里放了一张梗图：
-
-![flint](https://github.com/Renovamen/flint/raw/main/docs/_static/img/meme.png)
-
-现在它已经是一个我比较喜欢的项目了。
-
----
-
-然后是两个有那么一些人在用的项目，有人在用自己写的东西的确能带来好耶的感觉。
-
-一个是博客主题 Gungnir。这最开始是一个 Jekyll 主题，风格严重受到了 [Hux](https://github.com/Huxpro/huxpro.github.io) 和 [Sakura](https://github.com/mashirozx/sakura) 的影响。2020 年的时候我看着我当年啥都不懂的时候魔改的代码感到心烦意乱，而且不知为何我折腾了几次都没用弄好热加载，每次改代码都要手动刷新，更烦，遂决定用 VuePress 重写。去年我学了 React，学完以后我迅速被 Vue 3 的理念说服了并开始无法忍受 Vue 2 的写法。那时 VuePress 1 已经不再更新，基于 Vue 3 的 VuePress 2 进了 beta 阶段。用 Webpack 打包的 VuePress 1 的启动速度太慢了，而 Vite 真的太快了。而且 VuePress 1 不再更新以后，Github 的 Dependabot 天天给我报 alert。综上，去年年底的时候我又把它用 VuePress 2 重写了一遍。
-
-不知为何它现在已经一百多个 star 了，还会有人提 issue 和 pr。有点出乎意料，虽然我不是没有想象过它被人发现的一天，但我最开始的期望只是自己用用就行。
-
-另一个是 Vue 图标组件 [oh-vue-icons](https://github.com/Renovamen/oh-vue-icons)，它可以让你方便的从不同图标库里引入图标。这也是 2020 年开始写的项目，当时觉得在博客里处理不同图标库的图标太过麻烦，于是写了这个出来。去年的时候让它支持了 Vue 3，最初的实现是单独再写一份 Vue 3 版本的代码，后来通过 [vue-demi](https://github.com/vueuse/vue-demi) 实现了在一份代码里同时支持 Vue 2 和 3。
-
----
-
-其他：
-
-- 把当年找实习时写的看上去像个 RPG 游戏实际上是个抽卡游戏的[简历](https://github.com/Renovamen/midgard)升级到了 Vue 3
-- 还在国企实习时写的摸鱼网站 [Fishmail](https://github.com/Renovamen/Fishmail)，可以装作正在看 Gmail 的样子看知乎日报摸鱼
-
-  其实在国企看 Gmail 也非常突兀，而且我并不喜欢看知乎（但我认为的最好的中文技术社区偏偏就在知乎上，所以我得被迫使用它），而且公司里的同事们都是光明正大的摸鱼的
-
-  后来有个 issue 问能不能支持无图模式...这么说还真有人在用它摸鱼吗 (￣口￣)
-
-- 重构了大三为了抵软件测试期末项目在实验室搬砖时写的[语音情感识别](https://github.com/Renovamen/Speech-Emotion-Recognition)，不知为何它的 star 越来越多，现在在 Github 上搜关键词，它甚至会出现在前三位
-
-  上学期我发现同济软院新开了一门课叫语音识别，其期末项目是语音情感识别，只要这门课一直开，我的 star 就能一直涨（狗头
-
-- 在快手天天跟 Transformer 的 masked attention 拉扯时顺手写的带 mask 的 tensor 操作库 [torchmasked](https://github.com/Renovamen/torchmasked)
-
-  除了我以外并没有人在用
-
-- 因为实习在做应用所以看了一些主要贡献在 Transformer / CNN 网络结构上的论文，看完写了一下里面的核心操作：[torchop](https://github.com/Renovamen/torchop)
-
-  并没有看多少篇
-
-- 脑子一热想要写极简 [meta-learning](https://github.com/Renovamen/metallic) 和 [reinforcement learning](https://github.com/Renovamen/alkaid) 库
-  
-  无疾而终，不知道以后还有没有能捡起来的机会
-
-- 还有一些别的在 private repo 里放着的暂时无疾而终的东西
-
-
----
-
-最后是去年最大的意外 [playground-macos](https://github.com/Renovamen/playground-macos)，相当于我另一个更炫酷一点的个人主页，炫酷在于它仿了 macOS 的 UI。这是我第一个千 star 项目，并在 GitHub 和 Hacker News trending 前两位挂了两三天，让我“上一次 Github trending”的愿望提前了八年实现。
-
-那时离截稿日已经相当近了，而我论文还没开始写。即使如此，出于对摸鱼精神的崇敬，我依然决定开始学 React 并写个项目练手，于是这个项目就出现了。我已经忘了我是怎么想到要仿 macOS 的 UI 的，我只记得我基本写完这个项目以后才看到了另外几个同类项目，才意识到当时好像有一股仿 OS 前端项目的潮流。
-
-因为只是随便练手且最开始并没有想到要把它做成 portfolio，所以 repo 名字也取得非常随意，甚至当时连 create-react-app 默认生成的 `index.html` 的 title 都没改。后来做成 portfolio 是因为觉得这网站有那么多可以填充的地方，不利用太可惜了。
-
-一开始是冲着 Big Sur 的风格去的，后来发现很多 Big Sur 的很多细节我都看不到，因为我年迈的 Mac 硬盘剩余空间太小了，系统只能卡在 Catalina 升不上去。所以那些缺失的细节我都是对着 Catalina 来补的，但在宣传时我用了“把 Big Sur 和 Catalina 里我喜欢的部分拿出来拼凑到了一起”这种高情商说法。
-
-写完以后还尝试了一下推广。现在 Reddit 上发了个贴，没啥回应，于是我打算收拾收拾去写论文了，在收拾之前又在 V2EX 和 Hacker News 上发了贴。
-
-然后就炸了。
-
-那两天我目瞪口呆的看着 V2EX 和 Hacker News 上的回复迅速增加，repo 每次刷新都在涨 star 最后还上了 trending，走路甚至都有些飘，以至于我爸妈都对我表示了关切。最开始这个网站搭在 [Vercel](https://vercel.com) 上，两天不到免费带宽就被挤爆了。我琢磨了一下要不要上 CDN，但最后懒得弄，于是手忙脚乱的氪了个 Vercel 的 Pro plan 并在 Github Pages 上也搭了一个分流以勉强应付那几天。我刚开始用 Vercel 的时候还说就我这几个万年没人看的网站怎么都不可能用完免费带宽的，结果用完的那天那么快就来了。收到了比过去二十多年加起来还要多的邮件，除了表示鼓励和询问怎么学前端的，还有一堆让我去他们公司工作或让我接外包的邀请。论坛上的人们还鼓励我“你一定能靠这个项目找到一份前端工作的！”，我哭笑不得心说可我不是前端啊这个项目我甚至写不上简历啊，那时我也没有想到它后来居然真的带给了我意料之外的机会。最出乎意料的是，因为这个网站还仿了我很喜欢的熊掌记的 UI，熊掌记的一个负责人联系了我问我能不能分享到微博上（后来发现他们不但发了微博还发了推特）。我还顺便催了一下熊掌记的新功能，对面告诉我在写了在写了，虽然至今都还没有上线。
-
-这个项目让我今年的社交量比我大学四年加起来还多，甚至和其中一些来交流的人成为了朋友。虽然这些社交都在网上，但我这个没啥社交能力的菜鸡已经很开心了。
-
-不过从全局最优的角度来看的话，我本来应该可以趁这个项目有热度的时候获得更多的 connection，有很多机会被我浪费掉了。如果要找~~借口~~原因的话：
-
-- 那时还没有比较强的发展 connection 的意识
-- 虽然已经在改了，但我社交能力还是不够强，而且对社交有惰性
-- 这项目写完我就去赶论文了，没啥时间，等有时间的时候热度已经过完了
-- 这是一个前端项目，来关注的人自然大多是前端领域的人，和我主要发展的领域没啥太大的重叠
-- 虽然不管是国内还是国外都有很多人表示了关注，但跟我私下联系的人里绝大多数都是国外的人，而我至今都还不知道该怎么跟国外的人发展 connection
-
-另一个发现是，当时讨论这个项目的人绝大多数都默认我是男的。如果说当今中文语境中下的“老哥”及类似的词已经可以算作男女通用的话，那英文论坛和邮件中大量出现的 he / his / sir 也能说明问题。
-
----
-
-论文没产多少，奇怪的项目倒是多了一些，摸鱼果然是第一生产力。
-
-
-## 研究
-
-因为摸鱼强度太高、写奇怪的前端项目成瘾和论文被拒的很惨，去年研究产出远低于“大恶龙要四个月一篇顶会”的预期。希望今年能 all in research 和提高学术写作能力，总不能每次都被审稿人挑一堆 writing issues 出来。
-
-同时，希望能真的进一个研究组，体验随时都有做差不多方向的人跟我讨论问题的感觉。在北大的时候因为一直远程，基本没机会跟组里别的人交流，在快手的时候组里不同的人做的方向又很不一样。因此在这以前我基本都是一个人在看论文和琢磨，能一起讨论的人只有导师和 mentor。但搞研究的话思想碰撞大概相当重要吧。
-
-大三的时候就嚷嚷着想读博，但天平一直在左右摇摆。这几年我好像该折腾的都折腾过了，国企私企，互联网传统行业，大厂 startup，中国公司外国公司，中国大学外国大学，工业界学术界，开发算法研究，失学失业最后终于有书读。听起来就像在刷什么游戏成就，其中大多数成就都集中在去年。我很多时候会懊悔没有集中精力在研究上，觉得乱七八糟的折腾是时间的浪费。我经常会计算，我如果把这里那里的时间拿去做什么什么，我可能会比现在多多少的论文，我可能可以申到怎样的学校。但现在我觉得，这些折腾可以等同于负样本、reward 小的经验和全局最优前的震荡。
-
-在某次面试的时候（算是在面试吧），对面问我对自己 5 年和 10 年以后的期待是什么。这是一个面试经常会被问到的问题，一般来说我会给出一个确切的答案：5 年以后在读博，10 年以后博士已经毕业了，应该会进工业界。但那次我说了实话，我说我不确定，我直到现在也没确定自己想做什么。这种会显得自己没有职业规划的话大概是不应该在面试里说出来的，我会那么说可能是因为当时氛围太过轻松，也可能是因为面试官过于年轻。然后对面告诉我，没有关系，你觉得什么 cool 就去做什么就好了。
-
-那么我觉得什么是 cool 的呢？
-
-某次跟[宇言](https://yuyanzy.github.io/)聊天的时候，我说我能让我开心起来的事，一是无忧无虑的活着，这需要一定的物质条件身体素质和社交圈子来支撑，二就是做 impactful work。我没有任何崇高而远大的理想，我不在乎我的工作能为国家为世界为科学带来怎样的贡献，我也不在乎它们能给人类的生活带来怎样的改变。我就仅仅只是，看着我的工作很 impactful，我就开心。宇言当时对此给出了一个我非常喜欢的比喻：就像一只趴在自己的金山银山上的龙，金山银山对龙来说没有任何价值，但龙就是喜欢这些亮闪闪的东西。
-
-那么，希望有一天我能拥有自己的金山银山吧，嗷呜。
-
-~~虽然现在我连水论文都水不好。~~
-
-
-## 其他
-
-刚去上海的时候，我会思考我们跟上海顶级高中的学生之间的差距是我努把力就能弥补的，还是真的就是资源上的差距。我初高中都在重庆巴蜀中学，巴蜀完全可以相当自信地说自己是重庆的超级中学，其高考竞赛成绩、体育文艺和其他活动、师资、生源、土豪程度等等都是重庆最优秀的。我进了大学以后可以毫无过渡的进入长达四年的颓废期，一定程度上也是因为巴蜀太强劲了，我高中在巴蜀高当了三年的吊车尾，那自然也对在同济再当四年的吊车尾毫无心理负担，何况我在同济好像还不算吊车尾。但上海顶级中学还是有着吊打巴蜀的资源，当时让我有种无力感。
-
-而开始读硕之后，我开始思考我们跟国内和美国顶级本科的学生之间在资源上的差距，这个差距好像更大了。首先同济软工跟国内顶校的计算机相关专业的差距就已经不小了（因为软工不是同济的强势专业，所以甚至弱于一些和同济同等水平甚至水平低于同济的学校的计算机相关专业）。我当然希望同济软院能越来越好，但至少目前它的资源和平台还是配不上它随着大环境飞速上涨的门槛。国内顶校的学生能获得更多的资源，近几年招的老师也大多都有很强的海外背景，这意味着他们在国际上的影响力以及在国外的人脉。这些资源除了对于学生的研究产出有很大的正面影响以外，还让国内顶校的学生在申请海外 Phd 和暑研的时候更容易被捞起来，因为有本校老师的人脉、对方实验室里校友的引荐和口碑、甚至对方实验室的导师本身就是国内顶校出身。这就形成了一个对顶校学生来说是良性但对非顶校学生来说是恶性的循环，非顶校学生想要挤进去的难度太高了点，但如果挤不进去就会永远在这个循环以外。我希望软院（或其他学院）未来能出现很多可以挤进这个循环的大佬，这样软院学生以后的路会好走很多。
-
-而美国顶校学生的优势又更加明显了一点，他们大一实习时在系里随便找的组可能就已经是国内学生想去读博的组了。我在接触一些美国顶校本科生的时候，看着他们的履历一点挣扎的念头都没有，就觉得好像从大一甚至中学开始我就跟他们不在一个赛道上了。在其他的资源和平台方面跟国内相比也基本上是碾压式的差距，但这也是没有办法的事，如果国内大学也像美国那样一年收一二十万的学费，那绝大多数问题也都可以解决，但那样的话包括我在内的绝大多数人大概连大学都读不起。
-
-希望我们有一天也能有吃不完的面包。
-
----
-
-彻底不看朋友圈了。去年前我不看朋友圈是因为看了难受，去年新年的时候我说要培养看朋友圈的习惯，现在不看朋友圈纯粹是因为懒。总感觉看朋友圈就像一个任务，而我不喜欢任务。
-
-动物狂想曲第二季最后一集看得我非常迷惑，前面那么多的铺垫，最后到了该主题升华情感爆发的时候，为什么给人的感觉只能用迷惑来形容。我不知道漫画是怎么处理这一段的，我可以理解它想表达的立意，我也认为这个立意比较抽象和宏大所以不太好表达，我也能接受一些人物的行事不太符合正常逻辑，但最后一集的表现方式还是超出了我的心理承受能力。我太迷惑了。
-
-想换掉用了 5 年的 Mac，但因为想去美帝买更便宜的 Mac 和蹭返校季优惠而没有换，于是我年迈的 Mac 坚强的步入了它的第六个年头。
-
-想换掉用了 5 年的 iPhone，但因为想去美帝买更便宜的 iPhone 和等 iPhone 14 而没有换，于是我年迈的 iPhone 也坚强的步入了它的第六个年头。
-
-买了一个奇怪的 8 寸的 Windows 笔记本，反正我用着挺开心的。
-
-要多社交多社交多社交，虽然说了我也不一定做得到。
-
-
-## 结束
-
-我很久没有过一年以前经常会有的那种难受的感觉了，我甚至已经很难回忆起来那些难受的感受和原因了，虽然我知道它们非常真实的存在过。而我的朋友则迅速地帮我指出了难受的原因：
-
-<img src="/img/in-post/2022-02-21/qq-1.jpg" width="250px" alt="qq-1" />
-
-如果一切痛苦的根源真的就是能力不足，那么摸鱼可以让我不为了能力不足而痛苦。
-
-去年新年的时候，我的另一个愿望是成为一个正常一些甚至温暖的人类。我不确定这个愿望实现了多少。
-
-OPPO hr 面的时候，hr 问我“想成为一个什么样的人”，我说：“我希望能在保持理性的前提下，做一个尽可能温暖的人”，当时脱口而出没有思考和犹豫，因为这真的就是我的愿望。
-
-这也是我今年的愿望。
-
-新年快乐朋友们。
Index: blog/posts/2020-10-07-my-blog.md
===================================================================
diff --git a/blog/posts/2020-10-07-my-blog.md b/blog/posts/2020-10-07-my-blog.md
deleted file mode 100644
--- a/blog/posts/2020-10-07-my-blog.md	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
+++ /dev/null	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
@@ -1,293 +0,0 @@
----
-layout: Post
-title: 关于博客的碎碎念
-subtitle: 部署、优化以及乱七八糟的事
-author: Renovamen
-date: 2020-10-07
-headerImage: /img/in-post/2020-10-07/header.jpg
-permalinkPattern: /post/:year/:month/:day/:slug/
-tags:
-  - 摸鱼
----
-
-“虽然研究进度堪忧，但鱼还是要摸的”，在这样的理念的驱动下，菜鸡最终折腾出了一个目前看上去还算可以的方案。
-
-<!-- more -->
-
-我的博客最初 fork 自 [Huxpro/huxpro.github.io](https://github.com/Huxpro/huxpro.github.io)，用了一段时间之后开始瞎改，把别人干净的代码改得乱七八糟。博客用的是 Jekyll 框架，而 Jekyll 就是 Github Pages 的默认引擎，所以在部署的时候 Github Pages 连 build 这一步都帮你省了。于是在很长一段时间内，作为一只懒惰的菜鸡，我并没有什么动力来折腾这些东西。而现在之所以要折腾，是因为不折腾的确不行了。
-
-::: warning WARNING
-不过这版博客已经是用 VuePress 重写过后的版本了，所以这篇文章中的某些部分已经并不适用了...
-:::
-
-
-## 奇怪的起因
-
-说起来这还是一个漫长的故事。首先我的博客的公式渲染引擎用的是 [Katex](https://katex.org/)，因为它快，比 Mathjax 快多了（可以参考[这里](https://katex.org/)）。
-
-kramdown 的默认数学公式渲染引擎是 Mathjax，而从 `v2.0.0` 开始 kramdown 似乎引入了一些插件来支持 Katex，比如 [kramdown-math-katex](https://github.com/kramdown/math-katex)。那么问题来了，Github Pages 的 Jekyll 是不支持除了[这些插件](https://pages.github.com/versions/)以外的插件的。那么唯一的办法就只有在本地 build 网站，然后把 build 好的文件 push 到 `gh-pages` 分支上去。
-
-不行，这样多麻烦，Jekyll 的天生优势不就没了吗，不然我为啥不用 Hexo 或者 Hugo，它们还比 Jekyll 快，不行不行。
-
-那个时候还没有 Github Actions 这种东西，我又完全不知道别的持续集成方案，就算知道了估计也不想去折腾。于是我在[这里](https://xuc.me/blog/katex-and-jekyll/)看到了一个比较 hack 的方法，首先让 kramdown 以为我们要用 Mathjax：
-
-```yaml{3}
-markdown: kramdown    
-kramdown:
-  math_engine: mathjax
-```
-
-这样 kramdown 就会把像 `$$a + b$$` 这样的公式转换成 Mathjax 能识别的 HTML 形式：
-
-```js
-<script type="math/tex">a + b</script>
-```
-
-然后通过 JavaScript 把 `<script type="math/tex">` 标签里的东西用 Katex 渲染出来：
-
-```js
-$("script[type='math/tex']").replaceWith(function() {
-  var tex = $(this).text();
-  return katex.renderToString(tex, {
-    displayMode: false
-  });
-});
-
-$("script[type='math/tex; mode=display']").replaceWith(function() {
-  var tex = $(this).html();
-  return katex.renderToString(tex.replace(/%.*/g, ''), {
-    displayMode: true
-  });
-});
-```
-
-虽然看上去不太优雅，但好歹能用，本菜鸡的理念是能用就行，于是就这样过了一段时间。直到几个月前，我发现我博客的公式不对劲了，它们突然都变成了这样：`\(a + b\)`。
-
-我一脸懵逼，第一反应是我是不是又把博客哪儿的代码搞崩了，但想了想我似乎也没有动过公式那部分的代码？而且当时我部署在 Coding Pages 上的博客公式还是正常的，那么大概率就是 Github Pages 哪里不对劲了。
-
-搜了一下发现 Github Pages 把 kramdown 的版本更新到了 `v2.2.0`，从这一版开始，为了兼容 Mathjax `v3.x`，kramdown 会把 inline math 转换成 `\(a + b\)` 的形式，把 block math 转换成 `\[a + b\]` 的形式（参考[这个 commit](https://github.com/gettalong/kramdown/commit/c3acf8df1db49d2456050f4456f3f542294e2e8f)），于是上面那段脚本就坏掉了。
-
-于是一切都回到了最初的起点，摆在面前的办法只剩下把在本地用 kramdown `v2.1.0` build 好的网站扔 `gh-pages` 上去。这样干了几个月后懒惰的我实在忍不了了，并决定让 Github Actions 来帮我干这件事。
-
-所以我当初为啥不选 Hexo...
-
-
-## Github Actions
-
-在 repo 下建一个目录 `.github/workflow`，在这个目录下放一个 `.yaml` 格式的 workflow 文件。GitHub 只要发现 `.github/workflows` 下有 `.yaml` 文件，就会自动运行它们。[这里](https://docs.github.com/en/free-pro-team@latest/actions/reference/workflow-syntax-for-github-actions)是 workflow 文件的详细文档。
-
-### Jekyll
-
-[Jekyll 官方](https://jekyllrb.com/docs/continuous-integration/github-actions/)已经给了一个现成的 [action](https://github.com/helaili/jekyll-action)，直接引用它就好：
-
-
-```yaml
-name: build Jekyll site and deploy it to GitHub Pages
-
-# 检测 master 分支上的推送和 pr
-on:
-  push:
-    branches: [ master ]
-  pull_request:
-    branches: [ master ]
-
-jobs:
-  jekyll-build-and-deploy:
-    runs-on: ubuntu-latest
-    steps:
-      - name: checkout
-        uses: actions/checkout@v2
-      
-      # 检测 vendor/bundle 下有没有已经安装好的包
-      # 如果有的话就不用再 bundle install 了，节省时间和资源
-      - name: check cache
-        uses: actions/cache@v1
-        with:
-          path: vendor/bundle
-          key: runner.os−gems−{%raw%}{{ hashFiles('**/Gemfile.lock') }}{% endraw %}
-          restore-keys: |
-            ${{ runner.os }}-gems-
-      
-      # 引用 helaili/jekyll-action 来打包 Jekyll 网站
-      # 并把打包好的文件推到同一个 repo 的 gh-pages 分支
-      - name: build and deploy
-        uses: helaili/jekyll-action@2.0.4
-        env:
-          JEKYLL_PAT: ${{ secrets.GITHUB_TOKEN }}
-        with:
-          target_branch: 'gh-pages'
-```
-
-
-相当于这个 workflow 会自动检测 `master` 分支上的 push 和 pull_request，一旦检测就到准备环境，然后运行 `bundle exec jekyll build` 打包网站，并把打包产物扔 `gh-pages` 分支上去。
-
-需要注意的是必须得有一个 `Gemfile` 和 `Gemfile.lock` 文件，`Gemfile` 里面写上要装的包，比如本博客的 `Gemfile` 长这样：
-
-```ruby
-source 'https://rubygems.org'
-
-gem 'jekyll', '~> 4.0'
-gem 'kramdown', '= 2.1.0'  # 这里为了 Katex 把 kramdown 版本固定在了 2.1.0
-gem 'jemoji', '~> 0.11.1'
-gem 'jekyll-paginate', '~> 1.1.0'
-```
-
-如果用了自定义域名，那就还需要在 `master` 分支放一个 `CNAME`，这样 [helaili/jekyll-action](https://github.com/helaili/jekyll-action) 就会把 `CNAME` 也推到 `gh-pages` 分支去。直接在 `gh-pages` 分支加 `CNAME` 是没有什么用的，因为下次自动推送时它就会被清掉...
-
-
-### Node.js
-
-所有能用 Node.js 搞定的东西（比如这个基于 VuePress 的博客）都能用以下工作流处理：
-
-#### npm
-
-```yaml
-name: build and deploy
-
-# 检测 master 分支上的推送和 pr
-on:
-  push:
-    branches: [ master ]
-  pull_request:
-    branches: [ master ]
-
-jobs:
-  build-and-deploy-vuepress:
-    runs-on: ubuntu-latest
-
-    steps:
-      - name: Checkout
-        uses: actions/checkout@v2
-
-      # Node.js 环境
-      - name: Setup Node
-        uses: actions/setup-node@v2.1.2
-        with:
-          node-version: '12.x'
-
-      - name: Cache dependencies
-        uses: actions/cache@v2
-        with:
-          path: ~/.npm
-          key: ${{ runner.os }}-node-${{ hashFiles('**/package-lock.json') }}
-          restore-keys: |
-            ${{ runner.os }}-node-
-      
-      # npm run build
-      - name: Build
-        run: |
-          npm ci
-          npm run build
-      
-      # 推送到同一个 repo 的 gh-pages 分支
-      - name: Deploy
-        uses: peaceiris/actions-gh-pages@v3
-        with:
-          github_token: ${{ secrets.GITHUB_TOKEN }}
-          publish_dir: dist # build 输出文件夹
-          cname: zxh.io  # 如果用了自定义域名，在这里设置
-```
-
-其中 [peaceiris/actions-gh-pages](https://github.com/peaceiris/actions-gh-pages) 也是一个别人写好的 action，能把指定路径的文件推到 `gh-pages` 分支。
-
-
-#### yarn
-
-如果包管理工具用的 `yarn`：
-
-```yaml
-name: build and deploy
-
-on:
-  push:
-    branches: [ master ]
-  pull_request:
-    branches: [ master ]
-
-jobs:
-  build-and-deploy-vuepress:
-    runs-on: ubuntu-latest
-
-    steps:
-      - name: Checkout
-        uses: actions/checkout@v2
-
-      - name: Setup Node
-        uses: actions/setup-node@v2.1.2
-        with:
-          node-version: '12'
-
-      - name: Get yarn cache
-        id: yarn-cache
-        run: echo "::set-output name=dir::$(yarn cache dir)"
-
-      - name: Cache dependencies
-        uses: actions/cache@v2
-        with:
-          path: ${{ steps.yarn-cache.outputs.dir }}
-          key: ${{ runner.os }}-yarn-${{ hashFiles('**/yarn.lock') }}
-          restore-keys: |
-            ${{ runner.os }}-yarn-
-      
-      - name: Build
-        run: |
-          yarn install --frozen-lockfile
-          yarn build
-      
-      - name: Deploy
-        uses: peaceiris/actions-gh-pages@v3
-        with:
-          github_token: ${{ secrets.GITHUB_TOKEN }}
-          publish_dir: dist
-          cname: zxh.io
-```
-
-## 优化
-
-### 减少依赖
-
-通过砍掉一些觉得用不太上的功能，和直接手写一些比较简单的功能，去掉了一些依赖。但我已经忘了去掉了哪些了...
-
-### 合并依赖
-
-为了减少请求次数，可以尽量把多个 JS 或 CSS 文件合并压缩成一个。上 Gulp 之类的工具当然也可以，不过 jsDelivr 自带了合并功能，比如要合并以下两个库：
-
-- [https://cdn.jsdelivr.net/npm/chart.js@2.9.3/dist/Chart.min.js](https://cdn.jsdelivr.net/npm/chart.js@2.9.3/dist/Chart.min.js)
-- [https://cdn.jsdelivr.net/npm/mermaid@8.4.8/dist/mermaid.min.js](https://cdn.jsdelivr.net/npm/mermaid@8.4.8/dist/mermaid.min.js)
-
-只需要：
-
-```
-https://cdn.jsdelivr.net/combine/npm/chart.js@2.9.3/dist/Chart.min.js,npm/mermaid@8.4.8/dist/mermaid.min.js
-```
-
-于是我把除了 Katex 和 Mathjax（因为这俩涉及到引用字体的问题）以外的文件都合并成了一个 `lib.min.js`。
-
-### CDN
-
-又一次喜闻乐见的白嫖 jsDelivr，对于托管在 Github 上的博客来说，在静态资源路径前加上以下 URL 即可：
-
-```
-https://cdn.jsdelivr.net/gh/{{ 用户名 }}/{{ 仓库名 }}@{{ 分支名 }}
-```
-
-比如：
-
-```
-https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@master/js/lib.min.js
-```
-
-
-## Vercel
-
-我一直以来都在听说双线部署甚至多线部署这种提高访问速度的操作，但一直没有去折腾。因为 Github Pages 虽然境内访问慢了点，但至少还是能访问的，那么能用就行了。直到几个月前，我发现 Github Pages 境内完全访问不上了...
-
-间歇性抽风想想还是很让人不安，那行吧行吧双线部署我来了...
-
-那时候我所知的有境内节点的静态网站托管服务就 [Gitee Pages](https://gitee.com/help/articles/4136) 和 [Coding Pages](https://help.coding.net/docs/devops/cd/static-website.html) 俩，而 Gitee Pages 不能免费自定义域名，于是就把境内的线路解析到了 Coding Pages 上。
-
-然而不久之前，新版 Coding Pages 的静态网站合并到腾讯云静态网站，并开始收费了。之前旧版的静态网站还能正常部署和访问，但之后的网站就都得用新版。收费倒是并不贵且也没有什么问题，问题在于如果域名不备案的话，即使是境内的访问，Coding 也会强制给你上境外 CDN 加速，于是速度会很慢，估计比直接访问 Github Pages 还慢。
-
-于是就手忙脚乱的把境内线路的博客扔到了 Vercel 上。只能说 Vercel 至少到目前为止还没发现什么毛病，有境内节点（不过感觉还是没有以前的 Coding Pages 快？），而且是直接自动从 Github 仓库上拉代码然后打包加部署，对菜鸡相当友好。
-
-以前为啥就没发现呢。
Index: blog/posts/2020-08-24-regularization-based-continual-learning.md
===================================================================
diff --git a/blog/posts/2020-08-24-regularization-based-continual-learning.md b/blog/posts/2020-08-24-regularization-based-continual-learning.md
deleted file mode 100644
--- a/blog/posts/2020-08-24-regularization-based-continual-learning.md	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
+++ /dev/null	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
@@ -1,469 +0,0 @@
----
-layout: Post
-title: Regularization-based Continual Learning
-subtitle: EWC / Online EWC / IS / MAS ...
-author: Renovamen
-date: 2020-08-24
-headerImage: /img/in-post/2020-08-24/header.jpg
-permalinkPattern: /post/:year/:month/:day/:slug/
-tags:
-  - Deep Learning
-  - Continual Learning
-  - Bayesian
----
-
-基于正则（regularization-based）的持续学习：用一个表示参数重要程度的正则项来控制参数在未来的任务中的更新幅度。
-
-<!-- more -->
-
-
-## 持续学习
-
-传统的机器学习要求训练样本之间是 **i.i.d**（**Independent and Identically Distributed，独立同分布**）的，为了达到这个目的往往会随机打乱训练数据。但如果要让模型处理分布在变化的连续数据，如果不做任何处理依然按传统方法来训练，就会出现**灾难性遗忘**（**Catastrophic Forgetting**），因为新的数据会对模型造成干扰（interference）。模型会调整它学到的关于旧数据的参数以适应新任务，这样在旧数据上学到的知识就会被遗忘。
-
-**Continual** / Lifelong / Incremental / Cumulative Learning（**持续学习** / 终身学习 / 增量学习）就是为了解决这个问题（我从未见过命名如此不统一的方向 2333）。标准版持续学习的目标是（叫它标准版是因为最近的很多研究给持续学习加了一些新目标）：
-
-- 学习当前任务
-
-- 解决灾难性遗忘问题
-
-为了搞定灾难性遗忘，常见的三种套路是：
-
-- **Dynamic Expansion**：既然问题在于关于旧任务的参数会被干扰，那就不用这些参数来学习新任务了，直接搞一批新的参数来学新任务。这样模型的参数就会越来越多，所以叫 dynamic expansion。模型参数太多了之后可能会很难训练。为了让参数不要增加得太快，有些方法会加一些模型剪枝知识蒸馏一类的压缩操作进来。
-
-- **Rehearsal**：如果让新任务上的梯度尽可能接近旧任务上的梯度，那在旧任务上学习到的知识就不会被遗忘多少。这种思路需要去搞一些旧数据，而搞旧数据的方法又大概能分为两种：
-
-    - **Extra Memory**：直接存一些旧数据，这样就需要额外的存储空间；
-
-    - **Generative Replay**：用旧数据训练一个生成模型（如 GAN、VAE 等），然后用这个生成模型来生成旧数据。这样不需要额外的存储空间，但模型参数会变多（多了生成模型的参数）。
-
-        不过我很好奇用生成模型模拟旧数据的效果，和把生成模型的权重占的存储空间全拿去存旧数据的效果哪个更好。假设权重几十或几百兆，如果直接把它拿来存旧数据，假设一张图片几百 K（因为大多数持续学习论文的实验设置都是在做图像分类，所以这里考虑存图片），也能存几百张了。考虑到目前生成模型生成的图片质量都没有很高，在存储空间一样大的前提下它的效果能不能超过直接存几百张旧图片的效果我觉得是不一定的。我还是很希望看到有论文做这种对比实验的，不过目前似乎还没看到这样做的？虽然我也没看过多少论文就是了...
-
-- **Regularization**：直觉上来说更优雅的一类方法，毕竟不用额外存储空间也不用增加模型参数。这种方法会加一些正则项来避免跟旧任务关联较大的参数更新幅度过大。这种方法存在的基础是现在的绝大多数神经网络都是过参数化（over-parameterization）的。本文要理的一些方法就属于这一类。
-
-
-## 直觉上的理解
-
-<img src="/img/in-post/2020-08-24/ewc.png" width="400px" alt="EWC" />
-
-<p class="desc">图片来源：论文 <a href="https://arxiv.org/pdf/1612.00796.pdf" target="_blank">Overcoming Catastrophic Forgetting in Neural Networks</a></p>
-
-上图是参数在参数空间里的变化轨迹。蓝色的箭头相当于在任务 $A$（可以推广为旧任务）上训练完之后，直接拿去任务 $B$（可以推广为新任务）上 fine-tune。这样在学完任务 $B$ 之后，基本就把任务 $A$ 忘得差不多了。
-
-那么一个想法是加一个正则项（L2），让在任务 $B$ 上训练完后的参数不能离在任务 $A$ 上训练完后的参数太远，即绿色箭头。但直接加 L2 正则项没有考虑不同参数对任务的重要性，对任务 $A$ 特别重要的参数限制应该大一些，而不那么重要的参数则不用怎么限制，不然任务 $B$ 就学不好了。
-
-于是红色箭头就是很多 regularization-based 的方法的思想：计算一下每个参数 $\theta_i$ 对任务 $A$ 的重要性 $\Omega_i$，然后加了正则项的损失函数变成（$\theta_{A,i}^\text{*}$ 是在任务 $A$ 上训练完后得到的最优参数）：
-
-$$
-L(\theta) = L_B(\theta) + \frac{\lambda}{2} \sum_i \Omega_i (\theta_i - \theta_{A,i}^\text{*})^2
-$$
-
-只不过这些方法计算重要性 $\Omega_i$ 的方式有所不同。
-
-
-## EWC
-
-**Overcoming Catastrophic Forgetting in Neural Networks.** *James Kirkpatrick, et al.* PNAS 2017. [[Paper]](https://arxiv.org/pdf/1612.00796.pdf)
-
-**EWC（Elastic Weight Consolidation）**
-
-### 参数重要性
-
-如果直接上结论的话，参数 $\theta_i$ 的重要性 = Fisher 信息矩阵的第 $i$ 个对角线元素，也即：
-
-$$
-\Omega_i = \frac{1}{|D_A|} \sum_{x \in D_A} \left ( \frac{\partial \log p_\theta(Y = y_x^\text{*} \mid x)}{\partial \theta_i} \Bigg |_{\theta = \theta_A^\text{*}} \right )^2
-$$
-
-其中 $y_x^\text{*}$ 是模型 $p_{\theta_A^\text{*}}(y \mid x)$ 对 $x$ 的输出。
-
-
-
-### 贝叶斯视角
-
-如果按照贝叶斯方法来学习参数的话，灾难性遗忘并不会发生。贝叶斯方法希望估计出参数的后验分布：
-
-$$
-\begin{aligned}
-    p(\theta \mid D) &= \frac{p(\theta, D)}{p(D)} = \frac{p(\theta, D_A, D_B)}{p(D_A, D_B)} \\[10px]
-        & = \frac{p(\theta, D_B \mid D_A) p(D_A)}{p(D_B \mid D_A) p(D_A)} \\[10px]
-        & = \frac{p(\theta, D_B \mid D_A)}{p(D_B \mid D_A)} \\[10px]
-        & = \frac{p(D_B \mid \theta, D_A) p(\theta \mid D_A)}{p(D_B \mid D_A)} \\[10px]
-        & = \frac{p(D_B \mid \theta) p(\theta \mid D_A)}{p(D_B)}
-\end{aligned}
-$$
-
-最后一步是因为 $D_A, D_B$ 相互独立。这个形式实际上就是增量贝叶斯公式（incremental version of Bayes' rule）。
-
-那么有：
-
-$$
-\log p(\theta \mid D) = \log p(D_B \mid \theta) + \log p(\theta \mid D_A) - \log p(D_B)
-$$
-
-对于右边的这三项，第一项 $\log p(D_B \mid \theta)$ 很明显就是 $D_B$ 上的损失函数取负 $-L_B(\theta)$，第三项 $\log p(D_B)$ 是个参数无关的常数，于是优化目标就变为了（实际上就是[最大后验估计（MAP）](/2020/08/16/bayesian-neural-network/#最大后验估计)）：
-
-$$
-\begin{aligned}
-    \theta &= \arg \max_\theta \log p(\theta \mid D) \\
-        &= \arg \max_\theta (- L_B(\theta) + \log p(\theta \mid D_A)) \\
-        &= \arg \min_\theta L_B(\theta) - \log p(\theta \mid D_A)
-\end{aligned}
-$$
-
-可以看到这个优化目标相当于一边最小化 $D_B$ 上的损失，一边最大化 $D_A$ 上的参数后验 $p(\theta \mid D_A)$，从而避免了灾难性遗忘的发生。
-
-那么我们需要求的就是 $p(\theta \mid D_A)$，但这个后验是 intractabe 的，我记得我在好几个地方都写过它为啥 intractabe 所以这里就不写了...那么我们又需要把它近似出来，常用的近似方法大概就是变分推断、MCMC、拉普拉斯（Laplace）近似之类的，论文用了拉普拉斯近似。
-
-btw，可以看到相比 MLE，上式就是多了一项 $- \log p(\theta \mid D_A)$。所以也可以理解为，论文就是在把这一项设计成结构化风险里的正则项。
-
-
-### 拉普拉斯近似
-
-拉普拉斯近似的目标是用一个高斯分布来近似 $p(\theta \mid D_A)$。假设它是个高斯分布：
-
-$$
-\\[2px]
-
-p(\theta \mid D_A) = N(\sigma, \mu) = \frac{1}{\sqrt{2 \pi} \sigma} e^{- \frac{(\theta - \mu)^2}{2 \sigma^2}}
-$$
-
-$$
-\rArr \log p(\theta \mid D_A) = \log \frac{1}{\sqrt{2 \pi} \sigma} - \frac{(\theta - \mu)^2}{2 \sigma^2}
-$$
-
-右边其实是在取 $\ln$，不过这里 $\log$ 和 $\ln$ 没有本质区别。
-
-令 $f(\theta) = \log p(\theta \mid D_A)$，当 $\theta = \theta_A^\text{*}$ 时取最优解，那么在 $\theta = \theta_A^\text{*}$ 处对 $f(\theta)$ [泰勒展开](#泰勒展开)：
-
-$$
-f(\theta) = f(\theta_A^\text{*}) + \underbrace{\Bigg ( \frac{\partial f(\theta)}{\partial \theta} \Bigg |_{\theta = \theta_A^\text{*}}  \Bigg )}_{\text{雅克比矩阵}} (\theta - \theta_A^\text{*}) + \frac{1}{2} (\theta - \theta_A^\text{*})^\top \underbrace{\Bigg ( \frac{\partial^2 f(\theta)}{\partial^2 \theta} \Bigg |_{\theta = \theta_A^\text{*}}  \Bigg )}_{\text{海森矩阵}} (\theta - \theta_A^\text{*}) + o(\theta_A^\text{*}) \\[5px]
-$$
-
-因为 $\theta_A^\text{*}$ 使得 $f(\theta)$ 有极大值（[这里](https://www.cnblogs.com/hapjin/p/8834794.html)似乎证明了一定有这个极大值），所以 $f(\theta)$ 在 $\theta = \theta_A^\text{*}$ 处的一阶导为 0，二阶导为负（海森矩阵负定），并且我们忽略掉三阶及以上的项，那么 $f(\theta)$ 可以近似为：
-
-$$
-f(\theta) = \log \frac{1}{\sqrt{2 \pi} \sigma} - \frac{(\theta - \mu)^2}{2 \sigma^2} \approx f(\theta_A^\text{*}) + \frac{1}{2} (\theta - \theta_A^\text{*})^2 f''(\theta_A^\text{*})
-$$
-
-为了方便这里就不强调矩阵了，记住 $f''(\theta_A^\text{*})$ 是个[海森矩阵](#海森矩阵)就好 2333。因为 $\log \frac{1}{\sqrt{2 \pi} \sigma}$ 和 $f(\theta_A^\text{*})$ 都是参数无关的常数，所以：
-
-$$
-- \frac{(\theta - \mu)^2}{2 \sigma^2} = \frac{(\theta - \theta_A^\text{*})^2}{2} f''(\theta_A^\text{*}) \\[2px]
-$$
-
-所以：
-
-$$
-\mu =  \theta_A^\text{*}
-$$
-
-$$
-\sigma = - \frac{1}{f''(\theta_A^\text{*})}
-$$
-
-高斯分布的两个超参求出来了，$p(\theta \mid D_A)$ 也就求出来了，现在优化目标可以写成：
-
-$$
-\begin{aligned}
-    \theta &= \arg \min_\theta L_B(\theta) - \log p(\theta \mid D_A) \\
-        &= \arg \min_\theta L_B(\theta) - \frac{1}{2} (\theta - \theta_A^\text{*})^2 f''(\theta_A^\text{*})
-\end{aligned}
-$$
-
-$f(\theta_A^\text{*})$ 是个常数所以可以省掉。相当于最大化 $p(\theta \mid D_A)$ 变成了最大化 $\frac{1}{2} (\theta - \theta_A^\text{*})^2 f''(\theta_A^\text{*})$。
-
-那么现在问题又变成了怎么求 $f''(\theta_A^\text{*})$。$f''(\theta_A^\text{*})$ 能直接算出来，但是这里参数 $\theta$ 是 $n$ 维向量，所以 $f''(\theta_A^\text{*})$ 是 $n \times n$ 的海森矩阵，计算的时间和空间复杂度都比较大。为了减小计算开销，论文把海森矩阵转成了 Fisher 信息矩阵。
-
-### Fisher 信息矩阵
-
-首先，一个结论是 Fisher 信息矩阵等于海森矩阵的期望取负（[这里](https://wiseodd.github.io/techblog/2018/03/11/fisher-information/)是证明过程）：
-
-$$
-F_{ij} = - \mathbb{E}[f''(\theta_A^\text{*})] = - \mathbb{E}_{p(\theta \mid D_A)} \left [ \frac{\partial^2 \log p(\theta \mid D_A)}{\partial \theta_i \theta_j} \Bigg |_{\theta = \theta_A^\text{*}} \right ]
-$$
-
-为了省计算量，只取了 Fisher 信息矩阵的对角线，相当于假设各参数之间相互独立：
-
-$$
-F_{ii} = - \mathbb{E}_{p(\theta \mid D_A)} \left [ \frac{\partial^2 \log p(\theta \mid D_A)}{\partial^2 \theta_i} \Bigg |_{\theta = \theta_A^\text{*}} \right ]
-$$
-
-之所以要转成 Fisher 信息矩阵，是因为 Fisher 信息矩阵可以只靠求一阶导算出来（基本定义），一阶导的计算复杂度比二阶导要低很多：
-
-$$
-\\[1px]
-\begin{aligned}
-    F_{ii} &= - \mathbb{E}_{p(\theta \mid D_A)} \left [ \left ( \frac{\partial \log p(\theta \mid D_A)}{\partial \theta_i} \Bigg |_{\theta = \theta_A^\text{*}} \right )^2 \right ] \\[20pt]
-\end{aligned}
-$$
-
-最大化 $\log p(\theta \mid D_A)$ 跟最大化 $\log p(y \mid x)$ 是一个意思，而求期望可以用蒙特卡洛采样来近似，所以：
-
-$$
-F_{ii} \approx - \mathbb{E}_{x \thicksim D_A, y \thicksim p_\theta (y \mid x)} \left [ \left ( \frac{\partial \log p(y \mid x)}{\partial \theta_i} \Bigg |_{\theta = \theta_A^\text{*}} \right )^2 \right ]
-$$
-
-其中 $x$ 是从任务 $A$ 的样本里采样出来的，$y$ 是模型 $p_{\theta_A^\text{*}}(y \mid x)$ 对 $x$ 的输出。这是需要注意的一点，$y$ 是从模型里采样出来的，不是直接从数据分布里采样的。所以求 Fisher 信息矩阵时至少需要再额外来一次反向传播流程，因为需要把 $p_{\theta_A^\text{*}}(y \mid x)$ 的输出拿来当 ground truth，然后重新算一遍损失，然后再求一次梯度。
-
-当然的确也有直接从数据分布里采样 $y$ 的做法，叫 empirical Fisher，这样倒是可以把现成算好的梯度直接拿来用。
-
-论文在算期望时把每个样本都采样了一遍，所以相当于是对每个样本上的梯度的平方求平均：
-
-$$
-F_{ii} = \frac{1}{|D_A|} \sum_{x \in D_A} \left ( \frac{\partial \log p_\theta(Y = y_x^\text{*} \mid x)}{\partial \theta_i} \Bigg |_{\theta = \theta_A^\text{*}} \right )^2
-$$
-
-其中 $y_x^\text{*}$ 是模型 $p_{\theta_A^\text{*}}(y \mid x)$ 对 $x$ 的输出。
-
-于是最终的损失函数为：
-
-$$
-\begin{aligned}
-    L(\theta) &= L_B(\theta) - \frac{\lambda}{2} f''(\theta_A^\text{*}) (\theta - \theta_A^\text{*})^2 \\[5pt]
-        &= L_B(\theta) + \frac{\lambda}{2} \sum_i F_i (\theta_i - \theta_{A,i}^\text{*})^2
-\end{aligned}
-$$
-
-因为 Fisher 信息矩阵是海森矩阵的期望取负，所以这里从减号变成了加号。
-
-我认为的另一个理解方式是，Fisher 信息矩阵也反映了我们对参数估计的不确定度。二阶导越大，说明我们对该参数的估计越确定，同时 Fisher 信息也越大，正则项就越大。于是越确定的参数在后面的任务里更新幅度就越小。
-
-更多关于 Fisher 信息矩阵的细节可以参考我的[这篇博客](/post/2021/07/27/fisher-information-matrix/)。
-
-### 多个任务
-
-考虑一下有三个任务 $D_A, D_B, D_C$ 的情况，这时的参数后验为：
-
-$$
-\log (\theta \mid D_A, D_B, D_C) = \log p(D_C \mid \theta) + \log (\theta \mid D_A, D_B) + \text{constant}
-$$
-
-其中 $\log (\theta \mid D_A, D_B)$ 已经被近似出来了：
-
-$$
-\log (\theta \mid D_A, D_B) \approx \log p(D_B \mid \theta) + \frac{1}{2} \sum_i \lambda_A F_{A, i} (\theta_i - \theta_{A,i}^\text{*})^2 + \text{constant}
-$$
-
-而最大化 $\log p(D_B \mid \theta)$ 跟最大化 $\log p(\theta \mid D_B)$ 是一个意思，$\log p(\theta \mid D_B)$ 又可以近似为：
-
-$$
-\log p(\theta \mid D_B) \approx \frac{1}{2} \sum_i \lambda_B F_{B, i} (\theta_i - \theta_{B,i}^\text{*})^2
-$$
-
-那么 $\log (\theta \mid D_A, D_B, D_C)$ 可以近似为：
-
-$$
-\log (\theta \mid D_A, D_B, D_C) \approx \log p(D_C \mid \theta) + \frac{1}{2} \sum_i \Bigg (\lambda_A F_{A, i} (\theta_i - \theta_{A,i}^\text{*})^2 + \lambda_B F_{B, i} (\theta_i - \theta_{B,i}^\text{*})^2 \Bigg ) + \text{constant}
-$$
-
-相当于 EWC 会针对 $\theta_{A,i}^\text{*}$ 和 $\theta_{B,i}^\text{*}$ 各加一个惩罚项，来保证 $\theta_{C,i}^\text{*}$ 跟 $\theta_{A,i}^\text{*}$ 和 $\theta_{B,i}^\text{*}$ 都尽量接近。如果任务推广到多个，那么 EWC 会为每个历史任务上训练完后的最优参数 $\theta_1^\text{*}, \theta_2^\text{*}, \dots, \theta_{T-1}^\text{*}$ 都维护一个惩罚项，即：
-
-$$
-L_T^\text{regularization} = \frac{1}{2} \sum_i \Bigg ( \sum_{t<T} \lambda_t F_{t, i} (\theta_i - \theta_{t,i}^\text{*})^2 \Bigg )
-$$
-
-所以惩罚项数量会随任务数量线性增长，造成较大的计算开销。而 [Online EWC](#online-ewc) 给出了一个不管有多少任务都只用维护一个惩罚项的解决方案。
-
-
-
-### 其他
-
-- 不同任务上的参数差异较大时，再把泰勒展开的高阶项近似为 0 就很勉强了
-
-- 只取 Fisher 信息矩阵的对角线，相当于假设各参数之间相互独立，但实际上参数之间肯定有关联
-
-- 原论文写得相当简洁，给人一种好像很快就能看明白的错觉，实际上背地里公式推导省略了一大堆 orz
-
-
-## Online EWC
-
-**On Quadratic Penalties in Elastic Weight Consolidation.** *Ferenc Huszár, et al.* arXiv 2017. [[Paper]](https://arxiv.org/pdf/1712.03847.pdf)
-
-EWC 会为每个历史任务上都维护一个惩罚项，所以惩罚项数量会随任务数量线性增长，造成较大的计算开销。但从直觉上来说，$\theta_B^\text{*}$ 本来就是在对 $\theta_A^\text{*}$ 加了惩罚项的情况下估计出来的，那么在估计 $\theta_C^\text{*}$ 的时候就只需要对 $\theta_B^\text{*}$ 加惩罚项就够了，就没必要再维护 $\theta_A^\text{*}$ 的惩罚项了。推广到多个任务，即在估计 $\theta_T^\text{*}$ 的时候只需要维护一个 $\theta_{T-1}^\text{*}$ 的惩罚项就好。
-
-在[上一节](#多个任务)中我们已经得到 $\log (\theta \mid D_A, D_B, D_C)$ 的近似：
-
-$$
-\log (\theta \mid D_A, D_B, D_C) \approx \log p(D_C \mid \theta) + \frac{1}{2} \sum_i \Bigg (\lambda_A F_{A, i} (\theta_i - \theta_{A,i}^\text{*})^2 + \lambda_B F_{B, i} (\theta_i - \theta_{B,i}^\text{*})^2 \Bigg ) + \text{constant}
-$$
-
-现在我们认为 $\theta_{B,i}^\text{*}$ 和 $\theta_{A,i}^\text{*}$ 是差不多的（毕竟这就是 regularization-based 方法的目标），所以 $(\theta_i - \theta_{B,i}^\text{*})$ 和 $(\theta_i - \theta_{A,i}^\text{*})$ 也是差不多的。那么 $\log (\theta \mid D_A, D_B, D_C)$ 可以进一步近似为：
-
-$$
-\log (\theta \mid D_A, D_B, D_C) \approx \log p(D_C \mid \theta) + \frac{1}{2} \sum_i (\lambda_A F_{A, i} + \lambda_B F_{B, i})(\theta_i - \theta_{B,i}^\text{*})^2 + \text{constant}
-$$
-
-推广到 $T$ 个任务，优化目标即为：
-
-$$
-\theta_T^{*} = \arg \min_\theta \left \{ - \log p(D_T \mid \theta) - \frac{1}{2} \sum_i \Bigg ( \sum_{t<T} \lambda_t F_{t, i} \Bigg )(\theta_i - \theta_{T-1,i}^\text{*})^2 \right \}
-$$
-
-所以可以看到，我们并不需要为每个历史任务都维护一个惩罚项，我们只需要对上一个任务训练完后的最优参数加惩罚项就好。
-
-
-**Progress & Compress: A Scalable Framework for Continual Learning.** *Jonathan Schwarz, et al.* arXiv 2018. [[Paper]](https://arxiv.org/pdf/1805.06370.pdf)
-
-
-这就是 Online EWC 的思想，其正则项为：
-
-$$
-L_T^\text{regularization} = \frac{1}{2} \sum_i \hat{F}_{T-1, i}(\theta_i - \theta_{T-1,i}^\text{*})^2
-$$
-
-其中 $\hat{F}$ 是 Fisher 信息矩阵 $F$ 的（带权）累加和：
-
-$$
-\hat{F}_t = \gamma \hat{F}_{t-1} + F_t
-$$
-
-$$
-\hat{F}_1 = F_1
-$$
-
-$\gamma < 1$ 是一个超参数，相当于之前的任务上的算出来的参数重要性对最终结果的贡献会逐渐降低。
-
-P.S. 讲道理我也不知道它为啥要取 online EWC 这个名字，我第一眼看到这个名字还以为它要往 online learning 上靠，结果并没有...
-
-
-
-## MAS
-
-**Memory Aware Synapses: Learning What (Not) to Forget.** *Rahaf Aljundi, et al.* ECCV 2018. [[Paper]](https://arxiv.org/pdf/1711.09601.pdf) [[Code]](https://github.com/rahafaljundi/MAS-Memory-Aware-Synapses)
-
-**MAS（Memory Aware Synapses）**
-
-
-### 参数重要性
-
-对于第 $k$ 个输入数据点 $x_k$，如果对第 $i$ 个参数 $\theta_i$ 做了一个很小的改变 $\delta$，就让模型 $F$ 的输出结果有了很大的变化，就说明 $\theta_i$ 是很重要的。
-
-模型输出对所有参数 $\theta = \{\theta_i\}$ 的变化的变化量可以近似为：
-
-$$
-F(x_k;\theta + \delta) - F(x_k; \theta) \approx \sum_i g_i (x_k) \delta_i
-$$
-
-$$
-\rArr g_i(x_k) \approx \frac{\partial F(x_k)}{\partial \theta_i}
-$$
-
-$g_i(x_k)$ 可以被看做参数 $\theta_i$ 的变化对模型对样本 $x_k$ 的输出的影响。可以看到 $g_i(x_k)$ 就是模型函数对参数 $\theta_i$ 的偏导。
-
-重要性 $\Omega_i$ 为所有样本上的偏导的均值：
-
-$$
-\Omega_i = \frac{1}{N} \sum_{k=1}^N \| g_i(x_k) \|
-$$
-
-每个任务训练完后，都会算一个刚训练完的任务中每个参数的重要性，然后累加到之前的 $\Omega_i$ 上。一直累加可能会让 $\Omega_i$ 变得很大，造成梯度爆炸，于是该论文一作后来的一篇工作 [Task-Free Continual Learning](https://arxiv.org/pdf/1812.03596.pdf) 中用的是迄今为止所有 $\Omega_i$ 的平均值。
-
-
-### L2 范数
-
-大多数神经网络的输出 $F(x_k;\theta)$ 都是一个 $n$ 维向量，比如分类任务会输出每个类别上的概率。这样在求每个 $g_i(x_k)$ 的时候，算的都是向量的偏导，需要做 $n$ 次反向传播。
-
-为了降低计算复杂度，论文给了另一个可选的方法：对 $F(x_k;\theta)$ 的 [L2 范数](#l2-范数-1)（的平方）求偏导，这样算的就是标量的偏导了，只需要一次反向传播：
-
-$$
-\\[2px]
-g_i(x_k) = \frac{\partial [\ell_2^2 (F(x_k))]}{\partial \theta_i}
-$$
-
-
-## IS
-
-**Continual Learning Through Synaptic Intelligence.** *Friedemann Zenke, et al.* ICML 2017. [[Paper]](https://arxiv.org/pdf/1703.04200.pdf) [[Code]](https://github.com/ganguli-lab/pathint)
-
-**IS（Intelligent Synapses）**
-
-MAS 算的是参数改变对模型输出的影响，而 IS 算的是参数改变对损失函数的影响：
-
-$$
-L(\theta(t) + \delta(t)) - L(\theta(t)) \approx \sum_i g_i (t) \delta_i(t)
-$$
-
-$$
-\rArr g_i(t) \approx \frac{\partial L}{\partial \theta_i}
-$$
-
-其中 $\theta(t)$ 为任务 $t$ 训练完后的参数。如果算一个任务 $\mu-1$ 到任务 $\mu$ 的更新轨迹上所有微小变化的总和，即对更新开始时刻 $t^{\mu-1}$ 到结束时刻 $t^\mu$ 积分：
-
-$$
-\begin{aligned}
-    \int_{t^{\mu-1}}^{t^\mu} g(t) \delta(t) dt &= \sum_i \int_{t^{\mu-1}}^{t^\mu} g_i(t) \delta_i(t) dt \\
-        &= - \sum_i \omega_i^\mu
-\end{aligned}
-$$
-
-$$
-\rArr \omega_i^\mu = - \int_{t^{\mu-1}}^{t^\mu} g_i(t) \delta_i(t) dt
-$$
-
-$\omega_i^\mu$ 就是参数 $\theta_i$ 的变化对损失函数输出的影响。在 offline 场景下，$\omega_i^\mu$ 直接就能通过损失函数输出值的变化量算出来。与 EWC 和 MAS 不同的是，IS 还可以在 online 场景下计算 $\omega_i^\mu$，这时 $g_i(t)$ 可以用 $g_i(t) = \frac{\partial L}{\partial \theta_i}$ 来近似，而 $\delta_i(t)$ 就相当于 $\delta_i(t) = \theta_i'(t) = \frac{\partial \theta_i}{\partial t}$。
-
-最后，参数重要性的计算公式为：
-
-$$
-\Omega_i^\mu = \sum_{\nu < \mu} \frac{\omega_\nu^\mu}{(\Delta_i^\nu)^2 + \xi}
-$$
-
-其中 $\Delta_i^\nu = \theta_i(t^\nu) - \theta_i(t^{\nu-1})$ 是为了保证 $\Omega_i^\mu$ 的尺度跟损失函数输出值的尺度是差不多的。为了避免分母为 0 所以加了一个 $\xi$。
-
-
-## 附录
-
-### 海森矩阵
-
-令 $x = (x_1, x_2, \dots, x_n)$，多元函数 $f(x)$ 在 $x=x_0$ 处的的二阶偏导是一个海森矩阵（Hessian matrix）：
-
-$$
-\\[1pt]
-f''(x_0) = H = 
-
-\begin{bmatrix}
-    \frac{\partial f}{\partial x_1 x_1} & \frac{\partial f}{\partial x_1 x_2} & \dots & \frac{\partial f}{\partial x_1 x_n} \\[5pt]
-    \frac{\partial f}{\partial x_2 x_1} & \frac{\partial f}{\partial x_2 x_2} & \dots & \frac{\partial f}{\partial x_2 x_n} \\[5pt]
-    \vdots & \vdots & \ddots & \vdots \\[5pt]
-    \frac{\partial f}{\partial x_n x_1} & \frac{\partial f}{\partial x_n x_2} & \dots & \frac{\partial f}{\partial x_n x_n} \\
-\end{bmatrix}_{x=x_0}
-$$
-
-
-### 泰勒展开
-
-$f(x)$ 在 $x = x_0$ 处的泰勒展开公式为：
-
-$$
-f(x) = \frac{f(x_0)}{0!} + \frac{f'(x_0)}{1!} \cdot (x - x_0) + \frac{f''(x_0)}{2!} \cdot (x - x_0)^2 + o(x_0) \\[2px]
-$$
-
-$o(x_0)$ 为高阶项。在 $f(x)$ 是多元函数的情况下，一阶导要写成雅克比矩阵（Jacobian matrix），二阶导要写成海森矩阵：
-
-$$
-f(x) = \frac{f(x_0)}{0!} + \frac{J_f(x_0)}{1!} \cdot (x - x_0) + (x - x_0)^\top \cdot \frac{H_f(x_0)}{2!} \cdot (x - x_0) + o(x_0) \\[2px]
-$$
-
-### L2 范数
-
-向量 $x = [ x_1, x_2, \dots, x_n ]$ 的 L2 范数（L2 norm）为：
-
-$$
-\| x \|_2 = \sqrt{\Big ( \sum_{i=1}^n |x_i|^2 \Big )}
-$$
-
-
-## 参考
-
-- [Three Scenarios for Continual Learning.](https://arxiv.org/pdf/1904.07734.pdf) *Gido M. van de Ven, et al.* arXiv 2019.
-
-- [Elastic Weight Consolidation (EWC): Nuts and Bolts.](https://abhishekaich27.github.io/data/WriteUps/EWC_nuts_and_bolts.pdf) *Abhishek Aich.*
-
-- [终身持续学习-可塑权重巩固（Elastic Weight Consolidation）](https://zhuanlan.zhihu.com/p/86365066)
-
-- [Fisher Information Matrix](https://wiseodd.github.io/techblog/2018/03/11/fisher-information/)
-
-- [费雪信息 (Fisher information) 的直观意义是什么？](https://www.zhihu.com/question/26561604)
-
-- [Fisher Information 学习笔记](https://blog.csdn.net/lanran2/article/details/77995062)
Index: blog/posts/2019-02-15-rnn-with-its-friends.md
===================================================================
diff --git a/blog/posts/2019-02-15-rnn-with-its-friends.md b/blog/posts/2019-02-15-rnn-with-its-friends.md
deleted file mode 100644
--- a/blog/posts/2019-02-15-rnn-with-its-friends.md	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
+++ /dev/null	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
@@ -1,375 +0,0 @@
----
-layout: Post
-title: RNN 和它的朋友们
-subtitle: RNN, LSTM, GRU ...
-author: Renovamen
-date: 2019-02-15
-headerImage: /img/in-post/2019-02-15/header.jpg
-permalinkPattern: /post/:year/:month/:day/:slug/
-tags:
-  - Deep Learning
----
-
-对 RNN 系成员的一些总结。
-
-<!-- more -->
-
-## RNN
-
-这是一个三维低等生物眼里的 RNN：
-
-<img src="/img/in-post/2019-02-15/rnn/rolled.png" width="100px" alt="Rolled RNN" />
-
-这个细胞（绿色的框）相当于 Keras 中一层 RNN 的隐藏层，一个隐藏层可能有多个神经元。它在 $t$ 时刻的状态（隐状态）叫做 $h_t$，是一个向量，向量维数与这个隐藏层的神经元数量相等，每个神经元的值都是一个标量。
-
-这是一个四维高等生物眼里的 RNN（按时间步展开）：
-
-<img src="/img/in-post/2019-02-15/rnn/unrolled.png" width="600px" alt="Unrolled RNN" />
-
-如果画得详细一点：
-
-<img src="/img/in-post/2019-02-15/rnn/unrolled-details.png" width="500px" alt="Unrolled RNN's Details" />
-
-其中：
-
-- $x_t$：$t$ 时刻的输入向量；
-- $h_t$：$t$ 时刻的隐状态；
-- $o_t$：$t$ 时刻的输出（只由 $h_t$ 决定）；
-- $L_t$：$t$ 时刻的损失函数，最终的损失函数是 $\sum_t L_t$；
-- $y_t$：$t$ 时刻的真实结果（ground truth）；
-- $W^x, W^h, W^o$：权重矩阵，要学习的参数，在所有时间步中都是共享的；
-
-
-上一个时间步的隐状态 $h_{t-1}$ 会在 $t$ 时刻乘一个权重矩阵 $W^h$ 然后重新输入细胞，也就是 $h_t$ 同时依赖于 $x_t$ 和 $h_{t-1}$。
-
-### 前向传播
-
-符号说明：
-
-- $f(\cdot), g(\cdot)$：激活函数；
-- $b$：偏置向量（bias）；
-- $\hat{y}_t$：模型在 $t$ 时刻的最终输出；
-
-公式：
-
-$$
-h_t = f (W^x x_t + W^h h_{t-1} + b_h) 
-$$
-
-$$
-o_t = W^o h_t + b_o
-$$
-
-$$
-\hat{y}_t = g(o_t)
-$$
-
-损失函数 $L_t$ 的作用就是量化模型在当前位置的损失，即 $\hat{y}_t$ 和 $y_t$ 的差距。
-
-### 反向传播
-
-整体损失函数：
-
-$$
-L = \sum_t^n L_t
-$$
-
-
-有参数 $W^x, W^o, W^h, b_o, b_h$，先对它们随机初始化，然后在每个迭代周期对各参数求梯度，并按梯度的方向更新这些参数以使 $L$ 最小化：
-
-$$
-W_{t+1} = W_t - r \cdot  \frac{\partial L}{\partial W} \mid_{W:W_t}, r > 0
-$$
-
-其中 $r$ 是学习率，$\frac{\partial L}{\partial W}$ 是损失函数在 $W=W_t$ 位置的偏导数，即梯度。
-
-$W^o, b_o$ 没有长期依赖，所以偏导好求一些：
-
-$$
-\frac{\partial L}{\partial W^o}
-= \sum_{t=1}^n \frac{\partial L_t}{\partial W^o}
-= \sum_{t=1}^n (\hat{y}_t - y_t)(h_t)^T
-(= \sum_{t=1}^n \frac{\partial L_t}{\partial o_t} \cdot \frac{\partial o_t}{\partial W^o})
-$$
-
-$$
-\frac{\partial L}{\partial b_o} 
-= \sum_{t=1}^n \frac{\partial L_t}{\partial b^o}
-= \sum_{t=1}^n \hat{y}_t - y_t
-$$
-
-
-
-而正向传播中，$h_t$ 对 $h_{t+1}$ 还有贡献，所以反向传播计算 $W_x, W_h$ 在 $t$ 时刻的梯度时，还需要考虑 $t+1$ 时刻的梯度（全导数）。
-
-先求 $t$ 时刻隐状态的梯度：
-
-- 当 $t < n$ 时，需要从 $t+1$ 时刻递推到 $t$ 时刻隐状态的梯度：
-
-  $$
-  \frac{\partial L}{\partial h_t} 
-  = (\frac{\partial o_t}{\partial h_t})^T \frac{\partial L}{\partial o_t} + (\frac{\partial h_{t+1}}{\partial h_t})^T \frac{\partial L}{\partial h_{t+1}}
-  $$
-
-  $$
-  = (W^o)^T(\hat{y}_t - y_t) + (\frac{\partial h_{t+1}}{\partial z_{t+1}} \frac{\partial z_{t+1}}{\partial h_t})^T \frac{\partial L}{\partial h_{t+1}}
-  $$
-
-  $$
-  = (W^o)^T(\hat{y}_t - y_t) + (\text{diag} (1 - h_{t+1})^2 W^h)^T \frac{\partial L}{\partial h_{t+1}}
-  $$
-
-  $$
-  = (W^o)^T(\hat{y}_t - y_t) + (W^h)^T \text{diag} (1 - h_{t+1})^2 \frac{\partial L}{\partial h_{t+1}}
-  $$
-
-- 当 $t = n$ 时，因为已经是最后一个时刻了，所以：
-
-  $$
-  \frac{\partial L}{\partial h_n} 
-  = (\frac{\partial o_n}{\partial h_n})^T \frac{\partial L}{\partial o_n}
-  = (W^o)^T(\hat{y}_n - y_n)
-  $$
-
-然后 $W^h, W^x, b_o$ 的梯度为：
-
-$$
-\frac{\partial L}{\partial W_h} = \sum_{t=1}^n \text{diag} (1-h_t^2) \frac{\partial L}{\partial h_t} h_{t-1}^T
-$$
-
-$$
-\frac{\partial L}{\partial W_x} = \sum_{t=1}^n \text{diag} (1-h_t^2) \frac{\partial L}{\partial h_t} x_t^T
-$$
-
-$$
-\frac{\partial L}{\partial b_o} = \sum_{t=1}^n \text{diag} (1-h_t^2) \frac{\partial L}{\partial h_t}
-$$
-
-
-
-### 梯度消失和爆炸
-
-如果直接把 $W^h$ 在 $t$ 时刻的偏导式展开：
-
-$$
-\frac{\partial L_t}{\partial W^h} = 
-\frac{\partial L_t}{\partial o_t} \frac{\partial o_t}{\partial h_t} \frac{\partial h_t}{\partial W^h} + 
-\frac{\partial L_t}{\partial o_t} \frac{\partial o_t}{\partial h_t} \frac{\partial h_t}{\partial h_{t-1}} \frac{\partial h_{t-1}}{\partial W^h} + 
-... + 
-\frac{\partial L_t}{\partial o_t} \frac{\partial o_t}{\partial h_t} \frac{\partial h_t}{\partial h_{t-1}} \frac{\partial h_{t-1}}{\partial h_{t-2}} ... \frac{\partial h_2}{\partial h_1} \frac{\partial h_1}{\partial W^h} = 
-$$
-
-$$
-\sum_{k=0}^t \frac{\partial L_t}{\partial o_t} \frac{\partial o_t}{\partial h_t} (\prod_{j=k+1}^t \frac{\partial h_j}{\partial h_{j-1}}) \frac{\partial h_k}{\partial W^h}
-$$
-
-同理，$W^x$ 在 $t$ 时刻的偏导式展开为：
-
-$$
-\frac{\partial L_t}{\partial W^x} = \sum_{k=0}^t \frac{\partial L_t}{\partial o_t} \frac{\partial o_t}{\partial h_t} (\prod_{j=k+1}^t \frac{\partial h_j}{\partial h_{j-1}}) \frac{\partial h_k}{\partial W^x}
-$$
-
-$h$ 通过激活函数得到，假设激活函数为 tanh：
-
-$$
-h_j = \text{tanh} (W^x W_j + W^h h_{j-1} + b_h)
-$$
-
-$$
-\prod_{j=k+1}^t \frac{\partial h_j}{\partial h_{j-1}} = \prod_{j=k+1}^t \frac{\partial h_j}{\partial h_{j-1}} \text{tanh}' W^h
-$$
-
-tanh 函数的函数图像和导数图像为：
-
-<img src="/img/in-post/2019-02-15/rnn/tanh.png" width="400px" alt="tanh function" />
-
-假设激活函数为 sigmoid：
-
-$$
-\prod_{j=k+1}^t \frac{\partial h_j}{\partial h_{j-1}} = \prod_{j=k+1}^t \frac{\partial h_j}{\partial h_{j-1}} \sigma' W^h
-$$
-
-sigmoid 函数的函数图像和导数图像为：
-
-<img src="/img/in-post/2019-02-15/rnn/sigmoid.jpeg" width="500px" alt="sigmoid function" />
-
-**梯度消失：**
-
-可以看到，这俩函数的导数范围都不会超过 1，如果 $W^h$ 的初始化值也在 $[0, 1]$ 之间，那么就是一堆 $[0, 1]$ 之间的小数在连乘，乘到最后就会导致梯度越来越接近于 0，造成梯度消失。
-
-在 DNN 中，某一层的梯度消失就意味着那一层的参数再也不更新，那一层的隐层就变成了单纯的映射层。
-
-而 RNN 中，梯度是累加的，就算较远时刻的梯度趋近于 0，累加后的整体梯度依然不会为 0，整体梯度是不会消失的。但这会造成 RNN 被近距离梯度主导，只能利用的有限的历史数据，难以学到远距离的依赖关系。
-
-但相比 sigmoid，tanh 函数的梯度还是更大一点，所以收敛速度要快一些，且引起梯度消失更慢。
-
-而解决梯度消失可以靠换激活函数（ReLU、LeakyReLU、ELU 等）或改传播结构（LSTM、Batch Normalization、ResNet 残差结构）。
-
-如，ReLU 激活函数的函数图像和导数图像为：
-
-<img src="/img/in-post/2019-02-15/rnn/relu.jpeg" width="500px" alt="relu function" />
-
-因为 $y$ 轴右侧导数恒为 1，所以避免了梯度消失的问题。但恒为 1 的导数容易导致梯度爆炸，所以需要一些调参技巧，比如给梯度设定合适的阈值，如果大于这个阈值，就按这个阈值进行更新。
-
-**梯度爆炸：**
-
-而如果 $W^h$ 的初始化值非常大，那连乘起来就会梯度爆炸。梯度爆炸意味着可能因为过大的优化幅度而跨过最优解，导致前面的学习过程白费。
-
-
-## LSTM
-
-**Long Short-Term Memory.** *Sepp Hochreiter and Jürgen Schmidhuber.* Neural Computation 1997. [[Paper]](https://www.bioinf.jku.at/publications/older/2604.pdf)
-
-一般来说应该放一张这样的图：
-
-<img src="/img/in-post/2019-02-15/lstm/lstm1.png" width="500px" alt="LSTM" />
-
-同样，这个细胞相当于 Keras 中一层 LSTM 的隐藏层，隐藏层里有四个前馈网络层。图里的 4 个黄色框每个都是一个前馈网络层，它们的激活函数分别为 sigmoid（1，2，4）和 tanh（3）。
-
-Hidden Units（Keras 的 `units`）就是每个前馈网络层的神经元个数。
-
-
-另一种画法（论文 [Show and Tell](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Vinyals_Show_and_Tell_2015_CVPR_paper.pdf)），虽然它似乎把 output gate $o$ 写成了 output gate $f$（...）：
-
-<img src="/img/in-post/2019-02-15/lstm/lstm2.png" width="350px" alt="Also a LSTM" />
-
-
-LSTM 的核心是一个由 3 个门控制的记忆细胞 $c$。$t-1$ 时的隐状态 $h_{t-1}$ 会被用于当前细胞状态的损失计算，和下一细胞状态（$t$ 时）的隐状态 $h_t$ 的计算，所以 $h_{t-1}$ 会在 $t$ 时经过这 3 个门重新进入细胞。
-
-
-### 前向传播
-
-传播流程：
-
-<img src="/img/in-post/2019-02-15/lstm/lstm-forward.png" width="250px" alt="LSTM Forward" />
-
-后面公式中的符号说明：
-
-- $\sigma(\cdot)$：sigmoid 激活函数，会把矩阵转换为一个介于 0 和 1 之间的值作为门控信号，0 表示完全遗忘，1 表示完全接受；
-- $\text{tanh}(\cdot)$：tanh 激活函数，会把矩阵转换为一个介于 -1 和 1 之间的值；
-- $\odot$：哈达玛积（Hadamard Product），即俩矩阵对应元素相乘，所以要求俩矩阵同形
-
-#### 遗忘门
-
-<img src="/img/in-post/2019-02-15/lstm/forget.png" width="250px" alt="Forget Gate" />
-
-Forget Gate，对上一个细胞状态传进来的信息进行选择性遗忘。会根据 $h_{t-1}$ 和 $x_t$ 来为上一个细胞状态 $c_{t-1}$ 计算一个门控信号，计算公式为：
-
-$$
-f_t = \sigma (W_{fx} x_t + W_{fh} h_{t-1} + b_f)
-$$
-
-然后把 $f_t$ 跟 $c_{t-1}$ 相乘，就是最终从上一个状态输入的内容：
-
-$$
-f_t \odot c_{t-1}
-$$
-
-#### 输入门
-
-<img src="/img/in-post/2019-02-15/lstm/input.png" width="250px" alt="Input Gate" />
-
-Input Gate，对现阶段输入 $x_t$ 进行选择性记忆，更新细胞状态。由两个部分构成：
-
-- sigmoid 激活函数，计算门控信号，控制要记忆哪些内容：
-
-  $$
-  i_t = \sigma (W_{ix} x_t + W_{ih} h_{t-1} + b_i)
-  $$
-
-- tanh 激活函数，计算现阶段新学到的东西：
-
-  $$
-  \tilde{c}_t = \text{tanh}(W_{cx} x_t + W_{ch} h_{t-1} + b_c)
-  $$
-
-这俩相乘后的结果就是最终被记下来的现阶段新学到的东西，再加上从上一个细胞状态输入的内容就是更新后的细胞状态。所以细胞状态的更新公式为：
-
-$$
-c_t = f_t \odot c_{t-1} + i_t \odot \tilde{c}_t
-$$
-
-
-#### 输出门
-
-<img src="/img/in-post/2019-02-15/lstm/output.png" width="250px" alt="Output Gate" />
-
-Output Gate，现在细胞状态已经更新了，所以要决定那些状态最终会被输出（隐状态 $h_t$）。依然用 sigmoid 激活函数来计算一个门控信号，控制要输出哪些内容：
-
-  $$
-  o_t = \sigma (W_{ox} x_t + W_{oh} h_{t-1} + b_o)
-  $$
-
-然后把它跟用 tanh 激活函数放缩过的当前细胞状态 $c_t$ 相乘，就是这个阶段最终输出的隐状态：
-
-$$
-h_t = o_t \odot \text{tanh}(c_t)
-$$
-
-#### 最终输出
-
-最终的输出 $y_t$ 会由 $h_t$ 变换得到，常见的做法大概是把 $h_t$ 扔进 softmax：
-
-$$
-y_t = \text{softmax}(h_t)
-$$
-
-
-### 反向传播
-
-传播流程：
-
-<img src="/img/in-post/2019-02-15/lstm/lstm-backward.png" width="250px" alt="LSTM Backward" />
-
-公式以后再说，我已经跑偏太多了...
-
-
-## GRU
-
-<img src="/img/in-post/2019-02-15/gru/gru.png" width="280px" alt="GRU" />
-
-GRU 是 LSTM 的变体。它只有两个门，重置门 $r_t$ 和更新门 $z_t$（用一个门达到了遗忘和输入的目的）。它还合并了隐状态和细胞状态。它的模型结构比 LSTM 简单，但同时能达到跟 LSTM 相当的效果。
-
-### 重置门
-
-Reset Gate，先计算重置门控信号 $r_t$，用于控制要保留上一个时刻的多少信息：
-
-$$
-r_t = \sigma (W_{rx} x_t + W_{rh} h_{t-1} + b_r)
-$$
-
-然后计算当前时刻的候选隐状态（candidate hidden state）：
-
-$$
-\hat{h}_t = \text{tanh} (W_{hx} x_t + r_t \odot (W_{hh} h_{t-1}) + b_h)
-$$
-
-相当于 $\hat{h}_t$ 主要包含了当前输入 $x_t$ 的信息，然后有选择性的加入上一时刻的信息（$h_{t-1}$）。
-
-
-### 更新门
-
-Update Gate，先计算更新门控信号 $z_t$，用于控制要从 $h_{t-1}$ 中遗忘多少信息和要从 $\hat{h}_t$ 中记忆多少信息：
-
-$$
-z_t = \sigma (W_{zx} x_t + W_{zh} h_{t-1} + b_z)
-$$
-
-然后直接算出当前时刻隐状态 $h_t$：
-
-$$
-h_t = (1 - z_t) \odot h_{t-1} + z_t \odot \hat{h}_t
-$$
-
-可以理解为 $(1 - z_t)$ 对标 LSTM 中的遗忘门控，$z_t$ 对标 LSTM 中的输入门控。
-
-
-
-## Reference
-
-- [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)
-- [LSTM Forward and Backward Pass](http://arunmallya.github.io/writeups/nn/lstm/index.html#/)
-- [What is actually num_unit in LSTM cell circuit?](https://stackoverflow.com/questions/49225326/what-is-actually-num-unit-in-lstm-cell-circuit/49309905#49309905)
-- [RNN 循环神经网络 基本结构类型](https://blog.csdn.net/qq_16234613/article/details/79476763)
-- [循环神经网络（RNN）模型与前向反向传播算法](https://www.cnblogs.com/pinard/p/6509630.html)
-- [LSTM 模型与前向反向传播算法](https://www.cnblogs.com/pinard/p/6519110.html)
Index: blog/posts/2018-02-17-nlp-resource.md
===================================================================
diff --git a/blog/posts/2018-02-17-nlp-resource.md b/blog/posts/2018-02-17-nlp-resource.md
deleted file mode 100644
--- a/blog/posts/2018-02-17-nlp-resource.md	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
+++ /dev/null	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
@@ -1,115 +0,0 @@
----
-layout: Post
-title: NLP 不入门直接放弃
-subtitle: How to give up NLP
-author: Renovamen
-date: 2018-02-17
-headerImage: /img/in-post/2018-02-17/header.jpg
-permalinkPattern: /post/:year/:month/:day/:slug/
-tags:
-  - NLP
----
-
-来源：[Melanie Tosik（Twitter:@meltomene）列出的 NLP 学习资源清单](https://towardsdatascience.com/how-to-get-started-in-nlp-6a62aa4eaeff)
-
-<!-- more -->
-
-## Online courses
-
-- [Dan Jurafsky & Chris Manning: Natural Language Processing](https://www.youtube.com/playlist?list=PL8FFE3F391203C98C)
-
-- [Stanford CS224d: Deep Learning for Natural Language Processing](http://cs224d.stanford.edu/syllabus.html) [更高级的机器学习算法、深度学习和 NLP 的神经网络架构]
-
-- [Coursera: Introduction to Natural Language Processing](https://www.youtube.com/playlist?list=PLLssT5z_DsK8BdawOVCCaTCO99Ya58ryR) [密西根大学的 NLP 课程]
-
-## Libraries and open source
-
-- **spaCy** ([website](https://spacy.io), [blog](https://explosion.ai/blog/))	[Python；新兴的开放源码库并自带[炫酷的用法示例](https://spacy.io/usage/spacy-101)、API 文档和[演示应用程序](https://spacy.io/docs/usage/showcase)]
-
-- **Natural Language Toolkit (NLTK)** ([website](http://www.nltk.org/), [book](http://www.nltk.org/book/))	[Python；NLP 实用编程介绍，主要用于教学目的]
-
-- **Stanford CoreNLP** ([website](https://stanfordnlp.github.io/CoreNLP/))	[由 Java 开发的高质量的自然语言分析工具包]
-
-- **AllenNLP** ([website](https://allennlp.org/))	[Python；基于 PyTorch 的 NLP 研究库]
-
-- **fastText** ([website](https://fasttext.cc/))	[C++；高效的文本分类（text classification）和表示学习（representation learning）工具]
-
-## Active blogs
-
-- [language processing blog](https://nlpers.blogspot.com/natural)	（Hal Daumé III）
-
-- [Language Log](http://languagelog.ldc.upenn.edu/nll/)	（Mark Liberman）
-
-- [Google Research blog](https://research.googleblog.com/)
-
-- [Explosion AI blog](https://explosion.ai/blog/)
-
-- [Hugging Face](https://medium.com/huggingface)
-
-- [Sebastian Ruder’s blog](http://ruder.io/#open)
-
-## Books
-
-- [Speech and Language Processing](https://web.stanford.edu/~jurafsky/slp3/)	（Jurafsky and Martin）[经典的 NLP 教科书，涵盖了所有 NLP 的基础知识，第 3 版即将出版]
-
-- [Foundations of Statistical Natural Language Processing](https://nlp.stanford.edu/fsnlp/)	（Manning and Schütze）[更高级的统计 NLP 方法]
-
-- [Introduction to Information Retrieval](https://nlp.stanford.edu/IR-book/)	（Manning, Raghavan and Schütze）[关于排名/搜索的优秀参考书]
-
-- [Neural Network Methods in Natural Language Processing](https://www.morganclaypool.com/doi/abs/10.2200/S00762ED1V01Y201703HLT037)	（Goldberg）[深入介绍 NLP 的 NN 方法，和相对应的入门书籍]
-
-- [Linguistic Fundamentals for Natural Language Processing](http://www.morganclaypool.com/doi/abs/10.2200/S00493ED1V01Y201303HLT020)	（Bender）[更成功的 NLP 的词法和句法]
-
-- [Deep Learning](http://www.deeplearningbook.org/)	（Goodfellow, Courville and Bengio）[很好的深度学习介绍]
-
-## Miscellaneous
-
-- [How to build a word2vec model in TensorFlow](https://www.tensorflow.org/versions/master/tutorials/word2vec/index.html)	[学习指南]
-
-- [Deep Learning for NLP resources](https://github.com/andrewt3000/dl4nlp)	[按主题分类的关于深度学习的顶尖资源的概述]
-
-- [Last Words: Computational Linguistics and Deep Learning — A look at the importance of Natural Language Processing.](http://mitp.nautil.us/article/170/last-words-computational-linguistics-and-deep-learning)	（Manning）[文章]
-
-- [Natural Language Understanding with Distributed Representation](https://github.com/nyu-dl/NLP_DL_Lecture_Note/blob/master/lecture_note.pdf)	（Cho）[关于 NLU 的 ML / NN 方法的独立讲义]
-
-- [Bayesian Inference with Tears](http://www.isi.edu/natural-language/people/bayes-with-tears.pdf)	（Knight）[教程工作簿]
-
-- [Association for Computational Linguistics](http://aclanthology.info/) （ACL）[期刊选集]
-
-- [Quora: How do I learn Natural Language Processing?](https://www.quora.com/How-do-I-learn-Natural-Language-Processing)
-
-- [Natural Language Understanding and Computational Semantics](https://docs.google.com/document/d/1mkB6KA7KuzNeoc9jW3mfOthv_6Uberxs8l2H7BmJdzg/edit)	（Bowman）[开源的课程大纲和完整幻灯片]
-
-- [fast.ai](http://www.fast.ai/)	[“Making neural nets uncool again”]
-
-## DIY projects and data sets
-
-Nicolas Iderhoff 已经创建了一份[公开、详尽的 NLP 数据集的列表](https://github.com/niderhoff/nlp-datasets)。除了这些，这里还有一些推荐的项目：
-
-- Implement a [part-of-speech (POS) tagger (词性标注)](https://en.wikipedia.org/wiki/Part-of-speech_tagging) based on a [hidden Markov model (HMM) (隐马尔可夫模型)](https://en.wikipedia.org/wiki/Hidden_Markov_model)
-
-- Implement the [CYK algorithm](https://en.wikipedia.org/wiki/CYK_algorithm) for parsing [context-free grammars](https://en.wikipedia.org/wiki/Context-free_grammar)
-
-- Implement [semantic similarity (语义相似度)](https://en.wikipedia.org/wiki/Semantic_similarity) between two given words in a collection of text, e.g. [pointwise mutual information (PMI) (点互信息)](https://en.wikipedia.org/wiki/Pointwise_mutual_information)
-
-- Implement a [Naive Bayes classifier (朴素贝叶斯分类器)](https://en.wikipedia.org/wiki/Naive_Bayes_classifier) to [filter spam](https://en.wikipedia.org/wiki/Naive_Bayes_spam_filtering)
-
-- Implement a [spell checker](https://en.wikipedia.org/wiki/Spell_checker) based on [edit distances](https://en.wikipedia.org/wiki/Edit_distance) between words
-
-- Implement a [Markov chain (马尔科夫链)](https://en.wikipedia.org/wiki/Markov_chain) text generator
-
-- Implement a [topic model](https://en.wikipedia.org/wiki/Topic_model) using [latent Dirichlet allocation (LDA)](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation)
-
-- Use [word2vec](https://code.google.com/archive/p/word2vec/) to generate word embeddings from a large text corpus, e.g. [Wikipedia](https://en.wikipedia.org/wiki/Wikipedia:Database_download)
-
-- Use [k-means](https://en.wikipedia.org/wiki/K-means_clustering) to cluster [tf-idf](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) vectors of text, e.g. news articles
-
-- Implement a [named-entity recognizer (NER) (命名实体识别)](https://en.wikipedia.org/wiki/Named-entity_recognition) (also called a name tagger), e.g. following the [CoNLL-2003 shared task](https://www.clips.uantwerpen.be/conll2003/ner/)
-
-## NLP on social media
-
-- Twitter: [#nlproc](https://twitter.com/hashtag/nlproc), [list of NLPers](https://twitter.com/hashtag/nlproc) (by Jason Baldrige)
-
-- Reddit: [/r/LanguageTechnology](https://www.reddit.com/r/LanguageTechnology)
-
-- Medium: [NLP](https://medium.com/tag/nlp)
Index: blog/posts/2021-04-26-pc-algorithm.md
===================================================================
diff --git a/blog/posts/2021-04-26-pc-algorithm.md b/blog/posts/2021-04-26-pc-algorithm.md
deleted file mode 100644
--- a/blog/posts/2021-04-26-pc-algorithm.md	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
+++ /dev/null	(revision 9e01378bd2f6df42d670c21785efbc04373f03c3)
@@ -1,278 +0,0 @@
----
-layout: Post
-title: PC 算法
-subtitle: 贝叶斯网络与其结构学习算法
-author: Renovamen
-date: 2021-04-26
-headerImage: /img/in-post/2021-04-26/header.jpg
-useHeaderImage: true
-permalinkPattern: /post/:year/:month/:day/:slug/
-tags:
-  - Machine Learning
-  - Bayesian
----
-
-把大三的时候在实验室摸鱼看贝叶斯网络和 PC 算法时写的笔记整理到这里来，免得哪天我换电脑时把笔记搞没了。
-
-<!-- more -->
-
-这里是当时写的 PC 算法的 Python 实现：[<v-icon name="ri-link-m" scale="0.9"/> Renovamen/pcalg-py](https://github.com/Renovamen/pcalg-py)
-
-
-## 概率图模型
-
-对于一个 $K$ 维随机向量 $X = [X_1, X_2, \dots, X_K]^{\top}$，一般难以直接建模。因为如果每个变量为离散变量并有 $M$ 个可能取值，在不作任何独立性假设的前提下，需要 $M^K -1$ 个参数才能表示其概率分布，参数数量会非常庞大。
-
-一种减少参数数量的方法是独立性假设。把 $X$ 的联合概率分解为 $K$ 个条件概率的乘积：
-
-$$
-p(X = x) = \prod_{k=1}^K p(x_k | x_1, \dots, x_{k-1})
-$$
-
-$x$ 为随机向量 $X$ 的取值。可以看到，如果某些变量之间存在条件独立，参数数量就可以大幅减少。
-
-因此，**概率图模型**（Probabilistic Graphical Model，PGM）用图结构来描述多元随机变量之间的条件独立关系，从而为研究高维空间中的概率模型带来了很大的便捷。
-
-概率图模型中，每个节点表示一个（或一组）随机变量，边表示这些随机变量之间的概率依赖关系。常见的概率图模型可以分为有向图模型和无向图模型。
-
-- 有向图模型（Directed Graphical Model），也称为**贝叶斯网络**（Bayesian Network）或**信念网络**（Belief Network），使用**有向无环图**（Directed Acyclic Graph，DAG）来描述变量之间的关系。如果两个节点之间有连边，表示这两个变量之间有因果关系，即不存在其他变量使得这两个变量条件独立。
-
-- 无向图模型，也称为**马尔可夫随机场**（Markov Random Field，MRF），使用无向图来描述变量之间的关系。两个节点之间有连边代表这两个变量之间有概率依赖关系，但不一定是因果关系。
-
-![pcg](/img/in-post/2021-04-26/pcg.png)
-
-<p class="desc">图片来源：<a href="https://github.com/nndl/nndl.github.io" target="_blank">《神经网络与深度学习》</a>，邱锡鹏</p>
-
-本文只讨论有向图模型，即贝叶斯网络。
-
-
-## 贝叶斯网络
-
-### 定义
-
-有向无环图 $G$ 中，每个节点对应 $K$ 维随机向量 $X$ 中的一个变量，有向边 $e_{ij}$ 表示随机变量 $X_i$ 和 $X_j$ 之间具有因果关系，父节点 $X_i$ 是『因』，子节点 $X_j$ 是『果』，显然这两个点之间一定非条件独立。
-
-
-令 $X_{\pi_k}$ 为变量 $X_k$ 的所有父节点变量集合，$P(X_k \mid X_{\pi_k})$ 表示每个随机变量的**局部条件概率分布（Local Conditional Probability Distribution）**。
-
-如果 $X$ 的联合概率分布可以分解为每个随机变量 $X_k$ 的局部条件概率的连乘形式，即：
-
-$$
-p(x) = \prod_{k=1}^K p(x_k \mid x_{\pi_k})
-$$
-
-那么称 $(G,X)$ 构成了一个贝叶斯网络。
-
-
-### 局部马尔可夫性质
-
-每个随机变量在给定父节点的情况下，条件独立于它的非后代节点：
-
-$$
-\newcommand{\indep}{\perp \!\!\! \perp}
-
-X_k \indep Z \mid X_{\pi_k}
-$$
-
-其中 $Z$ 为 $X_k$ 的非后代节点。
-
-
-### 基本问题
-
-- **学习问题**
-
-  - **结构学习**：那么怎样才可以获得这个神奇的有向无环图呢，这就是结构学习问题。即学习出最优网络结构，也就是各节点之间的依赖关系。主流的结构学习方法主要可以分为：
-
-    - 基于**评分搜索**的方法：利用搜索算法和评分函数，对每一个搜索到的网络结构进行评分，最终搜索出评分最高的网络结构。搜索算法的复杂度和精确度直接决定了学习算法的搜索效率，评分函数的优劣也直接决定了算法的计算复杂度和精确度。所以选择合理的优化搜索算法和评分函数是该类方法的核心问题。
-
-      该类方法容易陷入局部最优解而无法达到全局最优，并且结构空间的⼤⼩随节点的增加呈指数增加(空间复杂度)。
-    
-    - 基于**依赖统计分析**的方法：分析变量间的依赖关系，在依赖性较大的两节点之间添加连接边，得到无向图。然后根据包含关系等方式确定无向图中边的方向，得到最终的有向无环图。本文要讨论的 **PC 算法**就是这类方法中（比较古老）的一种。
-
-      该类方法能获得全局最优解，但随着节点的增加，算法的时间复杂度会增加得很快；并且它不能区分同属于一个马尔可夫等价类的图，这一点[后面](#马尔科夫等价类)会讲到。
-
-  - **参数学习**：在给定网络结构时，确定网络参数，即参数估计问题：
-      
-    - **不含隐变量**：如果图模型中不含**隐变量**（latent variable），即所有变量都是可观测的，那么网络参数一般可以直接通过**最大似然**来进行估计。
-
-    - **含隐变量**：有些时候 $X$ 中的变量有很复杂的依赖关系，这时通常会引入**隐变量** $z$ 来简化模型。如果图模型中包含隐变量，即有部分变量是不可观测的，这时就需要用 **EM 算法**（Expectation Maximum，期望最大化算法）来进行参数估计。
-
-      如果 EM 算法中的后验是 intractable 的，那么又需要用**变分推断**（Variational Inference）来寻找一个简单分布来近似后验。
-
-      而在深度学习大行其道的今天，你可能会想到用神经网络去拟合这个后验不就完事儿了，是的这就是**变分自编码器**（Variational Auto-Encoder，VAE）的思想，去学它吧朋友。
-
-    本文不讨论参数学习问题，但我在我的[笔记本](https://note.zxh.io/ai/ml/pcg/parameters-learning-no-latent.html)上写了一些参数学习相关的东西，有兴趣的话可以看一看。
-
-- **推断问题**：在已知部分变量时，计算其他变量的条件概率分布
-
-
-## PC 算法
-
-好的现在讲主题了，用 PC 算法[^pc]来学习出贝叶斯网络的结构。如上文所述，PC 算法会先确定节点间的依赖关系（但不确定方向），即先生成一个无向图，然后再确定依赖方向，把无向图扩展为**完全部分有向无环图**（Completed Partially Directed Acyclic Graph，CPDAG）。
-
-
-### 依赖关系确立
-
-设 $V$ 是输入点集，有以下步骤：
-
-- 在 $V$ 上生成完全无向图 $G$
-- 对于 $G$ 中的两个相邻点 $i, j$，如果 $i$ 和 $j$ 能在给定节点 $k$ 时条件独立，则删除 $i$ 和 $j$ 之间的边
-
-这样会得到一个无向图，图中的无向边表示它连接的两个节点之间有依赖（因果）关系，这样的无向图叫**骨架**（skeleton）。PC 算法把上述过程转化为了 **$d$ 分隔**（d-separation）[^d-separation]问题。
-
-
-#### d 分隔
-
-::: info d 分隔的定义
-节点集合 $O$ 能 $d$ 分隔节点 $i$ 与节点 $j$，当且仅当：
-
-给定 $O$ 时，$i$ 与 $j$ 之间不存在**有效路径**（active path），即 $i$ 和 $j$ 在 $O$ 下条件独立（记作 $i \perp j \mid O$）。
-:::
-
-用 $O(i, j)$ 表示能够 $d$ 分隔 $i$ 和 $j$ 的点集，用 $adj(G, x)$ 表示图 $G$ 中节点 $x$ 的相邻点集，那么 PC 算法检验条件独立性的具体流程为[^pc-jmlr2007]：
-
-![pc-skeleton](/img/in-post/2021-04-26/pc-skeleton.png)
-
-<p class="desc"><a href="https://www.jmlr.org/papers/volume8/kalisch07a/kalisch07a.pdf" target="_blank">Estimating High-Dimensional Directed Acyclic Graphs with the PC-Algorithm</a>. Markus Kalisch and Peter Buhlmann. JMLR 2007.</p>
-
-简单总结一下：
-
-- $\ell = 1$
-
-- **repeat**
-
-  - **for 每个相邻点对 $(i, j)$**
-
-    - **for $adj(G, i) \backslash \{j\}$ 或 $adj(G, i) \backslash \{i\}$ 的所有可能的节点数为 $\ell$ 的子集 $K$**
-
-      - 测试 $K$ 能否 $d$ 分隔 $(i, j)$
-
-      - 如果能，说明 $i$ 和 $j$ 之间不存在有效的依赖关系，所以删除边 $i - j$，并将这个点集加入 $O(i, j)$ 和 $O(j, i)$，**break**
-
-  - $\ell = \ell + 1$
-
-- **until** 当前图中的所有的邻接点集都小于 $\ell$
-
-
-#### Fisher Z Test
-
-为了判断 $d$ 分隔，我们需要对任意两个节点进行条件独立性检验，PC 算法采用了 Fisher Z Test[^fisher-z-test] 作为条件独立性检验方法。实际上 Fisher Z Test 是一种相关性检验方法，但 PC 算法认为这一堆随机变量整体上服从多元高斯分布，这时变量条件独立与变量之间的偏相关系数为 0 等价（多元高斯分布的基本特性，证明过程可以参考 [Steffen L. Lauritzen 的课件](http://www.stats.ox.ac.uk/~steffen/teaching/gm10/stflournotes.pdf)[^graphical-models]第 4.2.1 节），所以可以用 Fisher Z Test 进行条件独立性检验。
-
-偏相关系数指校正其它变量后某一变量与另一变量的相关关系，校正的意思可以理解为假定其它变量都取值为均数。任意两个变量 $i, j$ 的 $h$ 阶（排除其他 $h$ 个变量的影响后，$h<=k-2$）偏相关系数为：
-
-$$
-\rho_{i,j \mid K} = \frac{\rho_{i,j \mid K \backslash h} - \rho_{i,h \mid K \backslash h} \rho_{j,h \mid K \backslash h}}{\sqrt{(1 - \rho^2_{i,h \mid K \backslash h}) (1 - \rho^2_{j,h \mid K \backslash h})}}
-$$
-
-为了判断 $\rho$ 是否为 0，需要将 $\rho$ 通过 Fisher Z 变换[^fisher-z-transformation]转换成正态分布：
-
-$$
-Z(i, j \mid K) = \frac{1}{2} \log (\frac{1 + \hat{\rho}_{i,j \mid K}}{1 - \hat{\rho}_{i,j \mid K}})
-$$
-
-定义零假设和对立假设：
-
-- 零假设：$H_0(i,j \mid K):  \rho_{i,j \mid K} \not= 0$
-- 对立假设：$H_1(i,j \mid K):  \rho_{i,j \mid K} = 0$
-
-然后给定一个显著性水平 $\alpha \in (0, 1)$，那么（双侧）检验的规则为，如果有：
-
-$$
-\sqrt{n - |K| - 3}| Z(i,j \mid K) \leq \Phi^{-1} (1 - \alpha/2)
-$$
-
-其中 $\Phi(\cdot)$ 为 $\mathcal{N}(0, 1)$ 的累积分布函数，则拒绝零假设，$i, k$ 关于 $K$  条件独立。所以将上面伪代码的第 11 行替换为 **if $\sqrt{n - |K| - 3}| Z(i,j \mid K) \leq \Phi^{-1} (1 - \alpha/2)$**。
-
-
-
-### 依赖关系方向确立
-
-经过上一个阶段，我们得到了一个无向图。现在我们要利用 $d$ 分隔的原理来确定图中边的依赖方向，把骨架扩展为 DAG。
-
-对于任意三个以有效依赖关系边相连的节点 $X-Z-Y$，其依赖关系必为下图的四种关系之一：
-
-<img src="/img/in-post/2021-04-26/link.png" width="450px" alt="link" />
-
-$d$ 分隔的结论为：对于有向无环图 $E$，有两个节点 $X, Y$ 和一个点集 $O$，为了判断 $X$ 和 $Y$ 是否关于 $O$ 条件独立，考虑 $E$ 中所有 $X$ 和 $Y$ 之间的无向路径，对于其中一条路径，如果它满足以下两个条件中的任意一条，则称这条路径是阻塞的：
-
-- 路径中存在某个节点 $Z$ 是 head-to-tial（图中情况 a, b）或 tail-to-tail 节点（图中情况 c），且 $Z$ 包含在 $O$ 中
-- 路径中存在某个节点 $Z$ 是 head-to-head 节点（图中情况 d），且 $Z$ 没有被包含在 $O$ 中
-
-如果 $X,Y$ 间所有的路径都是阻塞的，那么 $X,Y$ 关于 $O$ 条件独立；否则，$X,Y$ 不关于 $O$ 条件独立。
-
-而我们已经记录了 $d$ 分隔 $X$ 和 $Y$ 的点集 $O$，因此我们可以由 $d$ 分隔的结论反推出贝叶斯网络中边的方向，方向的判断方法可以转换成以下三条规则：
-
-- **规则 1**：如果存在 $X \rightarrow Y - Z$，把 $Y - Z$ 变为 $Y \rightarrow Z$
-- **规则 2**：如果存在 $X \rightarrow Z \rightarrow Y$，把 $X - Y$ 变为 $X \rightarrow Y$
-- **规则 3**： 如果存在 $X - Z_1 \rightarrow Y$，$X - Z_2 \rightarrow Y$，且 $Z_1, Z_2$ 不相邻，把 $X - Y$ 变为 $X \rightarrow Y$
-
-实际上还可以推出一个规则 4：
-
-- **规则 4**：如果存在 $X - Z_1 \rightarrow Z_2$ 和 $Z_1 \rightarrow Z_2 \rightarrow Y$，且 $Z_1, Z_2$ 不相邻，把 $X - Y$ 变为 $X \rightarrow Y$
-
-但很显然这种情况是矛盾的，不可能存在，所以不用考虑。
-
-总结一下：
-
-![extend-to-cpdag](/img/in-post/2021-04-26/extend-to-cpdag.png)
-
-<p class="desc"><a href="https://www.jmlr.org/papers/volume8/kalisch07a/kalisch07a.pdf" target="_blank">Estimating High-Dimensional Directed Acyclic Graphs with the PC-Algorithm</a>. Markus Kalisch and Peter Buhlmann. JMLR 2007.</p>
-
-这样我们就可以得到一个完全部分有向无环图。
-
-
-### 马尔科夫等价类
-
-很明显，完全部分有向无环图（CPDAG）跟有向无环图看上去就不一样。首先来看什么是**部分有向无环图**（Partially Directed Acyclic Graph，PDAG）：
-
-::: info 部分有向无环图
-假设 $G = (V, E)$ 是一个图，若边集 $E$ 中包含有向边和无向边，且不存在有向环，则称 $G$ 是一个部分有向无环图。
-:::
-
-而**完全部分有向无环图**指：
-
-::: info 完全部分有向无环图
-假设 $G = (V, E)$ 是一个部分有向无环图，若 $E$ 中的有向边都是不可逆的，并且 $E$ 中的无向边都是可逆的，则称 $G$ 是一个完全部分有向无环图。
-:::
-
-关于可逆和不可逆：
-
-::: info 可逆 / 不可逆
-对于有向无环图 $G = (V, E)$ 中的任意有向边 $V_i \rightarrow V_j \in E$，如果存在图 $G' = (V, E')$ 与 $G$ 等价，且 $V_j \rightarrow V_i \in E'$，则称有向边 $V_i \rightarrow V_j$ 在 $G$ 中是可逆的，否则是不可逆的。
-
-同理，对任意无向边 $V_i - V_j \in E$，若存在 $G_1 = (V, E_1)$、$G_2 = (V, E_2)$ 均与 $G$ 等价，且 $V_i \rightarrow V_j \in E_1$、$V_j \rightarrow V_i \in E_2$，则称无向边 $V_i - V_j$ 在 $G$ 中是可逆的，否则是不可逆的。
-:::
-
-换句话说用 PC 算法得到的图是含有无向边的。这是因为依据 $d$ 分隔确定的条件独立性所构造的网络
-结构不具有唯一性，它们只是真实的贝叶斯网络的**马尔科夫等价类**（Markov Equivalence Class）：
-
-::: info 马尔科夫等价类
-有向无环图 $G_1 = (V, E_1)$ 和 $G_2 = (V, E_2)$ 有相同的顶点集合和骨架，$V$ 为顶点集合，$E_1$ 和 $E_2$ 为边的集合。
-
-对于任意的不相交的顶点集合 $A, B, C \in V$，如果满足 $A, B$ 在 $G_1$ 和 $G_2$ 中都被 $C$ 所 $d$ 分隔（也叫有相同的 $V$ 结构），则称图 $G_1$ 和 $G_2$ 是马尔科夫等价的。
-:::
-
-举个栗子：
-
-<img src="/img/in-post/2021-04-26/markov-equivalence-class.png" width="450px" alt="markov-equivalence-class" />
-
-<p class="desc">马尔科夫等价类</p>
-
-上图 $G_1$ 和 $G_2$ 是马尔科夫等价类，它们左上角的那条有向边方向并不相同，这时 PC 算法就无法判断这条边的方向了，只能输出无向边，即 $G_3$。
-
-所以，严格来说，PC 算法以及大多数基于依赖统计分析的贝叶斯网络结构学习算法，得到的都只是一个 CPDAG（依然有无向边），而不是真正意义上的贝叶斯网络（有向无环图）。
-
-
-## 参考
-
-[^pc]: [An Algorithm for Fast Recovery of Sparse Causal Graphs.](http://shelf2.library.cmu.edu/Tech/28463803.pdf) *Peter Spirtes and Clark Glymour.* Social Science Computer Review 1991.
-
-[^pc-jmlr2007]: [Estimating High-Dimensional Directed Acyclic Graphs with the PC-Algorithm.](https://www.jmlr.org/papers/volume8/kalisch07a/kalisch07a.pdf) *Markus Kalisch and Peter Buhlmann.* JMLR 2007.
-
-[^d-separation]: [d-Separation: From Theorems to Algorithms.](https://arxiv.org/pdf/1304.1505.pdf) *Dan Geiger, et al.* UAI 1989.
-
-[^fisher-z-test]: [Frequency Distribution of the Values of the Correlation Coefficient in Samples from an Indefinitely Large Population.](https://www.quantresearch.org/Fisher%20transform%20seminal%20paper.pdf) *R. A. Fisher.* Biometrika 1915.
-
-[^graphical-models]: [Elements of Graphical Models.](http://www.stats.ox.ac.uk/~steffen/teaching/gm10/stflournotes.pdf) *Steffen L. Lauritzen.* 2011.
-
-[^fisher-z-transformation]: [Wikipedia: Fisher transformation](https://en.wikipedia.org/wiki/Fisher_transformation)
